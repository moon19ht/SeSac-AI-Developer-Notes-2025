# 🧠 Deep Learning 정리

##### 🗓️ 2025.07.25
##### 📝 Writer : Moon19ht

---

## 📚 목차

1. [개요](#개요)
2. [프로젝트 1: 유방암 진단 이진 분류](#프로젝트-1-유방암-진단-이진-분류)
3. [프로젝트 2: 와인 품종 다중 분류](#프로젝트-2-와인-품종-다중-분류)
4. [프로젝트 3: IMDB 영화 리뷰 감정 분석](#프로젝트-3-imdb-영화-리뷰-감정-분석)
5. [프로젝트 4: 로이터 뉴스 기사 분류](#프로젝트-4-로이터-뉴스-기사-분류)
6. [분류 유형별 비교 분석](#분류-유형별-비교-분석)
7. [데이터 타입별 특성 분석](#데이터-타입별-특성-분석)
8. [모델 아키텍처 패턴 분석](#모델-아키텍처-패턴-분석)
9. [주요 학습 내용](#주요-학습-내용)
10. [결론 및 향후 과제](#결론-및-향후-과제)

---

## 📖 개요

이번 실습에서는 **다양한 도메인과 데이터 타입**에 걸쳐 4가지 딥러닝 분류 모델을 구현했습니다. 의료 데이터부터 텍스트 분석까지, 실무에서 자주 마주치는 다양한 분류 문제를 해결해보았습니다.

### 🎯 학습 목표
- **다양한 분류 유형** 비교 (이진/다중 클래스)
- **서로 다른 데이터 타입** 처리 (구조화/비구조화)
- **실무형 파이프라인** 구축 경험
- **도메인별 특성** 이해 및 적용
- **성능 최적화** 방법 비교

### 🛠️ 주요 기술 스택
- **프레임워크**: TensorFlow 2.15.1, Keras 2.15.0
- **언어**: Python 3.x
- **라이브러리**: NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn

---

## 🏥 프로젝트 1: 유방암 진단 이진 분류

### 📊 프로젝트 개요
- **목표**: 의료 데이터를 활용한 유방암 진단 자동화
- **데이터**: sklearn 유방암 데이터셋 (569개 샘플, 30개 특성)
- **분류 유형**: 이진 분류 (악성 vs 양성)
- **실무 의미**: 의료 진단 보조 시스템

### 🏗️ 모델 아키텍처
```python
model = Sequential([
    Dense(128, activation='relu', input_shape=(30,)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')  # 이진 분류
])
```

### 📈 주요 성과
- **테스트 정확도**: **98.25%** (112/114 정확 예측)
- **ROC AUC**: **0.9997** (거의 완벽한 분류)
- **혼동 행렬**: 악성 42/42 정확, 양성 70/72 정확
- **F1-Score**: 악성 0.98, 양성 0.99

### 🔧 기술적 특징
- **표준화**: StandardScaler로 30개 특성 정규화
- **콜백 활용**: ModelCheckpoint + EarlyStopping
- **과적합 방지**: 검증 손실 모니터링
- **의료 특화**: 정밀도/재현율 균형 중시

---

## 🍷 프로젝트 2: 와인 품종 다중 분류

### 📊 프로젝트 개요
- **목표**: 화학적 특성을 바탕으로 와인 품종 분류
- **데이터**: sklearn 와인 데이터셋 (178개 샘플, 13개 특성, 3개 클래스)
- **분류 유형**: 다중 클래스 분류
- **실무 의미**: 품질 관리 및 자동 분류 시스템

### 🏗️ 모델 아키텍처
```python
model = Sequential([
    Dense(128, activation='relu', input_shape=(13,)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(32, activation='relu'),
    Dense(3, activation='softmax')  # 3클래스 분류
])
```

### 📈 주요 성과
- **테스트 정확도**: **97.22%** (35/36 정확 예측)
- **클래스별 성능**: Class_0 (92% precision), Class_1 (100% precision), Class_2 (100% precision)
- **균등한 분류**: 모든 클래스에서 우수한 성능
- **빠른 수렴**: 8에포크만으로 최적 성능 달성

### 🔧 기술적 특징
- **원핫 인코딩**: 다중 클래스 레이블 처리
- **소프트맥스**: 확률 분포 출력
- **categorical_crossentropy**: 다중 클래스 손실 함수
- **소규모 데이터**: 178개 샘플로도 높은 성능

---

## 🎬 프로젝트 3: IMDB 영화 리뷰 감정 분석

### 📊 프로젝트 개요
- **목표**: 영화 리뷰 텍스트의 감정(긍정/부정) 분류
- **데이터**: IMDB 리뷰 25,000개 훈련 + 25,000개 테스트
- **분류 유형**: 텍스트 이진 분류
- **실무 의미**: 소셜 미디어 감정 분석, 고객 피드백 자동화

### 🏗️ 모델 아키텍처
```python
model = Sequential([
    Dense(16, activation='relu', input_shape=(10000,)),
    Dense(16, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')  # 이진 분류
])
```

### 📈 주요 성과
- **테스트 정확도**: **85.31%** (21,327/25,000 정확 예측)
- **ROC AUC**: **0.9180** (우수한 분류 성능)
- **균형잡힌 성능**: 부정 86% precision, 긍정 85% precision
- **대용량 처리**: 25,000개 샘플 성공적 처리

### 🔧 기술적 특징
- **원핫 인코딩**: 10,000차원 희소 벡터 (99% 이상이 0)
- **텍스트 전처리**: 빈도 기반 상위 10,000 단어 선택
- **수동 구현**: vectorize_sequences 함수로 인코딩 직접 구현
- **메모리 효율성**: 희소 행렬의 한계 경험

---

## 📰 프로젝트 4: 로이터 뉴스 기사 분류

### 📊 프로젝트 개요
- **목표**: 뉴스 기사를 46개 카테고리로 자동 분류
- **데이터**: 로이터 뉴스 8,982개 훈련 + 2,246개 테스트
- **분류 유형**: 대규모 다중 클래스 분류
- **실무 의미**: 뉴스 포털 자동 분류, 콘텐츠 관리 시스템

### 🏗️ 모델 아키텍처
```python
model = Sequential([
    Dense(64, activation='relu', input_shape=(10000,)),
    Dense(64, activation='relu'),
    Dense(46, activation='softmax')  # 46클래스 분류
])
```

### 📈 주요 성과
- **테스트 정확도**: **78.14%** (1,755/2,246 정확 예측)
- **고신뢰도 예측**: 신뢰도 > 0.9인 경우 93.56% 정확도
- **카테고리별 편차**: 주요 카테고리(3,4번) 90%+ vs 소규모 카테고리 50%+
- **실무형 성능**: 실제 뉴스 분류에 적용 가능한 수준

### 🔧 기술적 특징
- **클래스 불균형**: 최대 3,159개 vs 최소 10개 (315:1 비율)
- **46차원 출력**: 대규모 다중 클래스 처리
- **실제 뉴스 데이터**: 노이즈와 복잡성이 높은 실무 데이터
- **성능 trade-off**: 복잡성 증가에 따른 정확도 하락

---

## 📊 분류 유형별 비교 분석

### 🔄 이진 분류 vs 다중 분류

| 특성 | 유방암 (이진) | IMDB (이진) | 와인 (3클래스) | 로이터 (46클래스) |
|------|---------------|-------------|----------------|-------------------|
| **정확도** | 98.25% | 85.31% | 97.22% | 78.14% |
| **출력 활성화** | sigmoid | sigmoid | softmax | softmax |
| **손실 함수** | binary_crossentropy | binary_crossentropy | categorical_crossentropy | categorical_crossentropy |
| **클래스 수** | 2 | 2 | 3 | 46 |
| **복잡도** | 낮음 | 중간 | 중간 | 높음 |

### 📈 성능 패턴 분석
1. **클래스 수 증가 → 정확도 감소**: 2클래스(98%,85%) > 3클래스(97%) > 46클래스(78%)
2. **데이터 타입 영향**: 구조화 데이터 > 텍스트 데이터
3. **데이터 품질 중요성**: 깨끗한 의료 데이터 vs 노이즈가 많은 뉴스 데이터

---

## 🔍 데이터 타입별 특성 분석

### 📋 구조화 데이터 (유방암, 와인)

#### 장점
- ✅ **높은 성능**: 95%+ 정확도 달성
- ✅ **안정적 학습**: 과적합 없이 빠른 수렴
- ✅ **해석 가능성**: 각 특성의 의미가 명확
- ✅ **전처리 단순**: 표준화만으로 충분

#### 특징
- **작은 차원**: 13~30개 특성
- **밀집 벡터**: 모든 값이 의미있는 정보
- **도메인 지식**: 특성 선택에 전문 지식 반영

### 📝 비구조화 데이터 (IMDB, 로이터)

#### 도전과제
- ❌ **높은 차원**: 10,000차원 희소 벡터
- ❌ **복잡한 전처리**: 토큰화, 인코딩, 어휘 제한
- ❌ **정보 손실**: 단어 순서, 문맥 정보 누락
- ❌ **메모리 비효율**: 99% 이상이 0인 희소 행렬

#### 개선 방향
- **임베딩 레이어**: 밀집 표현으로 차원 축소
- **순환 신경망**: LSTM/GRU로 순서 정보 활용
- **어텐션 메커니즘**: 중요한 단어에 집중

---

## 🏗️ 모델 아키텍처 패턴 분석

### 🔢 은닉층 설계 패턴

#### 깊은 네트워크 (유방암, 와인)
```
입력 → 128 → 64 → 32 → 32 → 출력
```
- **장점**: 복잡한 패턴 학습 가능
- **구조화 데이터**: 높은 성능 달성
- **파라미터**: 15,000~13,000개

#### 얕은 네트워크 (IMDB, 로이터)
```
입력 → 16/64 → 16/64 → (16) → 출력
```
- **장점**: 과적합 방지, 빠른 학습
- **텍스트 데이터**: 희소성으로 인한 단순 구조
- **파라미터**: 160,000~650,000개

### 📐 은닉층 크기 결정 요인
1. **입력 차원**: 고차원 입력 → 큰 첫 번째 은닉층
2. **데이터 복잡도**: 복잡한 패턴 → 깊은 네트워크
3. **과적합 위험**: 작은 데이터셋 → 작은 은닉층

---

## 🎓 주요 학습 내용

### 🔧 기술적 학습

#### 1. 분류 문제 유형별 설계
- **이진 분류**: sigmoid + binary_crossentropy
- **다중 분류**: softmax + categorical_crossentropy
- **클래스 수에 따른 복잡도 관리**

#### 2. 데이터 전처리 기법
- **구조화 데이터**: 표준화(StandardScaler)
- **텍스트 데이터**: 원핫 인코딩, 어휘 제한
- **레이블 처리**: to_categorical() 활용

#### 3. 모델 최적화 전략
- **콜백 활용**: EarlyStopping, ModelCheckpoint
- **검증 전략**: 훈련/검증/테스트 분할
- **성능 평가**: 정확도, 정밀도, 재현율, ROC AUC

### 🏢 실무적 인사이트

#### 1. 도메인별 특성 이해
- **의료**: 높은 정밀도 요구, 해석 가능성 중요
- **소비재**: 균형잡힌 성능, 실시간 처리
- **텍스트**: 전처리 품질이 성능 좌우
- **뉴스**: 클래스 불균형 문제 대응 필요

#### 2. 성능 vs 복잡도 Trade-off
- **단순한 문제**: 깊은 네트워크로 고성능 달성
- **복잡한 문제**: 적절한 복잡도로 과적합 방지
- **데이터 품질**: 모델 복잡도보다 더 중요

#### 3. 확장성 고려사항
- **메모리 효율성**: 희소 행렬 vs 임베딩
- **추론 속도**: 모델 크기 vs 성능
- **유지보수성**: 파이프라인 단순화

---

## 🚀 결론 및 향후 과제

### 🏆 주요 성과

#### 1. 다양한 분류 문제 해결
- **4개 도메인**: 의료, 소비재, 엔터테인먼트, 뉴스
- **다양한 복잡도**: 2클래스부터 46클래스까지
- **실무 수준 성능**: 모든 프로젝트에서 실용적 결과

#### 2. 기술적 역량 확보
- **전체 파이프라인**: 데이터 → 전처리 → 모델링 → 평가
- **성능 최적화**: 콜백, 정규화, 검증 전략
- **시각화 분석**: 훈련 과정, 성능 메트릭, 오분류 패턴

#### 3. 실무 적용 가능성
- **의료 진단 보조**: 98% 정확도의 유방암 진단
- **고객 피드백 분석**: 85% 정확도의 감정 분석
- **콘텐츠 자동 분류**: 78% 정확도의 뉴스 분류

### 📈 개선 방향

#### 1. 텍스트 분류 고도화
```python
# 현재: 원핫 인코딩
vectorize_sequences(sequences, 10000)

# 개선: 임베딩 + LSTM
Embedding(10000, 128) → LSTM(64) → Dense
```

#### 2. 클래스 불균형 해결
```python
# 가중치 적용
model.compile(
    loss='categorical_crossentropy',
    class_weight={0: 1.0, 1: 0.5, 2: 2.0}  # 불균형 보정
)
```

#### 3. 고급 정규화 기법
```python
# 드롭아웃 + 배치 정규화
Dense(64, activation='relu'),
Dropout(0.5),
BatchNormalization(),
```

### 🔮 다음 단계

#### 단기 목표 (1-2주)
1. **임베딩 레이어**: Word2Vec, GloVe 적용
2. **순환 신경망**: LSTM/GRU 텍스트 분류
3. **정규화 기법**: Dropout, BatchNorm 적용

#### 중기 목표 (1-2개월)
1. **어텐션 메커니즘**: Transformer 아키텍처
2. **전이 학습**: BERT, GPT 활용
3. **앙상블 방법**: 여러 모델 결합

#### 장기 목표 (3-6개월)
1. **멀티모달**: 텍스트 + 이미지 분류
2. **실시간 시스템**: 스트리밍 데이터 처리
3. **MLOps**: 모델 배포 및 모니터링

---

### 💡 핵심 교훈

> **"데이터의 특성을 이해하고, 문제에 맞는 적절한 모델을 선택하는 것이 성공의 열쇠"**

이번 실습을 통해 **다양한 도메인의 분류 문제**를 해결하면서, 딥러닝의 범용성과 동시에 각 문제별 특수성을 깊이 이해할 수 있었습니다. 특히 **구조화 데이터와 텍스트 데이터의 차이**, **이진 분류와 다중 분류의 복잡도**, **실무에서의 성능 vs 복잡도 트레이드오프**를 실제로 경험할 수 있었던 의미있는 학습이었습니다.
