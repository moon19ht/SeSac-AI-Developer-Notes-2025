# ğŸ§  Deep Learning ì •ë¦¬

##### ğŸ—“ï¸ 2025.07.31
##### ğŸ“ Writer : Moon19ht

---

## ğŸ“š ëª©ì°¨

1. [ìì—°ì–´ ì²˜ë¦¬ ê¸°ì´ˆ](#ìì—°ì–´-ì²˜ë¦¬-ê¸°ì´ˆ)
2. [í…ìŠ¤íŠ¸ ë²¡í„°í™” êµ¬í˜„](#í…ìŠ¤íŠ¸-ë²¡í„°í™”-êµ¬í˜„)
3. [Keras TextVectorization í™œìš©](#keras-textvectorization-í™œìš©)
4. [IMDB ê°ì„± ë¶„ì„ í”„ë¡œì íŠ¸](#imdb-ê°ì„±-ë¶„ì„-í”„ë¡œì íŠ¸)
5. [í•µì‹¬ ê°œë… ì •ë¦¬](#í•µì‹¬-ê°œë…-ì •ë¦¬)
6. [ì‹¤ë¬´ ì ìš© ë°©ì•ˆ](#ì‹¤ë¬´-ì ìš©-ë°©ì•ˆ)

---

## ìì—°ì–´ ì²˜ë¦¬ ê¸°ì´ˆ

### ğŸ¯ ìì—°ì–´ ì²˜ë¦¬ë€?
ìì—°ì–´ ì²˜ë¦¬(Natural Language Processing, NLP)ëŠ” ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì…ë‹ˆë‹¤.

### ğŸ“Š ì£¼ìš” ì‘ìš© ë¶„ì•¼
- **ê°ì„± ë¶„ì„**: í…ìŠ¤íŠ¸ì˜ ê°ì •, ì˜ê²¬ ë¶„ì„
- **ê¸°ê³„ ë²ˆì—­**: ì–¸ì–´ ê°„ ìë™ ë²ˆì—­
- **ì§ˆì˜ ì‘ë‹µ**: ìì—°ì–´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
- **í…ìŠ¤íŠ¸ ìš”ì•½**: ê¸´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
- **ê°œì²´ëª… ì¸ì‹**: ì¸ëª…, ì§€ëª…, ê¸°ê´€ëª… ë“± ì‹ë³„

### ğŸ”§ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ê³¼ì •
1. **í‘œì¤€í™”(Standardization)**: ëŒ€ì†Œë¬¸ì í†µì¼, êµ¬ë‘ì  ì œê±°
2. **í† í°í™”(Tokenization)**: ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í• 
3. **ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•(Vocabulary Building)**: ê³ ìœ  ë‹¨ì–´ ì§‘í•© ìƒì„±
4. **ìˆ˜ì¹˜í™”(Numerization)**: í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜

---

## í…ìŠ¤íŠ¸ ë²¡í„°í™” êµ¬í˜„

### ğŸ’¡ ë²¡í„°í™”ì˜ í•„ìš”ì„±
ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ«ìë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.

### ğŸ—ï¸ MyVectorize í´ë˜ìŠ¤ êµ¬í˜„

#### ì£¼ìš” ë©”ì„œë“œ
```python
class MyVectorize:
    def standardize(self, text):
        """í…ìŠ¤íŠ¸ í‘œì¤€í™”: ì†Œë¬¸ì ë³€í™˜, êµ¬ë‘ì  ì œê±°"""
        text = text.lower()
        return "".join(c for c in text if c not in string.punctuation)
    
    def tokenize(self, text):
        """í† í°í™”: ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ ë¶„í• """
        return text.split()
    
    def make_vocabulary(self, dataset):
        """ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•: íŠ¹ìˆ˜ í† í°ê³¼ ë‹¨ì–´ ë§¤í•‘"""
        self.vocabulary = {"": 0, "[UNK]": 1}  # íŒ¨ë”©, ë¯¸ë“±ë¡ ë‹¨ì–´
        # ë°ì´í„°ì…‹ ìˆœíšŒí•˜ë©° ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•
    
    def encode(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ì‹œí€€ìŠ¤ë¡œ ì¸ì½”ë”©"""
        # ë¯¸ë“±ë¡ ë‹¨ì–´ëŠ” [UNK] í† í°(1)ìœ¼ë¡œ ì²˜ë¦¬
    
    def decode(self, int_sequence):
        """ìˆ«ì ì‹œí€€ìŠ¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©"""
        # ì—­ë°©í–¥ ë§¤í•‘ìœ¼ë¡œ ë³µì›
```

#### íŠ¹ìˆ˜ í† í° ì²˜ë¦¬
- **íŒ¨ë”© í† í°("")**: ì¸ë±ìŠ¤ 0, ì‹œí€€ìŠ¤ ê¸¸ì´ ë§ì¶¤ìš©
- **ë¯¸ë“±ë¡ ë‹¨ì–´ í† í°("[UNK]")**: ì¸ë±ìŠ¤ 1, ì–´íœ˜ ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ ì²˜ë¦¬

### ğŸ“ˆ êµ¬í˜„ì˜ ì¥ë‹¨ì 
**ì¥ì :**
- êµ¬í˜„ ì›ë¦¬ ì´í•´ ìš©ì´
- ì™„ì „í•œ ì œì–´ ê°€ëŠ¥
- ì™¸ë¶€ ì˜ì¡´ì„± ìµœì†Œí™”

**ë‹¨ì :**
- ì„±ëŠ¥ ì œí•œ (Python ê¸°ë°˜)
- ê³ ê¸‰ ê¸°ëŠ¥ ë¶€ì¡±
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë‚®ìŒ

---

## Keras TextVectorization í™œìš©

### âš¡ TextVectorizationì˜ ì¥ì 
- **TensorFlow ìµœì í™”**: GPU ê°€ì† ì§€ì›
- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ìœ¨ì  ì²˜ë¦¬
- **ë‹¤ì–‘í•œ ì¶œë ¥ ëª¨ë“œ**: int, binary, count, tf-idf
- **ëª¨ë¸ í†µí•©**: Keras ë ˆì´ì–´ë¡œ ì§ì ‘ ì—°ê²°

### ğŸ”§ ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ í•¨ìˆ˜
```python
def custom_standardization_fn(text):
    """ì»¤ìŠ¤í…€ í‘œì¤€í™” í•¨ìˆ˜"""
    lower_text = tf.strings.lower(text)
    return tf.strings.regex_replace(lower_text, f"[{re.escape(string.punctuation)}]", "")

def custom_split_fn(text):
    """ì»¤ìŠ¤í…€ í† í°í™” í•¨ìˆ˜"""
    return tf.strings.split(text)
```

### ğŸ“Š ì¶œë ¥ ëª¨ë“œ ë¹„êµ
```python
# Int ëª¨ë“œ: ì •ìˆ˜ ì‹œí€€ìŠ¤
vectorizer_int = TextVectorization(output_mode="int")

# Binary ëª¨ë“œ: ë‹¨ì–´ ì¡´ì¬ ì—¬ë¶€ (0 ë˜ëŠ” 1)
vectorizer_binary = TextVectorization(output_mode="binary")

# Count ëª¨ë“œ: ë‹¨ì–´ ë¹ˆë„ìˆ˜
vectorizer_count = TextVectorization(output_mode="count")

# TF-IDF ëª¨ë“œ: ê°€ì¤‘ì¹˜ ì ìš©
vectorizer_tfidf = TextVectorization(output_mode="tf_idf")
```

### ğŸ—ï¸ ëª¨ë¸ í†µí•© ì˜ˆì œ
```python
model = Sequential([
    text_vectorization,  # ì „ì²˜ë¦¬ ë ˆì´ì–´
    Embedding(input_dim=len(vocabulary), output_dim=16),
    LSTM(32),
    Dense(1, activation='sigmoid')
])
```

---

## IMDB ê°ì„± ë¶„ì„ í”„ë¡œì íŠ¸

### ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”
- **ë°ì´í„°ì…‹**: Stanford AI Labì˜ IMDB ì˜í™” ë¦¬ë·° (50,000ê°œ)
- **ë¬¸ì œ ìœ í˜•**: ì´ì§„ ë¶„ë¥˜ (ê¸ì •/ë¶€ì • ê°ì„± ë¶„ì„)
- **ê¸°ìˆ  ìŠ¤íƒ**: TensorFlow/Keras, TextVectorization, Dense Neural Network
- **ë²¡í„°í™” ë°©ì‹**: Multi-hot encoding (Bag of Words)

### ğŸ—‚ï¸ ë°ì´í„° êµ¬ì¡°
```
aclImdb/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ pos/          # ê¸ì • ë¦¬ë·° (12,500ê°œ)
â”‚   â””â”€â”€ neg/          # ë¶€ì • ë¦¬ë·° (12,500ê°œ)
â”œâ”€â”€ val/              # ê²€ì¦ìš© (5,000ê°œ)
â”‚   â”œâ”€â”€ pos/          
â”‚   â””â”€â”€ neg/          
â””â”€â”€ test/
    â”œâ”€â”€ pos/          # ê¸ì • ë¦¬ë·° (12,500ê°œ)
    â””â”€â”€ neg/          # ë¶€ì • ë¦¬ë·° (12,500ê°œ)
```

### ğŸ”„ ë°ì´í„° íŒŒì´í”„ë¼ì¸
1. **ë°ì´í„° ë‹¤ìš´ë¡œë“œ**: ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
2. **ì••ì¶• í•´ì œ**: tar.gz í˜•ì‹ ì•ˆì „ í•´ì œ
3. **ë°ì´í„° ë¶„í• **: train/validation ë¶„í•  (80:20 ë¹„ìœ¨)
4. **ë²¡í„°í™”**: TextVectorizationìœ¼ë¡œ multi-hot encoding
5. **ëª¨ë¸ í›ˆë ¨**: Dense ì‹ ê²½ë§ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜

### ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜
```python
def getModel(max_tokens=20000, hidden_dim=16):
    inputs = keras.Input(shape=(max_tokens,))        # ì…ë ¥ì¸µ: 20,000ì°¨ì›
    x = layers.Dense(hidden_dim, activation='relu')(inputs)  # ì€ë‹‰ì¸µ: 16ê°œ ë‰´ëŸ°
    x = layers.Dropout(0.5)(x)                       # ë“œë¡­ì•„ì›ƒ: ê³¼ì í•© ë°©ì§€
    outputs = layers.Dense(1, activation='sigmoid')(x)      # ì¶œë ¥ì¸µ: ì´ì§„ ë¶„ë¥˜
    
    model = keras.Model(inputs, outputs)
    model.compile(
        optimizer="rmsprop",
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )
    return model
```

### ğŸ“ˆ ì„±ëŠ¥ ê²°ê³¼
- **í…ŒìŠ¤íŠ¸ ì •í™•ë„**: 87.42%
- **í›ˆë ¨ ì‹œê°„**: ì•½ 30ì´ˆ (10 ì—í¬í¬)
- **ëª¨ë¸ í¬ê¸°**: 1.22MB (320,033 íŒŒë¼ë¯¸í„°)

---

## í•µì‹¬ ê°œë… ì •ë¦¬

### ğŸ¯ ì£¼ìš” ë²¡í„°í™” ê¸°ë²•

#### 1. Bag of Words (BoW)
```
"I love this movie" â†’ [0, 1, 1, 0, 1, 0, ...]
```
- **ì¥ì **: êµ¬í˜„ ê°„ë‹¨, í•´ì„ ìš©ì´
- **ë‹¨ì **: ë‹¨ì–´ ìˆœì„œ ë¬´ì‹œ, í¬ì†Œ ë²¡í„°

#### 2. TF-IDF
```
TF-IDF = TF(ë‹¨ì–´ ë¹ˆë„) Ã— IDF(ì—­ë¬¸ì„œ ë¹ˆë„)
```
- **ì¥ì **: ì¤‘ìš”í•œ ë‹¨ì–´ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
- **ë‹¨ì **: ì—¬ì „íˆ ìˆœì„œ ì •ë³´ ì—†ìŒ

#### 3. Word Embeddings
```
"king" - "man" + "woman" â‰ˆ "queen"
```
- **ì¥ì **: ì˜ë¯¸ë¡ ì  ê´€ê³„ í‘œí˜„
- **ë‹¨ì **: ì‚¬ì „ í›ˆë ¨ í•„ìš”

### ğŸ”§ ìµœì í™” ê¸°ë²•
- **ë°ì´í„° ìºì‹±**: `dataset.cache()` í™œìš©
- **ë©€í‹°í”„ë¡œì„¸ì‹±**: `num_parallel_calls=4`
- **ë°°ì¹˜ ì²˜ë¦¬**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
- **ì¡°ê¸° ì¢…ë£Œ**: ê³¼ì í•© ë°©ì§€

### ğŸ“Š ì„±ëŠ¥ í‰ê°€ ì§€í‘œ
- **ì •í™•ë„(Accuracy)**: ì „ì²´ ì˜ˆì¸¡ ì¤‘ ë§ì¶˜ ë¹„ìœ¨
- **ì†ì‹¤(Loss)**: ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼
- **ê²€ì¦ ì„±ëŠ¥**: ê³¼ì í•© ëª¨ë‹ˆí„°ë§

---

## ì‹¤ë¬´ ì ìš© ë°©ì•ˆ

### ğŸ¢ ì‚°ì—…ë³„ í™œìš© ì‚¬ë¡€

#### 1. ì „ììƒê±°ë˜
```python
# ì œí’ˆ ë¦¬ë·° ìë™ ë¶„ì„
review_sentiment = model.predict("This product is amazing!")
if review_sentiment > 0.5:
    update_product_rating(positive=True)
```

#### 2. ì†Œì…œ ë¯¸ë””ì–´ ëª¨ë‹ˆí„°ë§
```python
# ë¸Œëœë“œ ë©˜ì…˜ ê°ì„± ë¶„ì„
brand_mentions = collect_social_posts("brand_name")
sentiment_scores = model.predict(brand_mentions)
generate_sentiment_report(sentiment_scores)
```

#### 3. ê³ ê° ì„œë¹„ìŠ¤
```python
# ë¬¸ì˜ ë‚´ìš© ìš°ì„ ìˆœìœ„ ë¶„ë¥˜
inquiry_sentiment = model.predict(customer_message)
if inquiry_sentiment < 0.3:  # ë§¤ìš° ë¶€ì •ì 
    escalate_to_manager(inquiry_id)
```

### ğŸš€ í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
```
ì‚¬ìš©ì ì…ë ¥ â†’ API Gateway â†’ 
ì „ì²˜ë¦¬ ì„œë²„ â†’ ML ëª¨ë¸ ì„œë²„ â†’ 
ê²°ê³¼ ìºì‹± â†’ í´ë¼ì´ì–¸íŠ¸ ì‘ë‹µ
```

### ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ë¡œë“œë§µ

#### Phase 1: ê¸°ë³¸ ì„±ëŠ¥ í–¥ìƒ
- TF-IDF ë²¡í„°í™” ì ìš©
- N-gram í™•ì¥ (bigram, trigram)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- ì •ê·œí™” ê°•í™”

#### Phase 2: ê³ ê¸‰ ëª¨ë¸ ë„ì…
- ì„ë² ë”© ë ˆì´ì–´ í™œìš©
- ìˆœí™˜ ì‹ ê²½ë§ (RNN/LSTM)
- í•©ì„±ê³± ì‹ ê²½ë§ (CNN)
- ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜

#### Phase 3: ìµœì‹  ê¸°ë²• ì ìš©
- ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ (BERT, RoBERTa)
- ì „ì´ í•™ìŠµ í™œìš©
- ë©€í‹°ëª¨ë‹¬ ì ‘ê·¼
- ì„¤ëª… ê°€ëŠ¥í•œ AI

### ğŸ”¬ ì¶”ê°€ ì‹¤í—˜ ë°©í–¥
- **ë°ì´í„° ì¦ê°•**: ë™ì˜ì–´ ì¹˜í™˜, ë°±ë²ˆì—­
- **ì•™ìƒë¸” í•™ìŠµ**: ë‹¤ì–‘í•œ ëª¨ë¸ ì¡°í•©
- **ë„ë©”ì¸ íŠ¹í™”**: ì˜ë£Œ, ê¸ˆìœµ, ë²•ë¥  í…ìŠ¤íŠ¸
- **ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ**: ì›¹ ì¸í„°í˜ì´ìŠ¤ + API

---

## ğŸ“š ì°¸ê³  ìë£Œ

### í•µì‹¬ ë…¼ë¬¸
- Maas et al. (2011): "Learning Word Vectors for Sentiment Analysis"
- Mikolov et al. (2013): "Efficient Estimation of Word Representations"
- Vaswani et al. (2017): "Attention Is All You Need"

### ì‹¤ë¬´ ìë£Œ
- [TensorFlow Text Guide](https://www.tensorflow.org/text)
- [Hugging Face Transformers](https://huggingface.co/transformers)
- [Papers With Code NLP](https://paperswithcode.com/area/natural-language-processing)

### í•œêµ­ì–´ NLP ìë£Œ
- KoBERT, KoGPT: í•œêµ­ì–´ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸
- í•œêµ­ì–´ Embedding: FastText, Word2Vec
- í˜•íƒœì†Œ ë¶„ì„ê¸°: KoNLPy, Mecab

---

**ğŸ‰ í•™ìŠµ ì™„ë£Œ!** ìì—°ì–´ ì²˜ë¦¬ì˜ ê¸°ë³¸ ê°œë…ë¶€í„° ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬í˜„ê¹Œì§€ ì™„ì „í•œ NLP íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.