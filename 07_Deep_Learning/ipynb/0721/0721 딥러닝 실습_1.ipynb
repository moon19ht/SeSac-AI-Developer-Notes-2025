{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🧠 합성곱 신경망(CNN)을 이용한 Fashion-MNIST 분류\n",
        "\n",
        "## 📋 학습 목표\n",
        "이 노트북에서는 다음 내용을 학습합니다:\n",
        "- Fashion-MNIST 데이터셋 이해하기\n",
        "- 합성곱 신경망(CNN)의 기본 구조 학습\n",
        "- Keras를 사용한 CNN 모델 구현\n",
        "- 모델 훈련 및 성능 평가\n",
        "- 과대적합 방지 기법 적용\n",
        "\n",
        "## 📚 목차\n",
        "1. **라이브러리 임포트 및 환경 설정**\n",
        "2. **Fashion-MNIST 데이터셋 로드 및 탐색**\n",
        "3. **데이터 전처리 및 시각화**\n",
        "4. **CNN 모델 아키텍처 설계**\n",
        "5. **모델 컴파일 및 구조 확인**\n",
        "6. **모델 훈련 (Training)**\n",
        "7. **성능 평가 및 결과 분석**\n",
        "8. **모델 개선 방안 및 결론**\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 합성곱 신경망(CNN)이란?\n",
        "\n",
        "**CNN(Convolutional Neural Network)**은 이미지 처리에 특화된 딥러닝 모델입니다.\n",
        "\n",
        "### 주요 특징:\n",
        "- **합성곱층(Conv2D)**: 특징(feature) 추출\n",
        "- **풀링층(Pooling)**: 차원 축소 및 과대적합 방지\n",
        "- **완전연결층(Dense)**: 최종 분류 수행\n",
        "\n",
        "### CNN의 장점:\n",
        "- 이미지의 공간적 정보 보존\n",
        "- 매개변수 수 감소 (가중치 공유)\n",
        "- 평행이동 불변성 (Translation Invariance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 📦 라이브러리 임포트 및 환경 설정\n",
        "\n",
        "필요한 라이브러리들을 임포트하고 딥러닝 환경을 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 필수 라이브러리 임포트\n",
        "import tensorflow as tf  # type: ignore\n",
        "import keras  # type: ignore\n",
        "from keras.datasets import fashion_mnist  # type: ignore\n",
        "from keras import models, layers  # type: ignore\n",
        "import numpy as np  # type: ignore\n",
        "import matplotlib.pyplot as plt  # type: ignore\n",
        "\n",
        "# 한글 폰트 설정 (시각화용)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 텐서플로우 버전 확인\n",
        "print(f\"🔍 TensorFlow 버전: {tf.__version__}\")\n",
        "print(f\"🔍 Keras 버전: {keras.__version__}\")\n",
        "\n",
        "# GPU 사용 가능 여부 확인\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"✅ GPU 사용 가능\")\n",
        "else:\n",
        "    print(\"⚠️ CPU만 사용 가능\")\n",
        "\n",
        "# 재현 가능한 결과를 위한 시드 설정\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"🎯 환경 설정 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 👕 Fashion-MNIST 데이터셋 로드 및 탐색\n",
        "\n",
        "### Fashion-MNIST란?\n",
        "Fashion-MNIST는 Zalando의 의류 이미지 데이터셋으로, 기존 MNIST 숫자 데이터셋의 대안으로 개발되었습니다.\n",
        "\n",
        "### 데이터셋 특징:\n",
        "- **이미지 크기**: 28×28 픽셀 (그레이스케일)\n",
        "- **클래스 수**: 10개 (티셔츠, 바지, 풀오버, 드레스, 코트, 샌들, 셔츠, 스니커즈, 가방, 앵클부츠)\n",
        "- **훈련 데이터**: 60,000개\n",
        "- **테스트 데이터**: 10,000개\n",
        "\n",
        "### 클래스 레이블:\n",
        "- 0: T-shirt/top (티셔츠/탑)\n",
        "- 1: Trouser (바지)\n",
        "- 2: Pullover (풀오버)\n",
        "- 3: Dress (드레스)\n",
        "- 4: Coat (코트)\n",
        "- 5: Sandal (샌들)\n",
        "- 6: Shirt (셔츠)\n",
        "- 7: Sneaker (스니커즈)\n",
        "- 8: Bag (가방)\n",
        "- 9: Ankle boot (앵클부츠)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📁 Fashion-MNIST 데이터셋 로드\n",
        "print(\"📁 Fashion-MNIST 데이터셋 로드 중...\")\n",
        "\n",
        "# 데이터셋 로드 (자동으로 다운로드됨)\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"✅ 데이터 로드 완료!\")\n",
        "\n",
        "# 📊 데이터 형태 확인\n",
        "print(\"\\n📊 데이터셋 구조:\")\n",
        "print(f\"📈 훈련 이미지 형태: {X_train.shape}\")\n",
        "print(f\"📈 훈련 레이블 형태: {y_train.shape}\")\n",
        "print(f\"📈 테스트 이미지 형태: {X_test.shape}\")\n",
        "print(f\"📈 테스트 레이블 형태: {y_test.shape}\")\n",
        "\n",
        "# 🔍 데이터 타입 및 범위 확인\n",
        "print(f\"\\n🔍 데이터 타입: {X_train.dtype}\")\n",
        "print(f\"🔍 픽셀 값 범위: {X_train.min()} ~ {X_train.max()}\")\n",
        "print(f\"🔍 고유한 클래스 수: {len(np.unique(y_train))}\")\n",
        "print(f\"🔍 클래스 분포: {np.bincount(y_train)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 🖼️ 데이터 전처리 및 시각화\n",
        "\n",
        "CNN 모델에 데이터를 입력하기 전에 필요한 전처리 작업을 수행합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 👗 클래스 이름 정의\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# 🎨 샘플 이미지 시각화 함수\n",
        "def plot_sample_images(images, labels, class_names, num_images=10):\n",
        "    \"\"\"샘플 이미지들을 시각화하는 함수\"\"\"\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.title(f'{class_names[labels[i]]}\\\\n(Label: {labels[i]})')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 📊 샘플 이미지 출력\n",
        "print(\"🖼️ Fashion-MNIST 샘플 이미지들:\")\n",
        "plot_sample_images(X_train, y_train, class_names)\n",
        "\n",
        "# 📈 클래스별 분포 시각화\n",
        "plt.figure(figsize=(12, 6))\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(unique, counts, color='skyblue', alpha=0.7)\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Training Set - Class Distribution')\n",
        "plt.xticks(unique, [class_names[i] for i in unique], rotation=45, ha='right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(counts, labels=[class_names[i] for i in unique], autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Training Set - Class Distribution (Pie Chart)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ 각 클래스별 훈련 샘플 수: {dict(zip([class_names[i] for i in unique], counts))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 🏗️ CNN 모델 아키텍처 설계\n",
        "\n",
        "### 모델 구조 설명\n",
        "\n",
        "우리가 구축할 CNN 모델의 각 층에 대한 설명입니다:\n",
        "\n",
        "#### 1. **입력층 및 정규화**\n",
        "- `Rescaling(1./255)`: 픽셀 값을 0-1 범위로 정규화\n",
        "- 입력 형태: (28, 28, 1) - 높이, 너비, 채널\n",
        "\n",
        "#### 2. **합성곱층 (Convolutional Layers)**\n",
        "- `Conv2D(32, (3,3))`: 32개의 3×3 필터 사용\n",
        "- `Conv2D(64, (3,3))`: 64개의 3×3 필터 사용\n",
        "- 활성화 함수: ReLU\n",
        "\n",
        "#### 3. **풀링층 (Pooling Layer)**\n",
        "- `MaxPooling2D((2,2))`: 2×2 최대 풀링\n",
        "- 목적: 차원 축소 및 과대적합 방지\n",
        "\n",
        "#### 4. **평탄화층 (Flatten Layer)**\n",
        "- 4차원 텐서를 2차원으로 변환\n",
        "- CNN과 Dense 층 연결\n",
        "\n",
        "#### 5. **완전연결층 (Dense Layers)**\n",
        "- `Dense(128)`: 128개 뉴런\n",
        "- `Dense(64)`: 64개 뉴런  \n",
        "- `Dense(10, softmax)`: 10개 클래스 분류용 출력층\n",
        "\n",
        "### 모델의 매개변수 수 계산\n",
        "- **장점**: 일반적인 완전연결 신경망보다 매개변수 수가 적음\n",
        "- **이유**: 가중치 공유(weight sharing) 메커니즘\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🏗️ CNN 모델 구축\n",
        "print(\"🏗️ CNN 모델 구축 중...\")\n",
        "\n",
        "# 이미지 크기 설정\n",
        "img_height = 28\n",
        "img_width = 28\n",
        "\n",
        "# Sequential 모델 생성\n",
        "network = models.Sequential([\n",
        "    # 🔧 데이터 전처리층: 스케일링은 반드시 필요!\n",
        "    # 픽셀 값을 0-255에서 0-1 범위로 정규화\n",
        "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 1)), \n",
        "    \n",
        "    # 🧠 첫 번째 합성곱층\n",
        "    # 32개의 3x3 필터 사용 (일반적으로 많이 사용되는 크기)\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    \n",
        "    # 🧠 두 번째 합성곱층  \n",
        "    # 64개의 3x3 필터 사용 (특성 맵의 개수를 점진적으로 증가)\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    \n",
        "    # 📉 최대 풀링층: 서브샘플링으로 특성의 개수를 줄여 과대적합 방지\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # 🔄 평탄화층: CNN과 완전연결망을 연결하기 위해 4차원 → 2차원으로 변환\n",
        "    layers.Flatten(),\n",
        "    \n",
        "    # 🎯 완전연결층들\n",
        "    layers.Dense(128, activation='relu'),  # 첫 번째 은닉층\n",
        "    layers.Dense(64, activation='relu'),   # 두 번째 은닉층\n",
        "    layers.Dense(10, activation='softmax') # 출력층: 10개 클래스 분류\n",
        "])\n",
        "\n",
        "print(\"✅ 모델 구축 완료!\")\n",
        "\n",
        "# 📊 모델 구조 시각화 함수\n",
        "def visualize_model_architecture():\n",
        "    \"\"\"모델의 각 층별 출력 형태를 시각화\"\"\"\n",
        "    print(\"\\n🔍 모델 아키텍처 상세 정보:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for i, layer in enumerate(network.layers):\n",
        "        layer_type = layer.__class__.__name__\n",
        "        try:\n",
        "            output_shape = layer.output_shape\n",
        "            if hasattr(layer, 'filters'):\n",
        "                print(f\"Layer {i+1:2d}: {layer_type:15s} | Output: {str(output_shape):20s} | Filters: {layer.filters}\")\n",
        "            elif hasattr(layer, 'units'):\n",
        "                print(f\"Layer {i+1:2d}: {layer_type:15s} | Output: {str(output_shape):20s} | Units: {layer.units}\")\n",
        "            else:\n",
        "                print(f\"Layer {i+1:2d}: {layer_type:15s} | Output: {str(output_shape):20s}\")\n",
        "        except:\n",
        "            print(f\"Layer {i+1:2d}: {layer_type:15s}\")\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# 모델 아키텍처 시각화\n",
        "visualize_model_architecture()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. ⚙️ 모델 컴파일 및 구조 확인\n",
        "\n",
        "### 모델 컴파일 설정 설명\n",
        "\n",
        "#### 최적화 알고리즘 (Optimizer)\n",
        "- **Adam**: 적응적 학습률을 사용하는 고성능 최적화 알고리즘\n",
        "- 장점: 빠른 수렴, 안정적인 학습\n",
        "\n",
        "#### 손실 함수 (Loss Function)  \n",
        "- **SparseCategoricalCrossentropy**: 정수형 레이블을 위한 다중 클래스 분류 손실\n",
        "- 라벨이 원-핫 인코딩되지 않은 정수 형태일 때 사용\n",
        "\n",
        "#### 평가 지표 (Metrics)\n",
        "- **Accuracy**: 정확도 - 올바르게 분류된 샘플의 비율\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ⚙️ 모델 컴파일\n",
        "print(\"⚙️ 모델 컴파일 중...\")\n",
        "\n",
        "network.compile(\n",
        "    optimizer='adam',  # Adam 최적화 알고리즘 사용\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),  # 정수형 라벨용 손실함수\n",
        "    metrics=['accuracy']  # 정확도 측정\n",
        ")\n",
        "\n",
        "print(\"✅ 모델 컴파일 완료!\")\n",
        "\n",
        "# 📊 모델 구조 요약 출력\n",
        "print(\"\\n📋 모델 구조 요약:\")\n",
        "print(\"=\" * 70)\n",
        "network.summary()\n",
        "\n",
        "# 📈 총 매개변수 수 계산\n",
        "trainable_params = network.count_params()\n",
        "print(f\"\\n📊 총 학습 가능한 매개변수 수: {trainable_params:,}개\")\n",
        "\n",
        "# 💾 메모리 사용량 추정 (대략적)\n",
        "memory_mb = (trainable_params * 4) / (1024 * 1024)  # float32 기준\n",
        "print(f\"💾 모델 메모리 사용량 (추정): {memory_mb:.2f} MB\")\n",
        "\n",
        "print(\"\\n🎯 모델이 학습할 준비가 완료되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 🚀 모델 훈련 (Training)\n",
        "\n",
        "### 훈련 설정 설명\n",
        "\n",
        "#### 에포크 (Epochs)\n",
        "- **10 에포크**: 전체 훈련 데이터를 10번 반복 학습\n",
        "- 일반적으로 충분한 학습을 위해 선택\n",
        "\n",
        "#### 검증 분할 (Validation Split)\n",
        "- **validation_split=0.2**: 훈련 데이터의 20%를 검증용으로 사용\n",
        "- 훈련 중 과대적합 모니터링 가능\n",
        "- 실제 훈련 데이터: 48,000개 (80%)\n",
        "- 검증 데이터: 12,000개 (20%)\n",
        "\n",
        "### 훈련 과정에서 모니터링할 지표:\n",
        "- **Loss**: 손실 값 (낮을수록 좋음)\n",
        "- **Accuracy**: 정확도 (높을수록 좋음)\n",
        "- **Val_loss**: 검증 손실 (과대적합 확인용)\n",
        "- **Val_accuracy**: 검증 정확도 (일반화 성능 확인용)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 모델 훈련 시작\n",
        "print(\"🚀 모델 훈련을 시작합니다...\")\n",
        "print(\"💡 팁: 훈련 과정에서 loss는 감소하고, accuracy는 증가해야 합니다.\")\n",
        "print(\"⚠️ val_loss가 계속 증가한다면 과대적합의 신호입니다.\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 훈련 실행\n",
        "history = network.fit(\n",
        "    X_train, y_train,           # 훈련 데이터\n",
        "    epochs=10,                  # 10 에포크 동안 훈련\n",
        "    validation_split=0.2,       # 20%를 검증 데이터로 사용\n",
        "    verbose=1                   # 훈련 과정 출력\n",
        ")\n",
        "\n",
        "print(\"\\n✅ 모델 훈련 완료!\")\n",
        "\n",
        "# 📈 훈련 과정 시각화 함수\n",
        "def plot_training_history(history):\n",
        "    \"\"\"훈련 과정의 손실과 정확도를 시각화\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # 손실 그래프\n",
        "    ax1.plot(history.history['loss'], 'b-', label='Training Loss', linewidth=2)\n",
        "    ax1.plot(history.history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "    ax1.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 정확도 그래프\n",
        "    ax2.plot(history.history['accuracy'], 'b-', label='Training Accuracy', linewidth=2)\n",
        "    ax2.plot(history.history['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2)\n",
        "    ax2.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 훈련 과정 시각화\n",
        "print(\"\\n📈 훈련 과정 시각화:\")\n",
        "plot_training_history(history)\n",
        "\n",
        "# 📊 최종 훈련 결과 요약\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\n📊 최종 훈련 결과:\")\n",
        "print(f\"🔹 훈련 손실: {final_train_loss:.4f}\")\n",
        "print(f\"🔹 훈련 정확도: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "print(f\"🔹 검증 손실: {final_val_loss:.4f}\")\n",
        "print(f\"🔹 검증 정확도: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "\n",
        "# 과대적합 진단\n",
        "overfitting_check = final_val_loss > final_train_loss * 1.1\n",
        "if overfitting_check:\n",
        "    print(\"⚠️ 경고: 과대적합 가능성이 있습니다. (검증 손실 > 훈련 손실)\")\n",
        "else:\n",
        "    print(\"✅ 과대적합 없이 잘 훈련되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. 📊 성능 평가 및 결과 분석\n",
        "\n",
        "### 모델 평가의 중요성\n",
        "\n",
        "훈련된 모델의 실제 성능을 확인하기 위해 다음과 같은 평가를 수행합니다:\n",
        "\n",
        "#### 1. **훈련셋 성능**\n",
        "- 모델이 훈련 데이터에 얼마나 잘 적응했는지 확인\n",
        "- 과대적합 진단에 활용\n",
        "\n",
        "#### 2. **테스트셋 성능**\n",
        "- 실제 일반화 성능 측정\n",
        "- 새로운 데이터에 대한 예측 능력 평가\n",
        "\n",
        "#### 3. **성능 지표 해석**\n",
        "- **손실(Loss)**: 낮을수록 좋음\n",
        "- **정확도(Accuracy)**: 높을수록 좋음\n",
        "- **일반화 갭**: 훈련 정확도와 테스트 정확도의 차이\n",
        "\n",
        "### 예상 성능 범위:\n",
        "- **좋은 성능**: 테스트 정확도 85% 이상\n",
        "- **보통 성능**: 테스트 정확도 80-85%\n",
        "- **개선 필요**: 테스트 정확도 80% 미만\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 최종 성능 평가\n",
        "print(\"📊 최종 모델 성능 평가 중...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 훈련셋 성능 평가\n",
        "print(\"🔍 훈련셋 평가 중...\")\n",
        "train_loss, train_accuracy = network.evaluate(X_train, y_train, verbose=0)\n",
        "print(f\"📈 훈련셋 결과:\")\n",
        "print(f\"   손실: {train_loss:.4f}\")\n",
        "print(f\"   정확도: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 40)\n",
        "\n",
        "# 테스트셋 성능 평가\n",
        "print(\"🔍 테스트셋 평가 중...\")\n",
        "test_loss, test_accuracy = network.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"📈 테스트셋 결과:\")\n",
        "print(f\"   손실: {test_loss:.4f}\")\n",
        "print(f\"   정확도: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# 🎯 성능 분석 및 해석\n",
        "print(\"\\n🎯 성능 분석:\")\n",
        "\n",
        "# 일반화 갭 계산\n",
        "generalization_gap = train_accuracy - test_accuracy\n",
        "print(f\"📏 일반화 갭: {generalization_gap:.4f} ({generalization_gap*100:.2f}%p)\")\n",
        "\n",
        "# 성능 평가\n",
        "if test_accuracy >= 0.85:\n",
        "    performance_level = \"🏆 우수\"\n",
        "    emoji = \"🎉\"\n",
        "elif test_accuracy >= 0.80:\n",
        "    performance_level = \"✅ 양호\"\n",
        "    emoji = \"😊\"\n",
        "else:\n",
        "    performance_level = \"⚠️ 개선 필요\"\n",
        "    emoji = \"🤔\"\n",
        "\n",
        "print(f\"🏅 전체 성능 등급: {performance_level}\")\n",
        "\n",
        "# 과대적합 진단\n",
        "if generalization_gap > 0.05:  # 5% 이상 차이\n",
        "    print(\"⚠️ 과대적합 감지: 훈련 정확도가 테스트 정확도보다 5%p 이상 높습니다.\")\n",
        "    print(\"💡 개선 방안: 정규화, 드롭아웃, 조기 종료 등을 고려해보세요.\")\n",
        "elif generalization_gap < -0.02:  # 테스트가 훈련보다 2% 이상 높음\n",
        "    print(\"🤔 비정상적 패턴: 테스트 성능이 훈련 성능보다 높습니다.\")\n",
        "    print(\"💡 원인: 데이터 누수, 검증 분할 문제 등을 확인해보세요.\")\n",
        "else:\n",
        "    print(\"✅ 적절한 일반화: 과대적합 없이 잘 학습되었습니다.\")\n",
        "\n",
        "print(f\"\\n{emoji} CNN 모델의 Fashion-MNIST 분류 성능 평가가 완료되었습니다!\")\n",
        "\n",
        "# 📈 성능 비교 시각화\n",
        "def plot_performance_comparison():\n",
        "    \"\"\"훈련셋과 테스트셋 성능을 비교 시각화\"\"\"\n",
        "    categories = ['Training', 'Test']\n",
        "    accuracies = [train_accuracy, test_accuracy]\n",
        "    losses = [train_loss, test_loss]\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # 정확도 비교\n",
        "    bars1 = ax1.bar(categories, accuracies, color=['skyblue', 'lightcoral'], alpha=0.7)\n",
        "    ax1.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_ylim(0, 1)\n",
        "    \n",
        "    # 막대 위에 값 표시\n",
        "    for i, (bar, acc) in enumerate(zip(bars1, accuracies)):\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "                f'{acc:.3f}\\\\n({acc*100:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # 손실 비교\n",
        "    bars2 = ax2.bar(categories, losses, color=['lightgreen', 'lightsalmon'], alpha=0.7)\n",
        "    ax2.set_title('Loss Comparison', fontsize=14, fontweight='bold')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    \n",
        "    # 막대 위에 값 표시\n",
        "    for i, (bar, loss) in enumerate(zip(bars2, losses)):\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "                f'{loss:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n📊 성능 비교 시각화:\")\n",
        "plot_performance_comparison()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. 🚀 모델 개선 방안 및 결론\n",
        "\n",
        "### 🔧 성능 개선 방안\n",
        "\n",
        "#### 1. **모델 아키텍처 개선**\n",
        "- **더 깊은 네트워크**: 합성곱층 추가\n",
        "- **배치 정규화**: `BatchNormalization` 층 추가\n",
        "- **드롭아웃**: `Dropout` 층으로 과대적합 방지\n",
        "- **다양한 필터 크기**: 5×5, 1×1 필터 활용\n",
        "\n",
        "#### 2. **데이터 증강 (Data Augmentation)**\n",
        "```python\n",
        "# 예시: 데이터 증강 기법\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "```\n",
        "\n",
        "#### 3. **고급 최적화 기법**\n",
        "- **학습률 스케줄링**: `ReduceLROnPlateau`\n",
        "- **조기 종료**: `EarlyStopping`\n",
        "- **체크포인트**: `ModelCheckpoint`\n",
        "\n",
        "#### 4. **전이 학습 (Transfer Learning)**\n",
        "- 사전 훈련된 모델 활용\n",
        "- 예: ResNet, VGG, EfficientNet\n",
        "\n",
        "---\n",
        "\n",
        "### 📊 실습 결과 요약\n",
        "\n",
        "#### ✅ 학습한 내용:\n",
        "1. **Fashion-MNIST 데이터셋** 로드 및 탐색\n",
        "2. **CNN 모델 구조** 이해 및 구현\n",
        "3. **모델 컴파일** 및 훈련 과정\n",
        "4. **성능 평가** 및 결과 해석\n",
        "5. **과대적합 진단** 방법\n",
        "\n",
        "#### 🎯 주요 성과:\n",
        "- CNN의 기본 개념과 구조 이해\n",
        "- Keras를 이용한 실전 딥러닝 모델 구현\n",
        "- 모델 성능 평가 및 개선점 도출\n",
        "\n",
        "---\n",
        "\n",
        "### 🔮 다음 단계 학습 방향\n",
        "\n",
        "#### 1. **고급 CNN 아키텍처**\n",
        "- ResNet (잔차 네트워크)\n",
        "- DenseNet (밀집 연결 네트워크)\n",
        "- EfficientNet (효율적 네트워크)\n",
        "\n",
        "#### 2. **컴퓨터 비전 응용**\n",
        "- 객체 탐지 (Object Detection)\n",
        "- 이미지 분할 (Image Segmentation)\n",
        "- 얼굴 인식 (Face Recognition)\n",
        "\n",
        "#### 3. **실전 프로젝트**\n",
        "- 의료 이미지 분석\n",
        "- 자율주행 차량용 이미지 처리\n",
        "- 제조업 품질 검사 시스템\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 핵심 포인트\n",
        "\n",
        "1. **CNN의 핵심**: 합성곱층, 풀링층, 완전연결층의 조합\n",
        "2. **데이터 전처리**: 정규화의 중요성\n",
        "3. **성능 모니터링**: 훈련/검증 손실 추적\n",
        "4. **과대적합 방지**: 적절한 모델 복잡도 유지\n",
        "5. **지속적 개선**: 다양한 기법 실험 및 적용\n",
        "\n",
        "**🎉 축하합니다! CNN을 이용한 이미지 분류 모델을 성공적으로 구현했습니다!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
