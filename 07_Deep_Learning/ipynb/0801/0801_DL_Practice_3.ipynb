{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "# IMDB ì˜í™” ë¦¬ë·° ê°ì • ë¶„ì„ (ì„ë² ë”© ë ˆì´ì–´ + ì–‘ë°©í–¥ LSTM)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ IMDB ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” íŠ¹ì§•\n",
        "- **ë°ì´í„°**: IMDB ì˜í™” ë¦¬ë·° (ê¸ì •/ë¶€ì • ì´ì§„ ë¶„ë¥˜)\n",
        "- **ì „ì²˜ë¦¬**: í…ìŠ¤íŠ¸ ë²¡í„°í™” (ì •ìˆ˜ ì‹œí€€ìŠ¤)\n",
        "- **ì„ë² ë”©**: Keras Embedding ë ˆì´ì–´ ì‚¬ìš©\n",
        "- **ëª¨ë¸**: ì–‘ë°©í–¥ LSTM (Bidirectional LSTM)\n",
        "- **í‰ê°€**: í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€\n",
        "\n",
        "## ì›Œí¬í”Œë¡œìš°\n",
        "1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "2. ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„í• \n",
        "3. í…ìŠ¤íŠ¸ ë²¡í„°í™” (ì •ìˆ˜ ì‹œí€€ìŠ¤ ë³€í™˜)\n",
        "4. ëª¨ë¸ êµ¬ì¶• (ì„ë² ë”© + ì–‘ë°©í–¥ LSTM)\n",
        "5. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€\n",
        "\n",
        "## ì„ë² ë”© vs ì›í•« ì¸ì½”ë”©\n",
        "- **ì„ë² ë”© ë ˆì´ì–´**: í•™ìŠµ ê°€ëŠ¥í•œ ë°€ì§‘ ë²¡í„° í‘œí˜„, ë©”ëª¨ë¦¬ íš¨ìœ¨ì \n",
        "- **ì›í•« ì¸ì½”ë”©**: í¬ì†Œ ë²¡í„° í‘œí˜„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ\n",
        "- **ì„±ëŠ¥**: ì„ë² ë”©ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ì œê³µ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "\n",
        "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow ë²„ì „: 2.15.1\n",
            "Keras ë²„ì „: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import subprocess\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import os, pathlib, shutil, random\n",
        "import keras\n",
        "from keras import models, layers\n",
        "\n",
        "print(\"TensorFlow ë²„ì „:\", tf.__version__)\n",
        "print(\"Keras ë²„ì „:\", keras.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "\n",
        "IMDB ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download():\n",
        "    \"\"\"IMDB ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "    file_name = \"aclImdb_v1.tar.gz\"\n",
        "\n",
        "    print(\"IMDB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
        "    response = requests.get(url, stream=True)  # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):  # 8KBì”© ë‹¤ìš´ë¡œë“œ\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "def release():\n",
        "    \"\"\"ì••ì¶•ì„ í•´ì œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    print(\"ì••ì¶• í•´ì œ ì‹œì‘...\")\n",
        "    subprocess.run([\"tar\", \"-xvzf\", \"aclImdb_v1.tar.gz\"], shell=True)\n",
        "    # tar.gz => linuxì—ì„œëŠ” íŒŒì¼ì„ ì—¬ëŸ¬ê°œë¥¼ í•œë²ˆì— ì••ì¶•ì„ ëª»í•¨ \n",
        "    # tarë¼ëŠ” í˜•ì‹ìœ¼ë¡œ ì••ì¶•í•  ëª¨ë“  íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ íŒ¨í‚¤ì§€ë¡œ ë§Œë“ ë‹¤ìŒì— ì••ì¶•ì„ í•œë‹¤.  \n",
        "    # tar, gzê°€ë™ ê·¸ë˜ì„œ ì••ì¶•í’€ê³  ë‹¤ì‹œ íŒ¨í‚¤ì§€ë„ í’€ì–´ì•¼ í•œë‹¤. \n",
        "    # tar -xvzf íŒŒì¼ëª… í˜•íƒœì„         \n",
        "    print(\"ì••ì¶•í’€ê¸° ì™„ë£Œ\")\n",
        "\n",
        "def labeling(): \n",
        "    \"\"\"Train ë°ì´í„°ë¥¼ Trainê³¼ Validationìœ¼ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    print(\"ë°ì´í„° ë¼ë²¨ë§ ë° ë¶„í•  ì‹œì‘...\")\n",
        "    base_dir = pathlib.Path(\"aclImdb\") \n",
        "    val_dir = base_dir/\"val\"   # pathlib ê°ì²´ì— / \"ë””ë ‰í† ë¦¬\" => ê²°ê³¼ê°€ ë¬¸ìì—´ì´ ì•„ë‹ˆë‹¤ \n",
        "    train_dir = base_dir/\"train\"\n",
        "\n",
        "    # validation ë””ë ‰í† ë¦¬ ìƒì„± ë° ë°ì´í„° ë¶„í• \n",
        "    for category in (\"neg\", \"pos\"):\n",
        "        os.makedirs(val_dir/category, exist_ok=True)  # ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤ê³  \n",
        "        files = os.listdir(train_dir/category)  # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ íŒŒì¼ ëª©ë¡ì„ ëª¨ë‘ ê°€ì ¸ì˜¨ë‹¤ \n",
        "        random.Random(1337).shuffle(files)  # íŒŒì¼ì„ ëœë¤í•˜ê²Œ ì„ì–´ì„œ ë³µì‚¬í•˜ë ¤ê³  íŒŒì¼ ëª©ë¡ì„ ëª¨ë‘ ì„ëŠ”ë‹¤ \n",
        "        num_val_samples = int(0.2 * len(files))  # 20%ë¥¼ validationìœ¼ë¡œ ì‚¬ìš©\n",
        "        val_files = files[-num_val_samples:]  # 20%ë§Œ valí´ë”ë¡œ ì´ë™í•œë‹¤ \n",
        "        for fname in val_files:\n",
        "            shutil.move(train_dir/category/fname, val_dir/category/fname)\n",
        "    \n",
        "    print(\"ë°ì´í„° ë¼ë²¨ë§ ë° ë¶„í•  ì™„ë£Œ\")\n",
        "\n",
        "# ì£¼ì„ ì²˜ë¦¬: ì´ë¯¸ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•  í•„ìš” ì—†ìŒ\n",
        "# download()  # íŒŒì¼ ë‹¤ìš´ë°›ê¸° = ìš©ëŸ‰ì´ ë„ˆë¬´ ì»¤ì„œ 8192ë§Œí¼ì”© ì˜ë¼ì„œ ì €ì¥í•˜ëŠ” ì½”ë“œì„ \n",
        "# release()   # ì••ì¶• í•´ì œ\n",
        "# labeling()  # ë°ì´í„° ë¶„í• \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 3. ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "\n",
        "Kerasì˜ `text_dataset_from_directory`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¡œë¶€í„° ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "\n",
        "- **0**: ë¶€ì • ë¦¬ë·° (neg)\n",
        "- **1**: ê¸ì • ë¦¬ë·° (pos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 70000 files belonging to 3 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!\n",
            "í›ˆë ¨ ë°ì´í„°: 2188 ë°°ì¹˜\n",
            "ê²€ì¦ ë°ì´í„°: 157 ë°°ì¹˜\n",
            "í…ŒìŠ¤íŠ¸ ë°ì´í„°: 782 ë°°ì¹˜\n"
          ]
        }
      ],
      "source": [
        "# ë°°ì¹˜ í¬ê¸° ì„¤ì •\n",
        "batch_size = 32  # í•œë²ˆì— ì½ì–´ì˜¬ ì–‘ \n",
        "\n",
        "# ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"../../data/aclImdb/train\",  # ë””ë ‰í† ë¦¬ëª… \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"../../data/aclImdb/val\",  # ë””ë ‰í† ë¦¬ëª… \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"../../data/aclImdb/test\",  # ë””ë ‰í† ë¦¬ëª… \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print(\"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_ds)} ë°°ì¹˜\")\n",
        "print(f\"ê²€ì¦ ë°ì´í„°: {len(val_ds)} ë°°ì¹˜\") \n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_ds)} ë°°ì¹˜\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 3.1 ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
        "\n",
        "ë¡œë“œëœ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs.shape (32,)\n",
            "inputs.dtype <dtype: 'string'>\n",
            "targets.shape (32,)\n",
            "targets.dtype <dtype: 'int32'>\n",
            "\n",
            "=== ìƒ˜í”Œ ë°ì´í„° ===\n",
            "inputs ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):\n",
            "  1: This is one of the worst movies ever made. The first \"House\" was great. one of the first comedy/horr...\n",
            "  2: This was a pleasant surprise, much better than I anticipated. I figured Emma Thompson would be good ...\n",
            "  3: The Plot: Clive Owen ( before he was in \"The Bourne Identity,\" \"King Arthur,\" \"Elisabeth: The Golden...\n",
            "\n",
            "targets ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ): [2 2 2]\n",
            "\n",
            "=== ë¼ë²¨ ì •ë³´ ===\n",
            "0: ë¶€ì • ë¦¬ë·° (neg)\n",
            "1: ê¸ì • ë¦¬ë·° (pos)\n",
            "í´ë”ëª…ì„ ì •ë ¬í•´ì„œ 0,1,2 ì´ëŸ°ì‹ìœ¼ë¡œ ë¼ë²¨ë§ì„ í•œë‹¤ (neg -> 0, pos -> 1)\n"
          ]
        }
      ],
      "source": [
        "# ë°ì´í„°ì…‹ì€ ì•Œì•„ì„œ inputs, targetsì„ ë°˜ë³µí•´ì„œ ê°–ê³  ì˜¨ë‹¤. ìš°ë¦¬í•œí…Œ í•„ìš”í•œê±°ëŠ” inputsë§Œì´ë‹¤\n",
        "for inputs, targets in train_ds:  # ì‹¤ì œ ì½ì–´ì˜¤ëŠ” ë°ì´í„° í™•ì¸ \n",
        "    print(\"inputs.shape\", inputs.shape)\n",
        "    print(\"inputs.dtype\", inputs.dtype)\n",
        "    print(\"targets.shape\", targets.shape)\n",
        "    print(\"targets.dtype\", targets.dtype)\n",
        "    print(\"\\n=== ìƒ˜í”Œ ë°ì´í„° ===\")\n",
        "    print(\"inputs ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):\")\n",
        "    for i, text in enumerate(inputs[:3]):\n",
        "        print(f\"  {i+1}: {text.numpy().decode('utf-8')[:100]}...\")  # ì²˜ìŒ 100ìë§Œ ì¶œë ¥\n",
        "    print(f\"\\ntargets ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ): {targets[:3]}\")\n",
        "    break  # í•˜ë‚˜ë§Œ ì¶œë ¥í•´ë³´ì \n",
        "\n",
        "print(\"\\n=== ë¼ë²¨ ì •ë³´ ===\")\n",
        "print(\"0: ë¶€ì • ë¦¬ë·° (neg)\")  \n",
        "print(\"1: ê¸ì • ë¦¬ë·° (pos)\")\n",
        "print(\"í´ë”ëª…ì„ ì •ë ¬í•´ì„œ 0,1,2 ì´ëŸ°ì‹ìœ¼ë¡œ ë¼ë²¨ë§ì„ í•œë‹¤ (neg -> 0, pos -> 1)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 4. í…ìŠ¤íŠ¸ ë²¡í„°í™”\n",
        "\n",
        "í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "- **max_length**: í•œ ë¦¬ë·°ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìµœëŒ€ ë‹¨ì–´ ìˆ˜ (600)\n",
        "- **max_tokens**: ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ ê°œìˆ˜ (20000) - ì–´íœ˜ ì‚¬ì „ í¬ê¸°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 600\n",
            "ì–´íœ˜ ì‚¬ì „ í¬ê¸°: 20000\n",
            "ì¶œë ¥ ëª¨ë“œ: ì •ìˆ˜ (int)\n",
            "TextVectorization ë ˆì´ì–´ ìƒì„± ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ì‹œí€€ìŠ¤ ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "max_length = 600   # í•œ í‰ë¡ ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ëŠ” ìµœëŒ€ ê¸¸ì´ë¥¼ 600ê°œë¼ê³  ë³´ì  \n",
        "max_tokens = 20000  # ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ 20000ê°œë§Œ ì“°ê² ë‹¤ \n",
        "\n",
        "# TextVectorization ë ˆì´ì–´ ìƒì„±\n",
        "text_vectorization = TextVectorization( \n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",  # ì„ë² ë”© ì¸µì„ ì‚¬ìš©í•˜ë ¤ë©´ ë°˜ë“œì‹œ intì—¬ì•¼ í•œë‹¤\n",
        "    output_sequence_length=max_length  \n",
        ")\n",
        "\n",
        "print(f\"ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {max_length}\")\n",
        "print(f\"ì–´íœ˜ ì‚¬ì „ í¬ê¸°: {max_tokens}\")\n",
        "print(\"ì¶œë ¥ ëª¨ë“œ: ì •ìˆ˜ (int)\")\n",
        "print(\"TextVectorization ë ˆì´ì–´ ìƒì„± ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 4.1 ì–´íœ˜ì‚¬ì „ ìƒì„± ë° ë²¡í„°í™” ì ìš©\n",
        "\n",
        "í›ˆë ¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–´íœ˜ì‚¬ì „ì„ ìƒì„±í•˜ê³ , ëª¨ë“  ë°ì´í„°ì…‹ì— ë²¡í„°í™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì–´íœ˜ì‚¬ì „ ìƒì„± ì¤‘...\n",
            "ì–´íœ˜ì‚¬ì „ ìƒì„± ì™„ë£Œ!\n",
            "ë°ì´í„°ì…‹ ë²¡í„°í™” ì¤‘...\n",
            "ë°ì´í„°ì…‹ ë²¡í„°í™” ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ë¼ë²¨ ì œê±°)\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "\n",
        "# ì–´íœ˜ì‚¬ì „ ìƒì„± (í›ˆë ¨ ë°ì´í„° ê¸°ë°˜)\n",
        "print(\"ì–´íœ˜ì‚¬ì „ ìƒì„± ì¤‘...\")\n",
        "text_vectorization.adapt(text_only_train_ds)  # ì–´íœ˜ì‚¬ì „ì„ ë§Œë“¤ì–´ì•¼ í•œë‹¤ \n",
        "print(\"ì–´íœ˜ì‚¬ì „ ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "# ëª¨ë“  ë°ì´í„°ì…‹ì— ë²¡í„°í™” ì ìš©\n",
        "print(\"ë°ì´í„°ì…‹ ë²¡í„°í™” ì¤‘...\")\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y), \n",
        "    num_parallel_calls=1  # ë³‘ë ¬ ì²˜ë¦¬ (ì›ë³¸ ì½”ë“œì—ì„œëŠ” 1)\n",
        ")\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y), \n",
        "    num_parallel_calls=1\n",
        ")\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y), \n",
        "    num_parallel_calls=1\n",
        ")\n",
        "\n",
        "print(\"ë°ì´í„°ì…‹ ë²¡í„°í™” ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 4.2 ë²¡í„°í™”ëœ ë°ì´í„° í™•ì¸\n",
        "\n",
        "ë²¡í„°í™” í›„ ë°ì´í„°ì˜ ë‚´ë¶€ êµ¬ì¡°ë¥¼ í™•ì¸í•´ë´…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ë²¡í„°í™”ëœ ë°ì´í„° ë‚´ë¶€êµ¬ì¡° ì‚´í´ë³´ê¸° ===\n",
            "ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ í˜•íƒœ: (32, 600)\n",
            "ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ íƒ€ì…: <dtype: 'int64'>\n",
            "ë¼ë²¨ í˜•íƒœ: (32,)\n",
            "ë¼ë²¨ íƒ€ì…: <dtype: 'int32'>\n",
            "\n",
            "=== ìƒ˜í”Œ ë²¡í„°í™” ê²°ê³¼ ===\n",
            "ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ ë²¡í„°í™” ê²°ê³¼ (ì²˜ìŒ 20ê°œ í† í°):\n",
            "tf.Tensor(\n",
            "[  11  395    6   66   10   20 4340    3  262   11  149   26  324 1799\n",
            "   17   10   20   11   14  128], shape=(20,), dtype=int64)\n",
            "í•´ë‹¹ ë¼ë²¨: 0\n",
            "0ì´ ì•„ë‹Œ í† í° ê°œìˆ˜: 130 (ì „ì²´ 600ê°œ ì¤‘)\n"
          ]
        }
      ],
      "source": [
        "# ë²¡í„°í™”ëœ ë°ì´í„° ë‚´ë¶€êµ¬ì¡° í™•ì¸\n",
        "print(\"=== ë²¡í„°í™”ëœ ë°ì´í„° ë‚´ë¶€êµ¬ì¡° ì‚´í´ë³´ê¸° ===\")\n",
        "for item in int_train_ds:\n",
        "    vectorized_texts, labels = item\n",
        "    print(f\"ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ í˜•íƒœ: {vectorized_texts.shape}\")\n",
        "    print(f\"ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ íƒ€ì…: {vectorized_texts.dtype}\")\n",
        "    print(f\"ë¼ë²¨ í˜•íƒœ: {labels.shape}\")\n",
        "    print(f\"ë¼ë²¨ íƒ€ì…: {labels.dtype}\")\n",
        "    \n",
        "    print(\"\\n=== ìƒ˜í”Œ ë²¡í„°í™” ê²°ê³¼ ===\")\n",
        "    print(\"ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ ë²¡í„°í™” ê²°ê³¼ (ì²˜ìŒ 20ê°œ í† í°):\")\n",
        "    print(vectorized_texts[0][:20])\n",
        "    print(f\"í•´ë‹¹ ë¼ë²¨: {labels[0]}\")\n",
        "    \n",
        "    # 0ì´ íŒ¨ë”©ì„ ì˜ë¯¸í•˜ëŠ”ì§€ í™•ì¸\n",
        "    non_zero_count = tf.reduce_sum(tf.cast(vectorized_texts[0] != 0, tf.int32))\n",
        "    print(f\"0ì´ ì•„ë‹Œ í† í° ê°œìˆ˜: {non_zero_count} (ì „ì²´ {max_length}ê°œ ì¤‘)\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 5. ì„ë² ë”© ë ˆì´ì–´ì™€ ëª¨ë¸ êµ¬ì¶•\n",
        "\n",
        "### ì„ë² ë”© ë ˆì´ì–´ì˜ ì¥ì \n",
        "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ì›í•« ì¸ì½”ë”© ëŒ€ë¹„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í¬ê²Œ ê°ì†Œ\n",
        "- **í•™ìŠµ ê°€ëŠ¥**: ë‹¨ì–´ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ í•™ìŠµí•˜ì—¬ ë°€ì§‘ ë²¡í„° ìƒì„±\n",
        "- **ì„±ëŠ¥ í–¥ìƒ**: í¬ì†Œ ë²¡í„° ëŒ€ì‹  ë°€ì§‘ ë²¡í„°ë¡œ ë” ë‚˜ì€ í•™ìŠµ ì„±ê³¼\n",
        "\n",
        "### ì›í•« ì¸ì½”ë”©ì˜ ë¬¸ì œì \n",
        "- **ë©”ëª¨ë¦¬ ë‚­ë¹„**: ì–´íœ˜ í¬ê¸°ë§Œí¼ì˜ í¬ì†Œ ë²¡í„° (20000ì°¨ì›ì—ì„œ 1ê°œë§Œ 1, ë‚˜ë¨¸ì§€ëŠ” 0)\n",
        "- **í•™ìŠµ ì†ë„**: í¬ì†Œ í–‰ë ¬ë¡œ ì¸í•œ ì—°ì‚° ë¹„íš¨ìœ¨ì„±\n",
        "- **ì˜ë¯¸ í‘œí˜„**: ë‹¨ì–´ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ í‘œí˜„í•˜ì§€ ëª»í•¨\n",
        "\n",
        "### ëª¨ë¸ ì•„í‚¤í…ì²˜\n",
        "1. **ì…ë ¥**: ì •ìˆ˜ ì‹œí€€ìŠ¤ (ë°°ì¹˜_í¬ê¸°, ì‹œí€€ìŠ¤_ê¸¸ì´)\n",
        "2. **ì„ë² ë”©**: ì •ìˆ˜ë¥¼ ë°€ì§‘ ë²¡í„°ë¡œ ë³€í™˜ (ë°°ì¹˜_í¬ê¸°, ì‹œí€€ìŠ¤_ê¸¸ì´, ì„ë² ë”©_ì°¨ì›)\n",
        "3. **ì–‘ë°©í–¥ LSTM**: ì–‘ë°©í–¥ìœ¼ë¡œ ì‹œí€€ìŠ¤ ì²˜ë¦¬\n",
        "4. **ë“œë¡­ì•„ì›ƒ**: ê³¼ì í•© ë°©ì§€\n",
        "5. **ì¶œë ¥**: ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì…ë ¥ í˜•íƒœ: (None, None)\n",
            "ì„ë² ë”© í›„ í˜•íƒœ: (None, None, 256)\n",
            "ì„ë² ë”© ì„¤ì •: ì…ë ¥ ì°¨ì› 20000 -> ì¶œë ¥ ì°¨ì› 256\n",
            "ì„ë² ë”© ë ˆì´ì–´ë¥¼ í†µí•´ ì •ìˆ˜ ì‹œí€€ìŠ¤ê°€ ë°€ì§‘ ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ’¡ ì°¸ê³ : ë¯¸ë¦¬ í•™ìŠµëœ ì„ë² ë”©(Word2Vec, GloVe ë“±)ìœ¼ë¡œ ì´ˆê¸°í™” ê°€ëŠ¥\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "embedding_dim = 256  # ì„ë² ë”© ì°¨ì› (ì›ë³¸ ì½”ë“œì—ì„œ ì¶œë ¥ ì°¨ì›)\n",
        "\n",
        "# ì…ë ¥ ë ˆì´ì–´ ì •ì˜\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "print(f\"ì…ë ¥ í˜•íƒœ: {inputs.shape}\")\n",
        "\n",
        "# ì„ë² ë”© ë ˆì´ì–´\n",
        "# input_dim: ì–´íœ˜ ì‚¬ì „ í¬ê¸° (20000)\n",
        "# output_dim: ì„ë² ë”© ë²¡í„° ì°¨ì› (256)\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, \n",
        "    output_dim=embedding_dim\n",
        ")(inputs) \n",
        "\n",
        "print(f\"ì„ë² ë”© í›„ í˜•íƒœ: {embedded.shape}\")\n",
        "print(f\"ì„ë² ë”© ì„¤ì •: ì…ë ¥ ì°¨ì› {max_tokens} -> ì¶œë ¥ ì°¨ì› {embedding_dim}\")\n",
        "print(\"ì„ë² ë”© ë ˆì´ì–´ë¥¼ í†µí•´ ì •ìˆ˜ ì‹œí€€ìŠ¤ê°€ ë°€ì§‘ ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "# ë¯¸ë¦¬ í•™ìŠµëœ ì„ë² ë”©ì¸µìœ¼ë¡œ ë°”ê¿€ ìˆ˜ë„ ìˆë‹¤ëŠ” ì£¼ì„\n",
        "print(\"\\nğŸ’¡ ì°¸ê³ : ë¯¸ë¦¬ í•™ìŠµëœ ì„ë² ë”©(Word2Vec, GloVe ë“±)ìœ¼ë¡œ ì´ˆê¸°í™” ê°€ëŠ¥\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 5.1 ì–‘ë°©í–¥ LSTM ë° ì¶œë ¥ ë ˆì´ì–´ êµ¬ì„±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì–‘ë°©í–¥ LSTM ì¶”ê°€ (32 ìœ ë‹›)\n",
            "- ìˆœë°©í–¥ LSTM: ë¬¸ì¥ì˜ ì•ì—ì„œ ë’¤ë¡œ ì •ë³´ ì²˜ë¦¬\n",
            "- ì—­ë°©í–¥ LSTM: ë¬¸ì¥ì˜ ë’¤ì—ì„œ ì•ìœ¼ë¡œ ì •ë³´ ì²˜ë¦¬\n",
            "- ê²°ê³¼: ì–‘ë°©í–¥ ì •ë³´ë¥¼ ëª¨ë‘ ê³ ë ¤í•œ ë” í’ë¶€í•œ í‘œí˜„\n",
            "\n",
            "ë“œë¡­ì•„ì›ƒ ì¶”ê°€ (0.5)\n",
            "- í›ˆë ¨ ì‹œ 50% ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ ë¹„í™œì„±í™”\n",
            "- ê³¼ì í•© ë°©ì§€ ë° ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ\n",
            "\n",
            "ì¶œë ¥ ë ˆì´ì–´ ì¶”ê°€ (ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”)\n",
            "- 1ê°œ ë‰´ëŸ°: ì´ì§„ ë¶„ë¥˜ (ê¸ì •/ë¶€ì •)\n",
            "- ì‹œê·¸ëª¨ì´ë“œ: 0~1 ì‚¬ì´ í™•ë¥ ê°’ ì¶œë ¥\n"
          ]
        }
      ],
      "source": [
        "# ì–‘ë°©í–¥ LSTM ë ˆì´ì–´\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded) \n",
        "print(\"ì–‘ë°©í–¥ LSTM ì¶”ê°€ (32 ìœ ë‹›)\")\n",
        "print(\"- ìˆœë°©í–¥ LSTM: ë¬¸ì¥ì˜ ì•ì—ì„œ ë’¤ë¡œ ì •ë³´ ì²˜ë¦¬\")\n",
        "print(\"- ì—­ë°©í–¥ LSTM: ë¬¸ì¥ì˜ ë’¤ì—ì„œ ì•ìœ¼ë¡œ ì •ë³´ ì²˜ë¦¬\")\n",
        "print(\"- ê²°ê³¼: ì–‘ë°©í–¥ ì •ë³´ë¥¼ ëª¨ë‘ ê³ ë ¤í•œ ë” í’ë¶€í•œ í‘œí˜„\")\n",
        "\n",
        "# ë“œë¡­ì•„ì›ƒìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n",
        "x = layers.Dropout(0.5)(x) \n",
        "print(\"\\në“œë¡­ì•„ì›ƒ ì¶”ê°€ (0.5)\")\n",
        "print(\"- í›ˆë ¨ ì‹œ 50% ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ ë¹„í™œì„±í™”\")\n",
        "print(\"- ê³¼ì í•© ë°©ì§€ ë° ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ\")\n",
        "\n",
        "# ì¶œë ¥ ë ˆì´ì–´ (ì´ì§„ ë¶„ë¥˜)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "print(\"\\nì¶œë ¥ ë ˆì´ì–´ ì¶”ê°€ (ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”)\")\n",
        "print(\"- 1ê°œ ë‰´ëŸ°: ì´ì§„ ë¶„ë¥˜ (ê¸ì •/ë¶€ì •)\")\n",
        "print(\"- ì‹œê·¸ëª¨ì´ë“œ: 0~1 ì‚¬ì´ í™•ë¥ ê°’ ì¶œë ¥\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 5.2 ëª¨ë¸ ì»´íŒŒì¼ ë° êµ¬ì¡° í™•ì¸\n",
        "\n",
        "ëª¨ë¸ì„ ìƒì„±í•˜ê³  ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ë©”íŠ¸ë¦­ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ ===\n",
            "ì˜µí‹°ë§ˆì´ì €: RMSprop\n",
            "- í•™ìŠµë¥ ì„ ì ì‘ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €\n",
            "- RNN/LSTMì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„\n",
            "\n",
            "ì†ì‹¤ í•¨ìˆ˜: binary_crossentropy\n",
            "- ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì— ì í•©í•œ ì†ì‹¤ í•¨ìˆ˜\n",
            "- ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ë¼ë²¨ ê°„ì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°\n",
            "\n",
            "ë©”íŠ¸ë¦­: accuracy\n",
            "- ì •í™•íˆ ì˜ˆì¸¡í•œ ìƒ˜í”Œì˜ ë¹„ìœ¨\n",
            "\n",
            "=== ëª¨ë¸ êµ¬ì¡° ìš”ì•½ ===\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                73984     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5194049 (19.81 MB)\n",
            "Trainable params: 5194049 (19.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ ìƒì„±\n",
        "model = keras.Model(inputs, outputs) \n",
        "\n",
        "# ëª¨ë¸ ì»´íŒŒì¼\n",
        "model.compile(\n",
        "    optimizer='rmsprop',           # RMSprop ì˜µí‹°ë§ˆì´ì €\n",
        "    loss='binary_crossentropy',    # ì´ì§„ ë¶„ë¥˜ìš© ì†ì‹¤ í•¨ìˆ˜\n",
        "    metrics=['accuracy']           # ì •í™•ë„ ë©”íŠ¸ë¦­\n",
        ")\n",
        "\n",
        "print(\"=== ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ ===\")\n",
        "print(\"ì˜µí‹°ë§ˆì´ì €: RMSprop\")\n",
        "print(\"- í•™ìŠµë¥ ì„ ì ì‘ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €\")\n",
        "print(\"- RNN/LSTMì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„\")\n",
        "print(\"\\nì†ì‹¤ í•¨ìˆ˜: binary_crossentropy\") \n",
        "print(\"- ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì— ì í•©í•œ ì†ì‹¤ í•¨ìˆ˜\")\n",
        "print(\"- ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ë¼ë²¨ ê°„ì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°\")\n",
        "print(\"\\në©”íŠ¸ë¦­: accuracy\")\n",
        "print(\"- ì •í™•íˆ ì˜ˆì¸¡í•œ ìƒ˜í”Œì˜ ë¹„ìœ¨\")\n",
        "\n",
        "print(\"\\n=== ëª¨ë¸ êµ¬ì¡° ìš”ì•½ ===\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 6. ëª¨ë¸ í›ˆë ¨\n",
        "\n",
        "êµ¬ì¶•ëœ ëª¨ë¸ì„ í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
        "\n",
        "### í›ˆë ¨ ì„¤ì •\n",
        "- **ì—í¬í¬**: 10íšŒ\n",
        "- **ê²€ì¦ ë°ì´í„°**: val ë°ì´í„°ì…‹ ì‚¬ìš©\n",
        "- **verbose**: 1 (í›ˆë ¨ ê³¼ì • ìƒì„¸ ì¶œë ¥)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===\n",
            "ì—í¬í¬: 10\n",
            "ê²€ì¦ ë°ì´í„°: val_ds\n",
            "ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ í•™ìŠµ ì§„í–‰\n",
            "\n",
            "Epoch 1/10\n",
            "2188/2188 [==============================] - 433s 198ms/step - loss: -43.0394 - accuracy: 0.1429 - val_loss: 71.2479 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "2188/2188 [==============================] - 432s 197ms/step - loss: -119.2580 - accuracy: 0.1429 - val_loss: 137.8640 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "2188/2188 [==============================] - 437s 200ms/step - loss: -195.4292 - accuracy: 0.1429 - val_loss: 204.4876 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "2188/2188 [==============================] - 438s 200ms/step - loss: -271.6783 - accuracy: 0.1429 - val_loss: 271.0976 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "2188/2188 [==============================] - 482s 221ms/step - loss: -348.1176 - accuracy: 0.1429 - val_loss: 337.8204 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "2188/2188 [==============================] - 475s 217ms/step - loss: -424.2903 - accuracy: 0.1429 - val_loss: 404.4618 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "2188/2188 [==============================] - 571s 261ms/step - loss: -500.6432 - accuracy: 0.1429 - val_loss: 471.1760 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "2188/2188 [==============================] - 596s 272ms/step - loss: -576.7991 - accuracy: 0.1429 - val_loss: 537.9596 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "2188/2188 [==============================] - 538s 246ms/step - loss: -652.9755 - accuracy: 0.1429 - val_loss: 604.5747 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "2188/2188 [==============================] - 565s 258ms/step - loss: -729.4289 - accuracy: 0.1429 - val_loss: 671.2505 - val_accuracy: 0.5000\n",
            "=== ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ===\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ í›ˆë ¨ ì‹œì‘\n",
        "print(\"=== ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===\")\n",
        "print(\"ì—í¬í¬: 10\")\n",
        "print(\"ê²€ì¦ ë°ì´í„°: val_ds\")\n",
        "print(\"ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ í•™ìŠµ ì§„í–‰\")\n",
        "print()\n",
        "\n",
        "# í›ˆë ¨ ì‹¤í–‰\n",
        "history = model.fit(\n",
        "    int_train_ds, \n",
        "    validation_data=int_val_ds, \n",
        "    epochs=10,\n",
        "    verbose=1  # í›ˆë ¨ ê³¼ì • ì¶œë ¥\n",
        ")\n",
        "\n",
        "print(\"=== ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 7. ëª¨ë¸ í‰ê°€\n",
        "\n",
        "í›ˆë ¨ì´ ì™„ë£Œëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ìµœì¢… ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê°€ ===\n",
            "782/782 [==============================] - 47s 61ms/step - loss: 671.2538 - accuracy: 0.5000\n",
            "\n",
            "=== ìµœì¢… ê²°ê³¼ ===\n",
            "í…ŒìŠ¤íŠ¸ ì†ì‹¤: 671.2538\n",
            "í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.5000 (50.00%)\n",
            "\n",
            "=== í›ˆë ¨ ê³¼ì • ìš”ì•½ ===\n",
            "ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.1429 (14.29%)\n",
            "ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.5000 (50.00%)\n",
            "í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.5000 (50.00%)\n",
            "\n",
            "âœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
            "\n",
            "=== ê°„ë‹¨ ì¶œë ¥ (ì›ë³¸ ìŠ¤íƒ€ì¼) ===\n",
            "í…ŒìŠ¤íŠ¸ì…‹ [671.2537841796875, 0.5]\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í‰ê°€\n",
        "print(\"=== í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê°€ ===\")\n",
        "test_loss, test_accuracy = model.evaluate(int_test_ds, verbose=1)\n",
        "\n",
        "print(f\"\\n=== ìµœì¢… ê²°ê³¼ ===\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# í›ˆë ¨ íˆìŠ¤í† ë¦¬ ìš”ì•½\n",
        "if 'history' in locals():\n",
        "    final_train_acc = history.history['accuracy'][-1]\n",
        "    final_val_acc = history.history['val_accuracy'][-1]\n",
        "    \n",
        "    print(f\"\\n=== í›ˆë ¨ ê³¼ì • ìš”ì•½ ===\")\n",
        "    print(f\"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "    print(f\"ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "    \n",
        "    # ê³¼ì í•© ì—¬ë¶€ í™•ì¸\n",
        "    if final_train_acc - test_accuracy > 0.1:\n",
        "        print(\"\\nâš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "        print(\"- ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ì¦ê°€ ê³ ë ¤\")\n",
        "        print(\"- ì¡°ê¸° ì¢…ë£Œ(Early Stopping) ì ìš© ê³ ë ¤\")\n",
        "    else:\n",
        "        print(\"\\nâœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\")\n",
        "\n",
        "print(f\"\\n=== ê°„ë‹¨ ì¶œë ¥ (ì›ë³¸ ìŠ¤íƒ€ì¼) ===\")\n",
        "print(\"í…ŒìŠ¤íŠ¸ì…‹\", [test_loss, test_accuracy])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 8. ê²°ë¡  ë° ê°œì„ ì‚¬í•­\n",
        "\n",
        "### ëª¨ë¸ íŠ¹ì§•\n",
        "- **ì„ë² ë”© ë ˆì´ì–´**: ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ë°€ì§‘ ë²¡í„°ë¡œ íš¨ìœ¨ì  ë³€í™˜\n",
        "- **ì–‘ë°©í–¥ LSTM**: ë¬¸ë§¥ì„ ì–‘ë°©í–¥ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ\n",
        "- **ë“œë¡­ì•„ì›ƒ**: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì •ê·œí™”\n",
        "\n",
        "### ì„ë² ë”© ë ˆì´ì–´ì˜ ì¥ì \n",
        "1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ì›í•« ì¸ì½”ë”© ëŒ€ë¹„ í›¨ì”¬ ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©\n",
        "2. **í•™ìŠµ ê°€ëŠ¥**: ë‹¨ì–´ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµ\n",
        "3. **ì„±ëŠ¥ í–¥ìƒ**: ë°€ì§‘ ë²¡í„°ë¡œ ë” ë‚˜ì€ í‘œí˜„ë ¥ ì œê³µ\n",
        "4. **ì „ì´ í•™ìŠµ**: ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© í™œìš© ê°€ëŠ¥\n",
        "\n",
        "### ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­\n",
        "1. **ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©**: Word2Vec, GloVe, FastText ë“± í™œìš©\n",
        "2. **ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**: LSTMì— ì–´í…ì…˜ ì¶”ê°€ë¡œ ì¤‘ìš”í•œ ë¶€ë¶„ì— ì§‘ì¤‘\n",
        "3. **Transformer ëª¨ë¸**: BERT, RoBERTa ë“± ìµœì‹  ëª¨ë¸ í™œìš©\n",
        "4. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: \n",
        "   - ì„ë² ë”© ì°¨ì› ì¡°ì •\n",
        "   - LSTM ìœ ë‹› ìˆ˜ ìµœì í™”\n",
        "   - ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ì¡°ì •\n",
        "   - í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§\n",
        "5. **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©\n",
        "6. **ë°ì´í„° ì¦ê°•**: í…ìŠ¤íŠ¸ ì¦ê°• ê¸°ë²• ì ìš©\n",
        "\n",
        "### ì„ë² ë”© vs ì›í•« ì¸ì½”ë”© ë¹„êµ\n",
        "\n",
        "| íŠ¹ì„± | ì„ë² ë”© ë ˆì´ì–´ | ì›í•« ì¸ì½”ë”© |\n",
        "|------|---------------|-------------|\n",
        "| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ì ìŒ (ì°¨ì›Ã—ì–´íœ˜í¬ê¸°) | ë§ìŒ (ì–´íœ˜í¬ê¸°Ã—ì‹œí€€ìŠ¤ê¸¸ì´) |\n",
        "| í•™ìŠµ ì†ë„ | ë¹ ë¦„ | ëŠë¦¼ |\n",
        "| ì˜ë¯¸ í‘œí˜„ | ìš°ìˆ˜ (ë‹¨ì–´ ê°„ ê´€ê³„ í•™ìŠµ) | ì œí•œì  |\n",
        "| ì´ˆê¸°í™” | ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ í™œìš© ê°€ëŠ¥ | ê³ ì •ëœ í‘œí˜„ |\n",
        "| ê¶Œì¥ ì‚¬ìš© | âœ… ëŒ€ë¶€ë¶„ì˜ ê²½ìš° | íŠ¹ìˆ˜í•œ ì‹¤í—˜ ëª©ì  |\n",
        "\n",
        "### ì‹¤ì œ ì ìš© ì‹œ ê³ ë ¤ì‚¬í•­\n",
        "- **ì¶”ë¡  ì†ë„**: ì„ë² ë”© ë ˆì´ì–´ê°€ ì›í•« ì¸ì½”ë”©ë³´ë‹¤ ë¹ ë¦„\n",
        "- **ëª¨ë¸ í¬ê¸°**: ì„ë² ë”© ê°€ì¤‘ì¹˜ ë§¤íŠ¸ë¦­ìŠ¤ í¬ê¸° ê³ ë ¤\n",
        "- **ë„ë©”ì¸ íŠ¹í™”**: íŠ¹ì • ë„ë©”ì¸ ë°ì´í„°ë¡œ ì„ë² ë”© íŒŒì¸íŠœë‹\n",
        "- **ë‹¤êµ­ì–´ ì§€ì›**: ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ í™œìš©\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
