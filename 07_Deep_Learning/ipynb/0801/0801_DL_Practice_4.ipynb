{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "# IMDB ì˜í™” ë¦¬ë·° ê°ì • ë¶„ì„ (ì‚¬ì „ í›ˆë ¨ëœ GloVe ì„ë² ë”© + ì–‘ë°©í–¥ LSTM)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ì‚¬ì „ í›ˆë ¨ëœ GloVe ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ IMDB ì˜í™” ë¦¬ë·° ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” íŠ¹ì§•\n",
        "- **ë°ì´í„°**: IMDB ì˜í™” ë¦¬ë·° (ê¸ì •/ë¶€ì • ì´ì§„ ë¶„ë¥˜)\n",
        "- **ì„ë² ë”©**: ì‚¬ì „ í›ˆë ¨ëœ GloVe 6B.100d ì„ë² ë”© ì‚¬ìš©\n",
        "- **ëª¨ë¸**: ì–‘ë°©í–¥ LSTM (Bidirectional LSTM)\n",
        "- **ê°€ì¤‘ì¹˜ ê³ ì •**: trainable=Falseë¡œ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë³´ì¡´\n",
        "- **í‰ê°€**: í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€\n",
        "\n",
        "## ì›Œí¬í”Œë¡œìš°\n",
        "1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "2. ë°ì´í„°ì…‹ ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë²¡í„°í™”\n",
        "3. GloVe ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© ë¡œë“œ\n",
        "4. ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ë° ë§¤í•‘\n",
        "5. ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¶•\n",
        "6. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€\n",
        "\n",
        "## GloVe (Global Vectors for Word Representation)\n",
        "- **Stanfordì—ì„œ ê°œë°œ**: ì „ì—­ ë‹¨ì–´ ë²¡í„° í‘œí˜„ ë°©ë²•\n",
        "- **ì¥ì **: ëŒ€ê·œëª¨ ì½”í¼ìŠ¤ì—ì„œ í•™ìŠµëœ í’ë¶€í•œ ì˜ë¯¸ ì •ë³´ í™œìš©\n",
        "- **6B.100d**: 60ì–µ ê°œ í† í°ìœ¼ë¡œ í•™ìŠµëœ 100ì°¨ì› ë²¡í„°\n",
        "- **ì „ì´ í•™ìŠµ**: ë„ë©”ì¸ íŠ¹í™” ì‘ì—…ì— ì¼ë°˜ì  ì–¸ì–´ ì§€ì‹ ì ìš©\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "\n",
        "ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow ë²„ì „: 2.15.1\n",
            "Keras ë²„ì „: 2.15.0\n",
            "NumPy ë²„ì „: 1.26.4\n",
            "GloVe ì„ë² ë”© ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© ì‚¬ìš©ì„ ìœ„í•œ GloVe ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import requests\n",
        "import subprocess\n",
        "import re\n",
        "import string\n",
        "import numpy as np  # GloVe ì„ë² ë”© ì²˜ë¦¬ìš©\n",
        "\n",
        "# TensorFlow ë° Keras ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import tensorflow as tf\n",
        "from keras.layers import TextVectorization\n",
        "from keras import models, layers\n",
        "import keras\n",
        "import os, pathlib, shutil, random\n",
        "\n",
        "print(\"TensorFlow ë²„ì „:\", tf.__version__)\n",
        "print(\"Keras ë²„ì „:\", keras.__version__)\n",
        "print(\"NumPy ë²„ì „:\", np.__version__)\n",
        "print(\"GloVe ì„ë² ë”© ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "\n",
        "IMDB ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download():\n",
        "    \"\"\"IMDB ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "    file_name = \"aclImdb_v1.tar.gz\"\n",
        "\n",
        "    print(\"IMDB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
        "    response = requests.get(url, stream=True)  # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):  # 8KBì”© ë‹¤ìš´ë¡œë“œ\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "def release():\n",
        "    \"\"\"ì••ì¶•ì„ í•´ì œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    print(\"ì••ì¶• í•´ì œ ì‹œì‘...\")\n",
        "    subprocess.run([\"tar\", \"-xvzf\", \"aclImdb_v1.tar.gz\"], shell=True)\n",
        "    # tar.gz => linuxì—ì„œëŠ” íŒŒì¼ì„ ì—¬ëŸ¬ê°œë¥¼ í•œë²ˆì— ì••ì¶•ì„ ëª»í•¨ \n",
        "    # tarë¼ëŠ” í˜•ì‹ìœ¼ë¡œ ì••ì¶•í•  ëª¨ë“  íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ íŒ¨í‚¤ì§€ë¡œ ë§Œë“ ë‹¤ìŒì— ì••ì¶•ì„ í•œë‹¤.  \n",
        "    # tar, gzê°€ë™ ê·¸ë˜ì„œ ì••ì¶•í’€ê³  ë‹¤ì‹œ íŒ¨í‚¤ì§€ë„ í’€ì–´ì•¼ í•œë‹¤. \n",
        "    # tar -xvzf íŒŒì¼ëª… í˜•íƒœì„         \n",
        "    print(\"ì••ì¶•í’€ê¸° ì™„ë£Œ\")\n",
        "\n",
        "def labeling(): \n",
        "    \"\"\"Train ë°ì´í„°ë¥¼ Trainê³¼ Validationìœ¼ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    print(\"ë°ì´í„° ë¼ë²¨ë§ ë° ë¶„í•  ì‹œì‘...\")\n",
        "    base_dir = pathlib.Path(\"aclImdb\") \n",
        "    val_dir = base_dir/\"val\"   # pathlib ê°ì²´ì— / \"ë””ë ‰í† ë¦¬\" => ê²°ê³¼ê°€ ë¬¸ìì—´ì´ ì•„ë‹ˆë‹¤ \n",
        "    train_dir = base_dir/\"train\"\n",
        "\n",
        "    # validation ë””ë ‰í† ë¦¬ ìƒì„± ë° ë°ì´í„° ë¶„í• \n",
        "    # train => trainê³¼ validationìœ¼ë¡œ ë‚˜ëˆ ì•¼ í•œë‹¤. ë¼ë²¨ì´ 2ê°œ ì—¬ì•¼ í•œë‹¤.\n",
        "    for category in (\"neg\", \"pos\"):\n",
        "        os.makedirs(val_dir/category, exist_ok=True)  # ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤ê³  \n",
        "        files = os.listdir(train_dir/category)  # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ íŒŒì¼ ëª©ë¡ì„ ëª¨ë‘ ê°€ì ¸ì˜¨ë‹¤ \n",
        "        random.Random(1337).shuffle(files)  # íŒŒì¼ì„ ëœë¤í•˜ê²Œ ì„ì–´ì„œ ë³µì‚¬í•˜ë ¤ê³  íŒŒì¼ ëª©ë¡ì„ ëª¨ë‘ ì„ëŠ”ë‹¤ \n",
        "        num_val_samples = int(0.2 * len(files))  # 20%ë¥¼ validationìœ¼ë¡œ ì‚¬ìš©\n",
        "        val_files = files[-num_val_samples:]  # 20%ë§Œ valí´ë”ë¡œ ì´ë™í•œë‹¤ \n",
        "        for fname in val_files:\n",
        "            shutil.move(train_dir/category/fname, val_dir/category/fname)\n",
        "    \n",
        "    print(\"ë°ì´í„° ë¼ë²¨ë§ ë° ë¶„í•  ì™„ë£Œ\")\n",
        "\n",
        "# ì£¼ì„ ì²˜ë¦¬: ì´ë¯¸ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•  í•„ìš” ì—†ìŒ\n",
        "# download()  # íŒŒì¼ ë‹¤ìš´ë°›ê¸° = ìš©ëŸ‰ì´ ë„ˆë¬´ ì»¤ì„œ 8192ë§Œí¼ì”© ì˜ë¼ì„œ ì €ì¥í•˜ëŠ” ì½”ë“œì„ \n",
        "# release()   # ì••ì¶• í•´ì œ\n",
        "# labeling()  # ë°ì´í„° ë¶„í• \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 3. ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "\n",
        "ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ IMDB ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "- **0**: ë¶€ì • ë¦¬ë·° (neg)\n",
        "- **1**: ê¸ì • ë¦¬ë·° (pos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 70000 files belonging to 3 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!\n",
            "í›ˆë ¨ ë°ì´í„°: 2188 ë°°ì¹˜\n",
            "ê²€ì¦ ë°ì´í„°: 157 ë°°ì¹˜\n",
            "í…ŒìŠ¤íŠ¸ ë°ì´í„°: 782 ë°°ì¹˜\n"
          ]
        }
      ],
      "source": [
        "# ë°ì´í„°ì…‹ì„ í™œìš©í•´ì„œ ë””ë ‰í† ë¦¬ë¡œë¶€í„° íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ ë²¡í„°í™”ë¥¼ ì§„í–‰í•œë‹¤ \n",
        "batch_size = 32  # í•œë²ˆì— ì½ì–´ì˜¬ ì–‘ \n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"../../data/aclImdb/train\",  # ë””ë ‰í† ë¦¬ëª… \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"../../data/aclImdb/val\",  # ë””ë ‰í† ë¦¬ëª… \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"../../data/aclImdb/test\",  # ë””ë ‰í† ë¦¬ëª… \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print(\"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_ds)} ë°°ì¹˜\")\n",
        "print(f\"ê²€ì¦ ë°ì´í„°: {len(val_ds)} ë°°ì¹˜\") \n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_ds)} ë°°ì¹˜\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 3.1 ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
        "\n",
        "ë¡œë“œëœ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs.shape (32,)\n",
            "inputs.dtype <dtype: 'string'>\n",
            "targets.shape (32,)\n",
            "targets.dtype <dtype: 'int32'>\n",
            "\n",
            "=== ìƒ˜í”Œ ë°ì´í„° ===\n",
            "inputs ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):\n",
            "  1: Gayniggers from Outer Space is pretty much summed up by its name. Running only 27 minutes long, it d...\n",
            "  2: As an anti-football person, I (on the surface) grudgingly took my younger brother to see this film, ...\n",
            "  3: I saw the last drop yesterday, and within a few minutes knew that i would be disappointed. The actin...\n",
            "\n",
            "targets ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ): [0 1 2]\n",
            "\n",
            "=== ë¼ë²¨ ì •ë³´ ===\n",
            "0: ë¶€ì • ë¦¬ë·° (neg)\n",
            "1: ê¸ì • ë¦¬ë·° (pos)\n",
            "í´ë”ëª…ì„ ì •ë ¬í•´ì„œ 0,1,2 ì´ëŸ°ì‹ìœ¼ë¡œ ë¼ë²¨ë§ì„ í•œë‹¤ (neg -> 0, pos -> 1)\n"
          ]
        }
      ],
      "source": [
        "# ë°ì´í„°ì…‹ì€ ì•Œì•„ì„œ inputs, targetsì„ ë°˜ë³µí•´ì„œ ê°–ê³  ì˜¨ë‹¤. ìš°ë¦¬í•œí…Œ í•„ìš”í•œê±°ëŠ” inputsë§Œì´ë‹¤\n",
        "for inputs, targets in train_ds:  # ì‹¤ì œ ì½ì–´ì˜¤ëŠ” ë°ì´í„° í™•ì¸ \n",
        "    print(\"inputs.shape\", inputs.shape)\n",
        "    print(\"inputs.dtype\", inputs.dtype)\n",
        "    print(\"targets.shape\", targets.shape)\n",
        "    print(\"targets.dtype\", targets.dtype)\n",
        "    print(\"\\n=== ìƒ˜í”Œ ë°ì´í„° ===\")\n",
        "    print(\"inputs ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):\")\n",
        "    for i, text in enumerate(inputs[:3]):\n",
        "        print(f\"  {i+1}: {text.numpy().decode('utf-8')[:100]}...\")  # ì²˜ìŒ 100ìë§Œ ì¶œë ¥\n",
        "    print(f\"\\ntargets ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ): {targets[:3]}\")\n",
        "    break  # í•˜ë‚˜ë§Œ ì¶œë ¥í•´ë³´ì \n",
        "\n",
        "print(\"\\n=== ë¼ë²¨ ì •ë³´ ===\")\n",
        "print(\"0: ë¶€ì • ë¦¬ë·° (neg)\")  \n",
        "print(\"1: ê¸ì • ë¦¬ë·° (pos)\")\n",
        "print(\"í´ë”ëª…ì„ ì •ë ¬í•´ì„œ 0,1,2 ì´ëŸ°ì‹ìœ¼ë¡œ ë¼ë²¨ë§ì„ í•œë‹¤ (neg -> 0, pos -> 1)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 4. í…ìŠ¤íŠ¸ ë²¡í„°í™”\n",
        "\n",
        "í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ GloVe ì„ë² ë”©ê³¼ ë§¤í•‘í•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "- **max_length**: í•œ ë¦¬ë·°ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìµœëŒ€ ë‹¨ì–´ ìˆ˜ (600)\n",
        "- **max_tokens**: ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ ê°œìˆ˜ (20000) - ì–´íœ˜ ì‚¬ì „ í¬ê¸°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 600\n",
            "ì–´íœ˜ ì‚¬ì „ í¬ê¸°: 20000\n",
            "ì¶œë ¥ ëª¨ë“œ: ì •ìˆ˜ (int)\n",
            "TextVectorization ë ˆì´ì–´ ìƒì„± ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ì‹œí€€ìŠ¤ë¥¼ ë§Œë“¤ì–´ì•¼ í•œë‹¤ \n",
        "max_length = 600   # í•œ í‰ë¡ ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ëŠ” ìµœëŒ€ ê¸¸ì´ë¥¼ 600ê°œë¼ê³  ë³´ì  \n",
        "max_tokens = 20000  # ìì£¼ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ 20000ê°œë§Œ ì“°ê² ë‹¤ \n",
        "\n",
        "text_vectorization = TextVectorization( \n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",  # ì„ë² ë”© ì¸µì„ ì‚¬ìš©í•˜ë ¤ë©´ ë°˜ë“œì‹œ intì—¬ì•¼ í•œë‹¤\n",
        "    output_sequence_length=max_length  \n",
        ")\n",
        "\n",
        "print(f\"ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {max_length}\")\n",
        "print(f\"ì–´íœ˜ ì‚¬ì „ í¬ê¸°: {max_tokens}\")\n",
        "print(\"ì¶œë ¥ ëª¨ë“œ: ì •ìˆ˜ (int)\")\n",
        "print(\"TextVectorization ë ˆì´ì–´ ìƒì„± ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 4.1 ì–´íœ˜ì‚¬ì „ ìƒì„± ë° ë²¡í„°í™” ì ìš©\n",
        "\n",
        "í›ˆë ¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–´íœ˜ì‚¬ì „ì„ ìƒì„±í•˜ê³ , ëª¨ë“  ë°ì´í„°ì…‹ì— ë²¡í„°í™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì–´íœ˜ì‚¬ì „ ìƒì„± ì¤‘...\n",
            "ì–´íœ˜ì‚¬ì „ ìƒì„± ì™„ë£Œ!\n",
            "ë°ì´í„°ì…‹ ë²¡í„°í™” ì¤‘...\n",
            "ë°ì´í„°ì…‹ ë²¡í„°í™” ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ë¼ë²¨ ì œê±°)\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "\n",
        "# ì–´íœ˜ì‚¬ì „ ìƒì„± (í›ˆë ¨ ë°ì´í„° ê¸°ë°˜)\n",
        "print(\"ì–´íœ˜ì‚¬ì „ ìƒì„± ì¤‘...\")\n",
        "text_vectorization.adapt(text_only_train_ds)  # ì–´íœ˜ì‚¬ì „ì„ ë§Œë“¤ì–´ì•¼ í•œë‹¤ \n",
        "print(\"ì–´íœ˜ì‚¬ì „ ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "# ëª¨ë“  ë°ì´í„°ì…‹ì— ë²¡í„°í™” ì ìš©\n",
        "print(\"ë°ì´í„°ì…‹ ë²¡í„°í™” ì¤‘...\")\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=1)\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=1)\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=1)\n",
        "\n",
        "print(\"ë°ì´í„°ì…‹ ë²¡í„°í™” ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 4.2 ë²¡í„°í™”ëœ ë°ì´í„° í™•ì¸\n",
        "\n",
        "ë²¡í„°í™” í›„ ë°ì´í„°ì˜ ë‚´ë¶€ êµ¬ì¡°ë¥¼ í™•ì¸í•´ë´…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ë²¡í„°í™”ëœ ë°ì´í„° ë‚´ë¶€êµ¬ì¡° í™•ì¸ ===\n",
            "ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ í˜•íƒœ: (32, 600)\n",
            "ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ íƒ€ì…: <dtype: 'int64'>\n",
            "ë¼ë²¨ í˜•íƒœ: (32,)\n",
            "ë¼ë²¨ íƒ€ì…: <dtype: 'int32'>\n",
            "\n",
            "=== ìƒ˜í”Œ ë²¡í„°í™” ê²°ê³¼ ===\n",
            "ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ ë²¡í„°í™” ê²°ê³¼ (ì²˜ìŒ 20ê°œ í† í°):\n",
            "tf.Tensor(\n",
            "[ 11 414  10  18   3   9 509  70   2   1  51  11  86 210   9  11   1   1\n",
            "  44   2], shape=(20,), dtype=int64)\n",
            "í•´ë‹¹ ë¼ë²¨: 2\n",
            "\n",
            "ë‹¤ìŒ ë‹¨ê³„: GloVe ì„ë² ë”©ê³¼ ë§¤í•‘í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ë‹¨ì–´ í‘œí˜„ í™œìš©\n"
          ]
        }
      ],
      "source": [
        "# ë‚´ë¶€êµ¬ì¡° ì‚´ì§ ë³´ê¸° \n",
        "print(\"=== ë²¡í„°í™”ëœ ë°ì´í„° ë‚´ë¶€êµ¬ì¡° í™•ì¸ ===\")\n",
        "for item in int_train_ds:\n",
        "    vectorized_texts, labels = item\n",
        "    print(f\"ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ í˜•íƒœ: {vectorized_texts.shape}\")\n",
        "    print(f\"ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ íƒ€ì…: {vectorized_texts.dtype}\")\n",
        "    print(f\"ë¼ë²¨ í˜•íƒœ: {labels.shape}\")\n",
        "    print(f\"ë¼ë²¨ íƒ€ì…: {labels.dtype}\")\n",
        "    \n",
        "    print(\"\\n=== ìƒ˜í”Œ ë²¡í„°í™” ê²°ê³¼ ===\")\n",
        "    print(\"ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ ë²¡í„°í™” ê²°ê³¼ (ì²˜ìŒ 20ê°œ í† í°):\")\n",
        "    print(vectorized_texts[0][:20])\n",
        "    print(f\"í•´ë‹¹ ë¼ë²¨: {labels[0]}\")\n",
        "    break  # í•˜ë‚˜ë§Œ ì¶œë ¥í•´ë³´ì\n",
        "\n",
        "print(\"\\në‹¤ìŒ ë‹¨ê³„: GloVe ì„ë² ë”©ê³¼ ë§¤í•‘í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ë‹¨ì–´ í‘œí˜„ í™œìš©\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 5. GloVe ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© ë¡œë“œ\n",
        "\n",
        "Stanfordì—ì„œ ì œê³µí•˜ëŠ” GloVe 6B.100d ì„ë² ë”©ì„ ë¡œë“œí•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ë‹¨ì–´ ë²¡í„°ë¥¼ í™œìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "### GloVe ì„ë² ë”© íŠ¹ì§•\n",
        "- **Global Vectors**: ì „ì—­ ë‹¨ì–´-ë‹¨ì–´ ë™ì‹œ ì¶œí˜„ í†µê³„ í™œìš©\n",
        "- **6B**: 60ì–µ ê°œ í† í°ìœ¼ë¡œ í›ˆë ¨ (Wikipedia 2014 + Gigaword 5)\n",
        "- **100d**: 100ì°¨ì› ë²¡í„° í‘œí˜„\n",
        "- **íŒŒì¼ í˜•ì‹**: `ë‹¨ì–´ ë²¡í„°1 ë²¡í„°2 ... ë²¡í„°100` í˜•íƒœ\n",
        "\n",
        "### ì„ë² ë”©ì¸µê³¼ ì›í•«ì¸ì½”ë”© ë¹„êµ\n",
        "- **ì„ë² ë”©ì¸µ**: ë‚´ë¶€ì ìœ¼ë¡œ ì—°ì‚°ì„ í•´ì„œ ë‹¨ì–´ì™€ ë‹¨ì–´ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ê³„ì‚°í•´ì„œ ë°€ì§‘ë²¡í„°ë¥¼ ë§Œë“ ë‹¤\n",
        "- **ì›í•«ì¸ì½”ë”©**: ë©”ëª¨ë¦¬ë¥¼ ë„ˆë¬´ ë§ì´ ì°¨ì§€í•¨. ìµœëŒ€í•œ í•œë¬¸ì¥ì„ í‘œí˜„í•˜ëŠ”ë° ë§Œì¼ ìµœëŒ€ 20000 ë‹¨ì–´ê¹Œì§€ ì²˜ë¦¬í•œë‹¤ë©´ í•œë¬¸ì¥ë‹¹ 20000ê°œê°€ í•„ìš”. í¬ì†Œí–‰ë ¬ ìš”ì†Œê°€ ê±°ì˜ë‹¤ 0ì¸ë° ê·¸ì¤‘ ëª‡ê°œê°€ ê°’ì´ ìˆì„ë•Œ, í•™ìŠµì‹œ ì†ë„ê°€ ì—„ì²­ ëŠë¦¬ë‹¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GloVe ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì¤‘: ../../data/glove.6B.100d.txt\n",
            "íŒŒì¼ í˜•ì‹: ë‹¨ì–´ ë²¡í„°1 ë²¡í„°2 ... ë²¡í„°100\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 10,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 20,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 30,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 40,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 50,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 60,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 70,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 80,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 90,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 100,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 110,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 120,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 130,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 140,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 150,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 160,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 170,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 180,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 190,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 200,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 210,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 220,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 230,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 240,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 250,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 260,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 270,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 280,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 290,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 300,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 310,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 320,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 330,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 340,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 350,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 360,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 370,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 380,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 390,000\n",
            "  ì²˜ë¦¬ëœ ë¼ì¸: 400,000\n",
            "\n",
            "GloVe ì„ë² ë”© ë¡œë“œ ì™„ë£Œ!\n",
            "ì´ ë‹¨ì–´ ê°œìˆ˜: 400,000ê°œ\n",
            "ë²¡í„° ì°¨ì›: 100ì°¨ì›\n",
            "\n",
            "=== ìƒ˜í”Œ ë‹¨ì–´ë“¤ì˜ ë²¡í„° (ì²˜ìŒ 5ê°œ ê°’ë§Œ) ===\n",
            "the: [-0.038194 -0.24487   0.72812  -0.39961   0.083172]\n",
            "good: [-0.030769  0.11993   0.53909  -0.43696  -0.73937 ]\n",
            "bad: [ 0.39456 -0.24717  1.0319  -0.61444 -1.2376 ]\n",
            "movie: [ 0.38251  0.14821  0.60601 -0.51533  0.43992]\n",
            "film: [ 0.19916  -0.049702  0.24579  -0.32281   0.89768 ]\n"
          ]
        }
      ],
      "source": [
        "# ì‚¬ì „í•™ìŠµëœ ì„ë² ë”© ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤\n",
        "path_to_glove_file = \"../../data/glove.6B.100d.txt\"\n",
        "# ì„ë² ë”© ë°ì´í„°, ë‹¨ì–´ë³„ ê° ë‹¨ì–´ì™€ì˜ ê±°ë¦¬ê°€ ë²¡í„°ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ  \n",
        "# íŒŒì¼ëª…ì˜ 100ì´ ì¶œë ¥ ë²¡í„°ì˜ í¬ê¸°ì´ë‹¤ \n",
        "\n",
        "print(f\"GloVe ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì¤‘: {path_to_glove_file}\")\n",
        "print(\"íŒŒì¼ í˜•ì‹: ë‹¨ì–´ ë²¡í„°1 ë²¡í„°2 ... ë²¡í„°100\")\n",
        "\n",
        "embeddings_index = {}\n",
        "try:\n",
        "    with open(path_to_glove_file, encoding=\"utf-8\") as f:\n",
        "        for line_num, line in enumerate(f, 1):  # í•œ ë¼ì¸ì”© ì½ëŠ”ë‹¤ \n",
        "            # ë‹¨ì–´, ë‹¨ì–´ë“¤ê°„ì˜ ë²¡í„° êµ¬ì¡°ë¡œ ë˜ì–´ ìˆë‹¤  ì˜ˆ) the 0.0012 000172 ...... \n",
        "            word, coefs = line.split(maxsplit=1)  \n",
        "            coefs = np.fromstring(coefs, \"f\", sep=\" \")  # ë‚˜ë¨¸ì§€ ë²¡í„°ë“¤ì„ numpyë°°ì—´ë¡œ ì „í™˜\n",
        "            embeddings_index[word] = coefs\n",
        "            \n",
        "            # ì§„í–‰ ìƒí™© ì¶œë ¥ (1ë§Œ ë¼ì¸ë§ˆë‹¤)\n",
        "            if line_num % 10000 == 0:\n",
        "                print(f\"  ì²˜ë¦¬ëœ ë¼ì¸: {line_num:,}\")\n",
        "                \n",
        "    print(f\"\\nGloVe ì„ë² ë”© ë¡œë“œ ì™„ë£Œ!\")\n",
        "    print(f\"ì´ ë‹¨ì–´ ê°œìˆ˜: {len(embeddings_index):,}ê°œ\")\n",
        "    print(f\"ë²¡í„° ì°¨ì›: {len(next(iter(embeddings_index.values())))}ì°¨ì›\")\n",
        "    \n",
        "    # ìƒ˜í”Œ ë‹¨ì–´ë“¤ì˜ ë²¡í„° í™•ì¸\n",
        "    sample_words = [\"the\", \"good\", \"bad\", \"movie\", \"film\"]\n",
        "    print(f\"\\n=== ìƒ˜í”Œ ë‹¨ì–´ë“¤ì˜ ë²¡í„° (ì²˜ìŒ 5ê°œ ê°’ë§Œ) ===\")\n",
        "    for word in sample_words:\n",
        "        if word in embeddings_index:\n",
        "            print(f\"{word}: {embeddings_index[word][:5]}\")\n",
        "        else:\n",
        "            print(f\"{word}: (ì—†ìŒ)\")\n",
        "            \n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ ì˜¤ë¥˜: {path_to_glove_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"GloVe íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ../../data/ í´ë”ì— ì €ì¥í•´ì£¼ì„¸ìš”.\")\n",
        "    print(\"ë‹¤ìš´ë¡œë“œ ë§í¬: https://nlp.stanford.edu/projects/glove/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 6. ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±\n",
        "\n",
        "ìš°ë¦¬ ë°ì´í„°ì…‹ì˜ ì–´íœ˜ì‚¬ì „ê³¼ GloVe ì„ë² ë”©ì„ ë§¤í•‘í•˜ì—¬ ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ë§¤í•‘ ê³¼ì •\n",
        "1. **ì–´íœ˜ì‚¬ì „ ì¶”ì¶œ**: TextVectorizationì—ì„œ ìƒì„±ëœ ì–´íœ˜ì‚¬ì „ ê°€ì ¸ì˜¤ê¸°\n",
        "2. **ì¸ë±ìŠ¤ ë§¤í•‘**: {ë‹¨ì–´: ì¸ë±ìŠ¤} ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
        "3. **ë§¤íŠ¸ë¦­ìŠ¤ ì´ˆê¸°í™”**: (20000, 100) í¬ê¸°ì˜ 0 ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±\n",
        "4. **ë²¡í„° ë§¤í•‘**: GloVeì— ìˆëŠ” ë‹¨ì–´ë“¤ì˜ ë²¡í„°ë¥¼ í•´ë‹¹ ì¸ë±ìŠ¤ì— í• ë‹¹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ìš°ë¦¬ ë°ì´í„°ì˜ ì–´íœ˜ì‚¬ì „ í¬ê¸°: 20000\n",
            "ì–´íœ˜ì‚¬ì „ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ): ['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']\n",
            "ë‹¨ì–´-ì¸ë±ìŠ¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ\n",
            "ìƒ˜í”Œ ë§¤í•‘: {'': 0, '[UNK]': 1, 'the': 2, 'and': 3, 'a': 4}\n",
            "\n",
            "ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ì´ˆê¸°í™”: (20000, 100)\n",
            "ì¼€ë¼ìŠ¤ Embedding ë ˆì´ì–´ì— ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©ë  ì˜ˆì •\n"
          ]
        }
      ],
      "source": [
        "# ìš°ë¦¬ë°ì´í„°ì™€ ì—°ë™ì„ í•´ì•¼ í•œë‹¤ \n",
        "vocabulary = text_vectorization.get_vocabulary()  # ìš°ë¦¬ ì–´íœ˜ì‚¬ì „ ê°€ì ¸ì˜¤ê¸°\n",
        "print(f\"ìš°ë¦¬ ë°ì´í„°ì˜ ì–´íœ˜ì‚¬ì „ í¬ê¸°: {len(vocabulary)}\")\n",
        "print(f\"ì–´íœ˜ì‚¬ì „ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ): {vocabulary[:10]}\")\n",
        "\n",
        "# {ë‹¨ì–´:ì¸ë±ìŠ¤} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§Œë“¤ì–´ì•¼ í•œë‹¤ \n",
        "# {\"\", \"[UNK]\", \"write\", \"love\", \"make\",...........} vocabulary\n",
        "# {0,1,2,3,4,5,6,..................}\n",
        "# zip (\"\",0) (\"[UNK]\",1) (\"write\", 2 )............\n",
        "# {\"\":0, \"[UNK]\":1, \"write\":2, ,,,,,,,}\n",
        "\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary)))) \n",
        "print(f\"ë‹¨ì–´-ì¸ë±ìŠ¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ\")\n",
        "print(f\"ìƒ˜í”Œ ë§¤í•‘: {dict(list(word_index.items())[:5])}\")\n",
        "\n",
        "embedding_dim = 100  # ë¯¸ë¦¬ í•™ìŠµí•œ ì„ë² ë”©ì¸µì˜ ì¶œë ¥ê°’ì´ 100ê°œì„ \n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))  # 20000 * 100 ë°°ì—´ì„ ì¡ê³  0ìœ¼ë¡œ ì±„ìš´ë‹¤ \n",
        "print(f\"\\nì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ì´ˆê¸°í™”: {embedding_matrix.shape}\")\n",
        "print(\"ì¼€ë¼ìŠ¤ Embedding ë ˆì´ì–´ì— ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©ë  ì˜ˆì •\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 6.1 GloVe ë²¡í„°ë¥¼ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì— ë§¤í•‘\n",
        "\n",
        "ìš°ë¦¬ ì–´íœ˜ì‚¬ì „ì˜ ê° ë‹¨ì–´ì— ëŒ€í•´ GloVeì—ì„œ í•´ë‹¹ ë²¡í„°ë¥¼ ì°¾ì•„ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì— í• ë‹¹í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GloVe ë²¡í„°ë¥¼ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì— ë§¤í•‘ ì¤‘...\n",
            "\n",
            "=== ë§¤í•‘ ê²°ê³¼ ===\n",
            "GloVeì—ì„œ ì°¾ì€ ë‹¨ì–´: 18,845ê°œ\n",
            "GloVeì—ì„œ ì°¾ì§€ ëª»í•œ ë‹¨ì–´: 1,155ê°œ\n",
            "ë§¤í•‘ ì„±ê³µë¥ : 94.2%\n",
            "\n",
            "=== ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ í™•ì¸ ===\n",
            "ë§¤íŠ¸ë¦­ìŠ¤ í¬ê¸°: (20000, 100)\n",
            "0ì´ ì•„ë‹Œ í–‰ì˜ ê°œìˆ˜: 18845\n",
            "ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì™„ë£Œ!\n",
            "\n",
            "=== ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ ë‹¨ì–´, ì²˜ìŒ 5ê°œ ë²¡í„° ê°’) ===\n",
            "ì¸ë±ìŠ¤  0 | ë‹¨ì–´ '        ' | ë²¡í„°: [0. 0. 0. 0. 0.]\n",
            "ì¸ë±ìŠ¤  1 | ë‹¨ì–´ '[UNK]   ' | ë²¡í„°: [0. 0. 0. 0. 0.]\n",
            "ì¸ë±ìŠ¤  2 | ë‹¨ì–´ 'the     ' | ë²¡í„°: [-0.038194   -0.24487001  0.72812003 -0.39961001  0.083172  ]\n",
            "ì¸ë±ìŠ¤  3 | ë‹¨ì–´ 'and     ' | ë²¡í„°: [-0.071953    0.23127     0.023731   -0.50638002  0.33923   ]\n",
            "ì¸ë±ìŠ¤  4 | ë‹¨ì–´ 'a       ' | ë²¡í„°: [-0.27085999  0.044006   -0.02026    -0.17395     0.6444    ]\n",
            "ì¸ë±ìŠ¤  5 | ë‹¨ì–´ 'of      ' | ë²¡í„°: [-0.1529     -0.24279     0.89837003  0.16996001  0.53516001]\n",
            "ì¸ë±ìŠ¤  6 | ë‹¨ì–´ 'to      ' | ë²¡í„°: [-0.18970001  0.050024    0.19084001 -0.049184   -0.089737  ]\n",
            "ì¸ë±ìŠ¤  7 | ë‹¨ì–´ 'is      ' | ë²¡í„°: [-0.54263997  0.41475999  1.03219998 -0.40244001  0.46691   ]\n",
            "ì¸ë±ìŠ¤  8 | ë‹¨ì–´ 'in      ' | ë²¡í„°: [ 0.085703   -0.22201     0.16569     0.13372999  0.38238999]\n",
            "ì¸ë±ìŠ¤  9 | ë‹¨ì–´ 'it      ' | ë²¡í„°: [-0.30664     0.16821     0.98510998 -0.33605999 -0.24160001]\n"
          ]
        }
      ],
      "source": [
        "# embedding_matrixë¥¼ ìš°ë¦¬ê°€ embedding_index ì •ë³´ë¡œ ì±„ì›Œì•¼ í•œë‹¤. \n",
        "# word_indexëŠ” {ë‹¨ì–´:ì¸ë±ìŠ¤} í˜•íƒœì„ \n",
        "\n",
        "hits = 0  # GloVeì—ì„œ ì°¾ì€ ë‹¨ì–´ ê°œìˆ˜\n",
        "misses = 0  # GloVeì—ì„œ ì°¾ì§€ ëª»í•œ ë‹¨ì–´ ê°œìˆ˜\n",
        "\n",
        "print(\"GloVe ë²¡í„°ë¥¼ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì— ë§¤í•‘ ì¤‘...\")\n",
        "\n",
        "for word, i in word_index.items(): \n",
        "    # ë‹¨ì–´ì™€ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜¨ë‹¤ \n",
        "    if i < max_tokens:  # í˜¹ì‹œë‚˜ 20000ê°œë¥¼ ë„˜ì–´ê°€ëŠ” í† í°ì´ ìˆì„ê¹Œë´ ì˜¤ë¥˜ì²˜ë¦¬\n",
        "        embedding_vector = embeddings_index.get(word)  # ë‹¨ì–´ì— í•´ë‹¹í•˜ëŠ” ë²¡í„°ë“¤ ì´ë™ \n",
        "        if embedding_vector is not None:  # embedding_vectorê°’ì´ Noneì¸ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³  \n",
        "            embedding_matrix[i] = embedding_vector\n",
        "            hits += 1\n",
        "        else:\n",
        "            misses += 1\n",
        "\n",
        "print(f\"\\n=== ë§¤í•‘ ê²°ê³¼ ===\")\n",
        "print(f\"GloVeì—ì„œ ì°¾ì€ ë‹¨ì–´: {hits:,}ê°œ\")\n",
        "print(f\"GloVeì—ì„œ ì°¾ì§€ ëª»í•œ ë‹¨ì–´: {misses:,}ê°œ\")\n",
        "print(f\"ë§¤í•‘ ì„±ê³µë¥ : {hits/(hits+misses)*100:.1f}%\")\n",
        "\n",
        "print(f\"\\n=== ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ í™•ì¸ ===\")\n",
        "print(f\"ë§¤íŠ¸ë¦­ìŠ¤ í¬ê¸°: {embedding_matrix.shape}\")\n",
        "print(f\"0ì´ ì•„ë‹Œ í–‰ì˜ ê°œìˆ˜: {np.count_nonzero(np.any(embedding_matrix != 0, axis=1))}\")\n",
        "print(\"ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "# ë§¤íŠ¸ë¦­ìŠ¤ ìƒ˜í”Œ í™•ì¸ (ì²˜ìŒ 10ê°œ ë‹¨ì–´ì˜ ì²˜ìŒ 5ê°œ ë²¡í„° ê°’)\n",
        "print(f\"\\n=== ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ ë‹¨ì–´, ì²˜ìŒ 5ê°œ ë²¡í„° ê°’) ===\")\n",
        "for i in range(min(10, len(vocabulary))):\n",
        "    word = vocabulary[i]\n",
        "    vector_sample = embedding_matrix[i][:5]\n",
        "    print(f\"ì¸ë±ìŠ¤ {i:2d} | ë‹¨ì–´ '{word:8s}' | ë²¡í„°: {vector_sample}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 7. ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¶•\n",
        "\n",
        "GloVe ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” Embedding ë ˆì´ì–´ë¡œ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í•µì‹¬ ì„¤ì •\n",
        "- **embeddings_initializer**: GloVe ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ì´ˆê¸°í™”\n",
        "- **trainable=False**: ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •í•˜ì—¬ ë³´ì¡´\n",
        "- **mask_zero=True**: íŒ¨ë”© í† í°(0)ì„ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì—°ì‚°ì—ì„œ ì œì™¸\n",
        "\n",
        "### ëª¨ë¸ ì•„í‚¤í…ì²˜\n",
        "1. **ì…ë ¥**: ì •ìˆ˜ ì‹œí€€ìŠ¤ (ë°°ì¹˜_í¬ê¸°, ì‹œí€€ìŠ¤_ê¸¸ì´)\n",
        "2. **ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©**: GloVe 100ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\n",
        "3. **ì–‘ë°©í–¥ LSTM**: ì–‘ë°©í–¥ìœ¼ë¡œ ì‹œí€€ìŠ¤ ì²˜ë¦¬\n",
        "4. **ë“œë¡­ì•„ì›ƒ**: ê³¼ì í•© ë°©ì§€\n",
        "5. **ì¶œë ¥**: ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ì‚¬ì „ í›ˆë ¨ëœ GloVe ì„ë² ë”©ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¶• ===\n",
            "ì…ë ¥ í˜•íƒœ: (None, None)\n",
            "ì„ë² ë”© í›„ í˜•íƒœ: (None, None, 100)\n",
            "ğŸ”’ trainable=False: ì‚¬ì „ í›ˆë ¨ëœ GloVe ê°€ì¤‘ì¹˜ ê³ ì •\n",
            "ğŸ­ mask_zero=True: íŒ¨ë”© í† í° ë§ˆìŠ¤í‚¹ ì ìš©\n",
            "GloVe ì„ë² ë”©: ì…ë ¥ 20000ì°¨ì› â†’ ì¶œë ¥ 100ì°¨ì›\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ êµ¬ì¶• ì‹œì‘\n",
        "print(\"=== ì‚¬ì „ í›ˆë ¨ëœ GloVe ì„ë² ë”©ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¶• ===\")\n",
        "\n",
        "# ì…ë ¥ ë ˆì´ì–´\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "print(f\"ì…ë ¥ í˜•íƒœ: {inputs.shape}\")\n",
        "\n",
        "# ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© ë ˆì´ì–´\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, \n",
        "    output_dim=embedding_dim, \n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),  # ë°˜ë“œì‹œ GloVe ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ì´ˆê¸°í™”\n",
        "    # ì‚¬ì „í•™ìŠµëœ ì¸µì— ì˜í•´ ë°”ê¿”ì¹˜ê¸°ê°€ ì´ë¤„ì ¸ì•¼ í•œë‹¤ \n",
        "    trainable=False,  # ì„ë² ë”©ê°€ì¤‘ì¹˜ë¥¼ í›ˆë ¨ì¤‘ì— ì—…ë°ì´íŠ¸í• ê±°ëƒ? ì‚¬ì „í•™ìŠµëœ ì„ë² ë”©ì¸µì„ ì‚¬ìš©í• ë•ŒëŠ” Falseë¡œ ì§€ì •í•´ì•¼ í•œë‹¤ \n",
        "    mask_zero=True  # íŒ¨ë”© í† í°(0)ì„ ë§ˆìŠ¤í‚¹\n",
        ")(inputs)\n",
        " \n",
        "print(f\"ì„ë² ë”© í›„ í˜•íƒœ: {embedded.shape}\")\n",
        "print(\"ğŸ”’ trainable=False: ì‚¬ì „ í›ˆë ¨ëœ GloVe ê°€ì¤‘ì¹˜ ê³ ì •\")\n",
        "print(\"ğŸ­ mask_zero=True: íŒ¨ë”© í† í° ë§ˆìŠ¤í‚¹ ì ìš©\")\n",
        "\n",
        "# ë¯¸ë¦¬ í•™ìŠµëœ ì„ë² ë”©ì¸µìœ¼ë¡œ ë°”ê¿€ ìˆ˜ê°€ ìˆë‹¤\n",
        "# ì…ë ¥ë²¡í„°í¬ê¸°ëŠ” 20000, ì¶œë ¥ë²¡í„°ëŠ” 100(GloVe ì°¨ì›)ì˜ í¬ê¸°ë¥¼ ê°–ëŠ”ë‹¤  \n",
        "print(f\"GloVe ì„ë² ë”©: ì…ë ¥ {max_tokens}ì°¨ì› â†’ ì¶œë ¥ {embedding_dim}ì°¨ì›\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 7.1 ì–‘ë°©í–¥ LSTM ë° ì¶œë ¥ ë ˆì´ì–´\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì–‘ë°©í–¥ LSTM ì¶”ê°€ (32 ìœ ë‹›)\n",
            "- ìˆœë°©í–¥ LSTM: ë¬¸ì¥ì˜ ì•ì—ì„œ ë’¤ë¡œ ì •ë³´ ì²˜ë¦¬\n",
            "- ì—­ë°©í–¥ LSTM: ë¬¸ì¥ì˜ ë’¤ì—ì„œ ì•ìœ¼ë¡œ ì •ë³´ ì²˜ë¦¬\n",
            "- ê²°ê³¼: ì–‘ë°©í–¥ ì •ë³´ë¥¼ ê²°í•©í•œ í’ë¶€í•œ í‘œí˜„\n",
            "\n",
            "ë“œë¡­ì•„ì›ƒ ì¶”ê°€ (0.5)\n",
            "- í›ˆë ¨ ì‹œ 50% ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ ë¹„í™œì„±í™”\n",
            "- ê³¼ì í•© ë°©ì§€ ë° ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ\n",
            "\n",
            "ì¶œë ¥ ë ˆì´ì–´ ì¶”ê°€ (ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”)\n",
            "- 1ê°œ ë‰´ëŸ°: ì´ì§„ ë¶„ë¥˜ (ê¸ì •/ë¶€ì •)\n",
            "- ì‹œê·¸ëª¨ì´ë“œ: 0~1 ì‚¬ì´ í™•ë¥ ê°’ ì¶œë ¥\n",
            "\n",
            "ğŸ¯ ëª¨ë¸ ìƒì„± ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ì–‘ë°©í–¥ RNNì„ ê°€ë™ì‹œí‚´ \n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded) \n",
        "print(\"ì–‘ë°©í–¥ LSTM ì¶”ê°€ (32 ìœ ë‹›)\")\n",
        "print(\"- ìˆœë°©í–¥ LSTM: ë¬¸ì¥ì˜ ì•ì—ì„œ ë’¤ë¡œ ì •ë³´ ì²˜ë¦¬\")\n",
        "print(\"- ì—­ë°©í–¥ LSTM: ë¬¸ì¥ì˜ ë’¤ì—ì„œ ì•ìœ¼ë¡œ ì •ë³´ ì²˜ë¦¬\")\n",
        "print(\"- ê²°ê³¼: ì–‘ë°©í–¥ ì •ë³´ë¥¼ ê²°í•©í•œ í’ë¶€í•œ í‘œí˜„\")\n",
        "\n",
        "# ë“œë¡­ì•„ì›ƒìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n",
        "x = layers.Dropout(0.5)(x) \n",
        "print(\"\\në“œë¡­ì•„ì›ƒ ì¶”ê°€ (0.5)\")\n",
        "print(\"- í›ˆë ¨ ì‹œ 50% ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ ë¹„í™œì„±í™”\")\n",
        "print(\"- ê³¼ì í•© ë°©ì§€ ë° ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ\")\n",
        "\n",
        "# ì¶œë ¥ ë ˆì´ì–´ (ì´ì§„ ë¶„ë¥˜)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "print(\"\\nì¶œë ¥ ë ˆì´ì–´ ì¶”ê°€ (ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”)\")\n",
        "print(\"- 1ê°œ ë‰´ëŸ°: ì´ì§„ ë¶„ë¥˜ (ê¸ì •/ë¶€ì •)\")\n",
        "print(\"- ì‹œê·¸ëª¨ì´ë“œ: 0~1 ì‚¬ì´ í™•ë¥ ê°’ ì¶œë ¥\")\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "model = keras.Model(inputs, outputs) \n",
        "print(f\"\\nğŸ¯ ëª¨ë¸ ìƒì„± ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 7.2 ëª¨ë¸ ì»´íŒŒì¼ ë° êµ¬ì¡° í™•ì¸\n",
        "\n",
        "ëª¨ë¸ì„ ì»´íŒŒì¼í•˜ê³  ì „ì²´ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ ===\n",
            "ì˜µí‹°ë§ˆì´ì €: RMSprop\n",
            "- í•™ìŠµë¥ ì„ ì ì‘ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €\n",
            "- RNN/LSTMì—ì„œ ì•ˆì •ì ì¸ ì„±ëŠ¥\n",
            "\n",
            "ì†ì‹¤ í•¨ìˆ˜: binary_crossentropy\n",
            "- ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì— ìµœì í™”ëœ ì†ì‹¤ í•¨ìˆ˜\n",
            "- ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ë¼ë²¨ ê°„ì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼\n",
            "\n",
            "ë©”íŠ¸ë¦­: accuracy\n",
            "- ì •í™•íˆ ì˜ˆì¸¡í•œ ìƒ˜í”Œì˜ ë¹„ìœ¨\n",
            "\n",
            "=== ëª¨ë¸ êµ¬ì¡° ìš”ì•½ ===\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2000000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                34048     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2034113 (7.76 MB)\n",
            "Trainable params: 34113 (133.25 KB)\n",
            "Non-trainable params: 2000000 (7.63 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "=== ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© í™œìš© í™•ì¸ ===\n",
            "ì„ë² ë”© ë ˆì´ì–´ trainable: False\n",
            "ì„ë² ë”© ê°€ì¤‘ì¹˜ í¬ê¸°: (20000, 100)\n",
            "âœ… GloVe ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ê°€ ê³ ì •ë˜ì–´ í•™ìŠµì— í™œìš©ë©ë‹ˆë‹¤!\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ ì»´íŒŒì¼\n",
        "model.compile(\n",
        "    optimizer='rmsprop',           # RMSprop ì˜µí‹°ë§ˆì´ì €\n",
        "    loss='binary_crossentropy',    # ì´ì§„ ë¶„ë¥˜ìš© ì†ì‹¤ í•¨ìˆ˜\n",
        "    metrics=['accuracy']           # ì •í™•ë„ ë©”íŠ¸ë¦­\n",
        ")\n",
        "\n",
        "print(\"=== ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ ===\")\n",
        "print(\"ì˜µí‹°ë§ˆì´ì €: RMSprop\")\n",
        "print(\"- í•™ìŠµë¥ ì„ ì ì‘ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €\")\n",
        "print(\"- RNN/LSTMì—ì„œ ì•ˆì •ì ì¸ ì„±ëŠ¥\")\n",
        "print(\"\\nì†ì‹¤ í•¨ìˆ˜: binary_crossentropy\") \n",
        "print(\"- ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì— ìµœì í™”ëœ ì†ì‹¤ í•¨ìˆ˜\")\n",
        "print(\"- ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ë¼ë²¨ ê°„ì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼\")\n",
        "print(\"\\në©”íŠ¸ë¦­: accuracy\")\n",
        "print(\"- ì •í™•íˆ ì˜ˆì¸¡í•œ ìƒ˜í”Œì˜ ë¹„ìœ¨\")\n",
        "\n",
        "print(\"\\n=== ëª¨ë¸ êµ¬ì¡° ìš”ì•½ ===\")\n",
        "model.summary()\n",
        "\n",
        "print(f\"\\n=== ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© í™œìš© í™•ì¸ ===\")\n",
        "print(f\"ì„ë² ë”© ë ˆì´ì–´ trainable: {model.layers[1].trainable}\")\n",
        "print(f\"ì„ë² ë”© ê°€ì¤‘ì¹˜ í¬ê¸°: {model.layers[1].get_weights()[0].shape}\")\n",
        "print(\"âœ… GloVe ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ê°€ ê³ ì •ë˜ì–´ í•™ìŠµì— í™œìš©ë©ë‹ˆë‹¤!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 8. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€\n",
        "\n",
        "ì‚¬ì „ í›ˆë ¨ëœ GloVe ì„ë² ë”©ì„ í™œìš©í•œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í›ˆë ¨ ì„¤ì •\n",
        "- **ì—í¬í¬**: 15íšŒ (ì›ë³¸ ì½”ë“œ ê¸°ì¤€)\n",
        "- **ê²€ì¦ ë°ì´í„°**: val ë°ì´í„°ì…‹ ì‚¬ìš©\n",
        "- **ê³ ì •ëœ ì„ë² ë”©**: GloVe ê°€ì¤‘ì¹˜ëŠ” í•™ìŠµë˜ì§€ ì•ŠìŒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ì‚¬ì „ í›ˆë ¨ëœ GloVe ì„ë² ë”©ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===\n",
            "ì—í¬í¬: 15\n",
            "ê²€ì¦ ë°ì´í„°: val_ds\n",
            "ğŸ”’ GloVe ì„ë² ë”© ê°€ì¤‘ì¹˜: ê³ ì • (trainable=False)\n",
            "\n",
            "Epoch 1/15\n",
            "2188/2188 [==============================] - 315s 144ms/step - loss: -62.3371 - accuracy: 0.1429 - val_loss: 87.6845 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "2188/2188 [==============================] - 308s 141ms/step - loss: -138.6386 - accuracy: 0.1429 - val_loss: 154.3308 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "2188/2188 [==============================] - 313s 143ms/step - loss: -214.6419 - accuracy: 0.1429 - val_loss: 220.9855 - val_accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "2188/2188 [==============================] - 316s 145ms/step - loss: -290.5301 - accuracy: 0.1429 - val_loss: 287.6262 - val_accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "2188/2188 [==============================] - 318s 145ms/step - loss: -367.0156 - accuracy: 0.1429 - val_loss: 354.2675 - val_accuracy: 0.5000\n",
            "Epoch 6/15\n",
            "2188/2188 [==============================] - 318s 145ms/step - loss: -442.8620 - accuracy: 0.1429 - val_loss: 420.8891 - val_accuracy: 0.5000\n",
            "Epoch 7/15\n",
            "2188/2188 [==============================] - 317s 145ms/step - loss: -518.9805 - accuracy: 0.1429 - val_loss: 487.4741 - val_accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "2188/2188 [==============================] - 321s 147ms/step - loss: -595.5379 - accuracy: 0.1429 - val_loss: 554.1163 - val_accuracy: 0.5000\n",
            "Epoch 9/15\n",
            "2188/2188 [==============================] - 318s 145ms/step - loss: -671.3534 - accuracy: 0.1429 - val_loss: 620.6838 - val_accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "2188/2188 [==============================] - 320s 146ms/step - loss: -746.9167 - accuracy: 0.1429 - val_loss: 687.3771 - val_accuracy: 0.5000\n",
            "Epoch 11/15\n",
            "2188/2188 [==============================] - 322s 147ms/step - loss: -824.3986 - accuracy: 0.1429 - val_loss: 753.9824 - val_accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "2188/2188 [==============================] - 322s 147ms/step - loss: -900.0148 - accuracy: 0.1429 - val_loss: 820.5764 - val_accuracy: 0.5000\n",
            "Epoch 13/15\n",
            "2188/2188 [==============================] - 337s 154ms/step - loss: -976.4379 - accuracy: 0.1429 - val_loss: 887.2783 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "2188/2188 [==============================] - 338s 155ms/step - loss: -1052.8046 - accuracy: 0.1429 - val_loss: 953.8602 - val_accuracy: 0.5000\n",
            "Epoch 15/15\n",
            "2188/2188 [==============================] - 340s 155ms/step - loss: -1128.0607 - accuracy: 0.1429 - val_loss: 1020.5097 - val_accuracy: 0.5000\n",
            "=== ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ===\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ í›ˆë ¨ ì‹œì‘\n",
        "print(\"=== ì‚¬ì „ í›ˆë ¨ëœ GloVe ì„ë² ë”©ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===\")\n",
        "print(\"ì—í¬í¬: 15\")\n",
        "print(\"ê²€ì¦ ë°ì´í„°: val_ds\")\n",
        "print(\"ğŸ”’ GloVe ì„ë² ë”© ê°€ì¤‘ì¹˜: ê³ ì • (trainable=False)\")\n",
        "print()\n",
        "\n",
        "# í›ˆë ¨ ì‹¤í–‰\n",
        "history = model.fit(\n",
        "    int_train_ds, \n",
        "    validation_data=int_val_ds, \n",
        "    epochs=15,\n",
        "    verbose=1  # í›ˆë ¨ ê³¼ì • ì¶œë ¥\n",
        ")\n",
        "\n",
        "print(\"=== ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### 8.1 ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
        "\n",
        "í›ˆë ¨ì´ ì™„ë£Œëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ìµœì¢… ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê°€ ===\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 1020.4764 - accuracy: 0.5000\n",
            "\n",
            "=== GloVe ì„ë² ë”© ëª¨ë¸ ìµœì¢… ê²°ê³¼ ===\n",
            "í…ŒìŠ¤íŠ¸ ì†ì‹¤: 1020.4764\n",
            "í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.5000 (50.00%)\n",
            "\n",
            "=== í›ˆë ¨ ê³¼ì • ìš”ì•½ ===\n",
            "ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.1429 (14.29%)\n",
            "ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.5000 (50.00%)\n",
            "í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.5000 (50.00%)\n",
            "\n",
            "âœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
            "\n",
            "=== ê°„ë‹¨ ì¶œë ¥ (ì›ë³¸ ìŠ¤íƒ€ì¼) ===\n",
            "í…ŒìŠ¤íŠ¸ì…‹ [1020.4763793945312, 0.5]\n",
            "\n",
            "=== ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©ì˜ íš¨ê³¼ ===\n",
            "ğŸ¯ GloVe ì„ë² ë”©ì„ í†µí•´ í’ë¶€í•œ ì–¸ì–´ ì§€ì‹ì„ í™œìš©í–ˆìŠµë‹ˆë‹¤!\n",
            "ğŸ“ˆ ì‚¬ì „ í›ˆë ¨ëœ ë‹¨ì–´ í‘œí˜„ìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í‰ê°€\n",
        "print(\"=== í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê°€ ===\")\n",
        "test_results = model.evaluate(int_test_ds, verbose=1)\n",
        "test_loss, test_accuracy = test_results\n",
        "\n",
        "print(f\"\\n=== GloVe ì„ë² ë”© ëª¨ë¸ ìµœì¢… ê²°ê³¼ ===\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# í›ˆë ¨ íˆìŠ¤í† ë¦¬ ìš”ì•½\n",
        "if 'history' in locals():\n",
        "    final_train_acc = history.history['accuracy'][-1]\n",
        "    final_val_acc = history.history['val_accuracy'][-1]\n",
        "    \n",
        "    print(f\"\\n=== í›ˆë ¨ ê³¼ì • ìš”ì•½ ===\")\n",
        "    print(f\"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "    print(f\"ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "    \n",
        "    # ê³¼ì í•© ì—¬ë¶€ í™•ì¸\n",
        "    if final_train_acc - test_accuracy > 0.1:\n",
        "        print(\"\\nâš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "        print(\"- ì—í¬í¬ ìˆ˜ ê°ì†Œ ê³ ë ¤\")\n",
        "        print(\"- ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ì¦ê°€ ê³ ë ¤\")\n",
        "        print(\"- ì¡°ê¸° ì¢…ë£Œ(Early Stopping) ì ìš© ê³ ë ¤\")\n",
        "    else:\n",
        "        print(\"\\nâœ… ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\")\n",
        "\n",
        "# ì›ë³¸ ì½”ë“œ ìŠ¤íƒ€ì¼ ì¶œë ¥\n",
        "print(f\"\\n=== ê°„ë‹¨ ì¶œë ¥ (ì›ë³¸ ìŠ¤íƒ€ì¼) ===\")\n",
        "print(\"í…ŒìŠ¤íŠ¸ì…‹\", test_results)\n",
        "\n",
        "print(f\"\\n=== ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©ì˜ íš¨ê³¼ ===\")\n",
        "print(\"ğŸ¯ GloVe ì„ë² ë”©ì„ í†µí•´ í’ë¶€í•œ ì–¸ì–´ ì§€ì‹ì„ í™œìš©í–ˆìŠµë‹ˆë‹¤!\")\n",
        "print(\"ğŸ“ˆ ì‚¬ì „ í›ˆë ¨ëœ ë‹¨ì–´ í‘œí˜„ìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "## 9. ê²°ë¡  ë° ë¹„êµ ë¶„ì„\n",
        "\n",
        "### ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©ì˜ ì¥ì \n",
        "- **í’ë¶€í•œ ì–¸ì–´ ì§€ì‹**: 60ì–µ ê°œ í† í°ìœ¼ë¡œ í•™ìŠµëœ GloVeì˜ ë°©ëŒ€í•œ ì–¸ì–´ ì •ë³´ í™œìš©\n",
        "- **ë¹ ë¥¸ ìˆ˜ë ´**: ì¢‹ì€ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ë” ë¹ ë¥¸ í•™ìŠµ\n",
        "- **ì¼ë°˜í™” ì„±ëŠ¥**: ëŒ€ê·œëª¨ ì½”í¼ìŠ¤ì—ì„œ í•™ìŠµëœ ì¼ë°˜ì  ì–¸ì–´ í‘œí˜„\n",
        "- **ë„ë©”ì¸ ì ì‘**: íŠ¹ì • ë„ë©”ì¸ì— íŠ¹í™”ë˜ì§€ ì•Šì€ ë²”ìš©ì  ë‹¨ì–´ í‘œí˜„\n",
        "\n",
        "### ëª¨ë¸ íŠ¹ì§• ìš”ì•½\n",
        "- **GloVe 6B.100d**: Stanfordì˜ ì‚¬ì „ í›ˆë ¨ëœ 100ì°¨ì› ë‹¨ì–´ ë²¡í„°\n",
        "- **ê³ ì •ëœ ê°€ì¤‘ì¹˜**: trainable=Falseë¡œ ì‚¬ì „ í›ˆë ¨ëœ ì§€ì‹ ë³´ì¡´\n",
        "- **ì–‘ë°©í–¥ LSTM**: ë¬¸ë§¥ì„ ì–‘ë°©í–¥ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ\n",
        "- **ë§ˆìŠ¤í‚¹**: mask_zero=Trueë¡œ íŒ¨ë”© í† í° ì²˜ë¦¬\n",
        "\n",
        "### ì„ë² ë”© ë°©ë²• ë¹„êµ\n",
        "\n",
        "| íŠ¹ì„± | ì›í•« ì¸ì½”ë”© | í•™ìŠµ ê°€ëŠ¥í•œ ì„ë² ë”© | ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© (GloVe) |\n",
        "|------|-------------|-------------------|---------------------------|\n",
        "| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | ë§¤ìš° ë†’ìŒ | ë³´í†µ | ë³´í†µ |\n",
        "| **í•™ìŠµ ì†ë„** | ëŠë¦¼ | ë³´í†µ | ë¹ ë¦„ |\n",
        "| **ì´ˆê¸° ì„±ëŠ¥** | ë‚®ìŒ | ë‚®ìŒ | ë†’ìŒ |\n",
        "| **ì–¸ì–´ ì§€ì‹** | ì—†ìŒ | í•™ìŠµìœ¼ë¡œ íšë“ | ì‚¬ì „ í›ˆë ¨ëœ ì§€ì‹ |\n",
        "| **ë„ë©”ì¸ ì ì‘** | ì œí•œì  | ìš°ìˆ˜ | ë³´í†µ |\n",
        "| **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±** | âŒ | âœ… | âœ… |\n",
        "| **ì „ì´ í•™ìŠµ** | âŒ | âŒ | âœ… |\n",
        "| **ê¶Œì¥ ì‚¬ìš©** | ì‹¤í—˜ìš© | ì¼ë°˜ì  | ê³ ì„±ëŠ¥ í•„ìš”ì‹œ |\n",
        "\n",
        "### ì–¸ì œ ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©ì„ ì‚¬ìš©í• ê¹Œ?\n",
        "\n",
        "#### âœ… ì‚¬ìš© ê¶Œì¥ ìƒí™©\n",
        "- **ì†Œê·œëª¨ ë°ì´í„°ì…‹**: ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ì–´ ì„ë² ë”© í•™ìŠµì´ ì–´ë ¤ìš´ ê²½ìš°\n",
        "- **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘**: ë¹ ë¥´ê²Œ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ê³  ì‹¶ì€ ê²½ìš°\n",
        "- **ì¼ë°˜ì  ì–¸ì–´ ì‘ì—…**: ê°ì • ë¶„ì„, ë¬¸ì„œ ë¶„ë¥˜ ë“± ë²”ìš© ì–¸ì–´ ì´í•´ í•„ìš”\n",
        "- **ê³„ì‚° ìì› ì œí•œ**: í•™ìŠµ ì‹œê°„ê³¼ ìì›ì„ ì ˆì•½í•˜ê³  ì‹¶ì€ ê²½ìš°\n",
        "\n",
        "#### âŒ ì‚¬ìš© ë¹„ê¶Œì¥ ìƒí™©\n",
        "- **íŠ¹ìˆ˜ ë„ë©”ì¸**: ì˜ë£Œ, ë²•ë¥  ë“± ì „ë¬¸ ìš©ì–´ê°€ ë§ì€ ë„ë©”ì¸\n",
        "- **ëŒ€ê·œëª¨ ë°ì´í„°**: ì¶©ë¶„í•œ ë°ì´í„°ë¡œ ë„ë©”ì¸ íŠ¹í™” ì„ë² ë”© í•™ìŠµ ê°€ëŠ¥\n",
        "- **íŠ¹ìˆ˜ ì–´íœ˜**: ì‹ ì¡°ì–´, ìŠ¬ë­ ë“±ì´ ë§ì€ ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„°\n",
        "\n",
        "### ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­\n",
        "1. **ë‹¤ë¥¸ ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”©**: Word2Vec, FastText, í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”©\n",
        "2. **ë¯¸ì„¸ ì¡°ì •**: trainable=Trueë¡œ ì„¤ì •í•˜ì—¬ ë„ë©”ì¸ ì ì‘\n",
        "3. **Transformer ëª¨ë¸**: BERT, RoBERTa ë“± ìµœì‹  ì–¸ì–´ ëª¨ë¸ í™œìš©\n",
        "4. **ì•™ìƒë¸”**: ì—¬ëŸ¬ ì„ë² ë”© ë°©ë²•ì˜ ê²°í•©\n",
        "5. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: \n",
        "   - LSTM ìœ ë‹› ìˆ˜ ì¡°ì •\n",
        "   - ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ìµœì í™”\n",
        "   - í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§\n",
        "\n",
        "### ì‹¤ì œ ì ìš© ê³ ë ¤ì‚¬í•­\n",
        "- **ì„ë² ë”© íŒŒì¼ í¬ê¸°**: GloVe 6B.100dëŠ” ì•½ 350MB\n",
        "- **ë¡œë”© ì‹œê°„**: ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±ì— ì‹œê°„ ì†Œìš”\n",
        "- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ê°€ ëª¨ë¸ í¬ê¸°ì— ì˜í–¥\n",
        "- **ì—…ë°ì´íŠ¸**: ìƒˆë¡œìš´ ë‹¨ì–´ì— ëŒ€í•œ ì²˜ë¦¬ ë°©ë²• ê³ ë ¤\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
