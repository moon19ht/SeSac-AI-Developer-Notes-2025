{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 꽃 이미지 분류 딥러닝 프로젝트\n",
        "\n",
        "이 노트북은 꽃 이미지를 분류하는 CNN 모델을 구축하고 학습하는 과정을 담고 있습니다.\n",
        "\n",
        "## 프로젝트 개요\n",
        "- **목표**: 5가지 꽃 종류(daisy, dandelion, rose, sunflower, tulip)를 분류하는 모델 개발\n",
        "- **방법**: Convolutional Neural Network (CNN) 사용\n",
        "- **데이터**: 꽃 이미지 데이터셋\n",
        "- **프레임워크**: TensorFlow/Keras\n",
        "\n",
        "## 프로젝트 구조\n",
        "1. 라이브러리 임포트 및 환경 설정\n",
        "2. 데이터 전처리 함수 정의\n",
        "3. 데이터셋 구성 및 분할\n",
        "4. 딥러닝 모델 구축\n",
        "5. 모델 학습 및 저장\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 라이브러리 임포트 및 환경 설정\n",
        "\n",
        "필요한 라이브러리들을 임포트합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 딥러닝 관련 라이브러리\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model \n",
        "from keras import models, layers\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "# 데이터 처리 및 시각화 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import PIL.Image as pilimg \n",
        "\n",
        "# 파일 시스템 관련 라이브러리\n",
        "import os\n",
        "import shutil\n",
        "import random \n",
        "import imghdr\n",
        "import pickle\n",
        "\n",
        "print(\"라이브러리 임포트 완료!\")\n",
        "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
        "print(f\"Keras 버전: {keras.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 데이터 전처리 함수 정의\n",
        "\n",
        "이미지 데이터셋을 정리하고 분할하기 위한 함수들을 정의합니다.\n",
        "\n",
        "### 주요 기능:\n",
        "- **이미지 리네이밍**: 클래스별로 일관된 파일명으로 변경\n",
        "- **데이터 분할**: Train/Validation/Test 세트로 분할 (50:25:25 비율)\n",
        "- **디렉토리 구성**: 모델 학습에 적합한 폴더 구조 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rename_images_in_class_folder(src_class_dir, class_name, dest_dir):\n",
        "    \"\"\"\n",
        "    특정 클래스 폴더의 이미지들을 'class_name.인덱스.확장자' 형식으로 리네이밍\n",
        "    \n",
        "    Args:\n",
        "        src_class_dir: 원본 클래스 폴더 경로\n",
        "        class_name: 클래스명 (예: 'daisy')\n",
        "        dest_dir: 리네이밍된 이미지가 저장될 폴더\n",
        "    \"\"\"\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일만 필터링\n",
        "    files = [f for f in os.listdir(src_class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    files.sort()\n",
        "\n",
        "    for idx, fname in enumerate(files):\n",
        "        src_path = os.path.join(src_class_dir, fname)\n",
        "        ext = os.path.splitext(fname)[1].lower()\n",
        "        new_name = f\"{class_name}.{idx}{ext}\"\n",
        "        dst_path = os.path.join(dest_dir, new_name)\n",
        "        shutil.copyfile(src_path, dst_path)\n",
        "\n",
        "    print(f\"✅ {class_name} 리네임 완료: {len(files)}개 처리됨.\")\n",
        "\n",
        "\n",
        "def rename_all_classes(original_root_dir, renamed_root_dir):\n",
        "    \"\"\"\n",
        "    모든 클래스의 이미지들을 리네이밍하여 하나의 폴더에 통합\n",
        "    \n",
        "    Args:\n",
        "        original_root_dir: 원본 데이터셋 폴더 (클래스별 하위 폴더 포함)\n",
        "        renamed_root_dir: 리네이밍된 이미지들이 저장될 폴더\n",
        "    \"\"\"\n",
        "    classes = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
        "\n",
        "    # 기존 폴더가 있으면 삭제 후 새로 생성\n",
        "    if os.path.exists(renamed_root_dir):\n",
        "        shutil.rmtree(renamed_root_dir)\n",
        "    os.makedirs(renamed_root_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in classes:\n",
        "        src_class_dir = os.path.join(original_root_dir, class_name)\n",
        "        rename_images_in_class_folder(src_class_dir, class_name, renamed_root_dir)\n",
        "\n",
        "print(\"이미지 리네이밍 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def copy_images_by_class(class_name, original_dataset_dir, dest_dirs, split_ratio=(0.5, 0.25, 0.25)):\n",
        "    \"\"\"\n",
        "    특정 클래스의 이미지들을 Train/Validation/Test로 분할 복사\n",
        "    \n",
        "    Args:\n",
        "        class_name: 클래스명\n",
        "        original_dataset_dir: 리네이밍된 이미지들이 있는 폴더\n",
        "        dest_dirs: [train_dir, val_dir, test_dir] 리스트\n",
        "        split_ratio: 분할 비율 (기본값: 50:25:25)\n",
        "    \"\"\"\n",
        "    # 해당 클래스의 이미지 파일들 찾기\n",
        "    image_files = [\n",
        "        f for f in os.listdir(original_dataset_dir)\n",
        "        if f.startswith(f\"{class_name}.\") and f.lower().endswith(('.jpg', '.jpeg', '.png')) \n",
        "        and os.path.isfile(os.path.join(original_dataset_dir, f))\n",
        "    ]\n",
        "    image_files.sort()\n",
        "    random.shuffle(image_files)  # 랜덤 셔플\n",
        "\n",
        "    # 분할 인덱스 계산\n",
        "    total = len(image_files)\n",
        "    train_end = int(total * split_ratio[0])\n",
        "    val_end = train_end + int(total * split_ratio[1])\n",
        "\n",
        "    # 분할된 파일 리스트\n",
        "    splits = [image_files[:train_end], image_files[train_end:val_end], image_files[val_end:]]\n",
        "\n",
        "    # 각 세트로 파일 복사\n",
        "    for split, dst_dir in zip(splits, dest_dirs):\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        for fname in split:\n",
        "            src = os.path.join(original_dataset_dir, fname)\n",
        "            dst = os.path.join(dst_dir, fname)\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "def ImageCopy(renamed_dataset_dir, base_dir):\n",
        "    \"\"\"\n",
        "    리네이밍된 이미지들을 Train/Validation/Test 폴더로 분할하여 복사\n",
        "    \n",
        "    Args:\n",
        "        renamed_dataset_dir: 리네이밍된 이미지들이 있는 폴더\n",
        "        base_dir: Train/Val/Test 폴더들이 생성될 기본 경로\n",
        "    \"\"\"\n",
        "    categories = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
        "    sets = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "    # 기존 폴더 삭제 후 새로 생성\n",
        "    if os.path.exists(base_dir):\n",
        "        shutil.rmtree(base_dir)\n",
        "    for set_name in sets:\n",
        "        for category in categories:\n",
        "            os.makedirs(os.path.join(base_dir, set_name, category), exist_ok=True)\n",
        "\n",
        "    # 폴더 경로 설정\n",
        "    train_dir = os.path.join(base_dir, \"train\")\n",
        "    val_dir = os.path.join(base_dir, \"validation\")\n",
        "    test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "    # 각 클래스별로 이미지 분할 복사\n",
        "    for category in categories:\n",
        "        print(f\"🔄 {category} 분할 중...\")\n",
        "        copy_images_by_class(\n",
        "            class_name=category,\n",
        "            original_dataset_dir=renamed_dataset_dir,\n",
        "            dest_dirs=[\n",
        "                os.path.join(train_dir, category),\n",
        "                os.path.join(val_dir, category),\n",
        "                os.path.join(test_dir, category)\n",
        "            ],\n",
        "            split_ratio=(0.5, 0.25, 0.25)\n",
        "        )\n",
        "\n",
        "    print(\"\\n✅ 이미지 분할 복사 완료!\\n\")\n",
        "\n",
        "    # 결과 요약 출력\n",
        "    for set_name in sets:\n",
        "        for category in categories:\n",
        "            dir_path = os.path.join(base_dir, set_name, category)\n",
        "            count = len(os.listdir(dir_path))\n",
        "            print(f\"📁 {set_name}/{category}: {count}개\")\n",
        "\n",
        "print(\"데이터 분할 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 데이터셋 구성 및 분할 실행\n",
        "\n",
        "실제로 데이터 전처리를 수행합니다.\n",
        "\n",
        "### 처리 과정:\n",
        "1. **1단계**: 클래스별 이미지들을 `class_name.index.ext` 형식으로 리네이밍\n",
        "2. **2단계**: 리네이밍된 이미지를 Train(50%) / Validation(25%) / Test(25%) 비율로 분할\n",
        "\n",
        "### 폴더 구조:\n",
        "```\n",
        "flowers_small/\n",
        "├── train/\n",
        "│   ├── daisy/\n",
        "│   ├── dandelion/\n",
        "│   ├── rose/\n",
        "│   ├── sunflower/\n",
        "│   └── tulip/\n",
        "├── validation/\n",
        "│   └── (동일한 구조)\n",
        "└── test/\n",
        "    └── (동일한 구조)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 경로 설정\n",
        "original_dataset_dir = \"../../data/flowers\"           # 원본 데이터셋 폴더 (클래스별 하위 폴더 있음)\n",
        "renamed_root = \"../../data/flowers_renamed\"           # 리네이밍된 이미지들이 저장될 위치\n",
        "base_dir = \"../../data/flowers_small\"                 # 최종 분할된 train/val/test 폴더 생성 위치\n",
        "\n",
        "print(\"📁 데이터셋 경로 설정 완료!\")\n",
        "print(f\"원본 데이터: {original_dataset_dir}\")\n",
        "print(f\"리네이밍 저장: {renamed_root}\")\n",
        "print(f\"분할 저장: {base_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1단계: 클래스별 이미지들을 daisy.0.jpg 형식으로 리네이밍 + 통합\n",
        "print(\"🔄 1단계: 이미지 리네이밍 시작...\")\n",
        "rename_all_classes(original_dataset_dir, renamed_root)\n",
        "print(\"✅ 1단계 완료: 모든 이미지가 리네이밍되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2단계: 리네이밍된 이미지를 50:25:25 비율로 train/validation/test 분할 복사\n",
        "print(\"🔄 2단계: 데이터 분할 시작...\")\n",
        "ImageCopy(renamed_root, base_dir)\n",
        "print(\"✅ 2단계 완료: 데이터 분할이 완료되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 딥러닝 모델 구축 및 학습\n",
        "\n",
        "CNN(Convolutional Neural Network) 모델을 구축하고 학습합니다.\n",
        "\n",
        "### 모델 구조:\n",
        "1. **데이터 증강(Data Augmentation)**: RandomFlip, RandomRotation, RandomZoom\n",
        "2. **전처리**: Rescaling (0-1 정규화)\n",
        "3. **CNN 레이어들**: \n",
        "   - Conv2D (32, 64, 32 필터) + MaxPooling2D\n",
        "   - Flatten + Dropout (0.5)\n",
        "   - Dense (128, 64 유닛) + 출력층 (5 클래스)\n",
        "\n",
        "### 학습 설정:\n",
        "- **옵티마이저**: Adam\n",
        "- **손실 함수**: Sparse Categorical Crossentropy\n",
        "- **평가 지표**: Accuracy\n",
        "- **에포크**: 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 분할된 데이터셋 경로 설정\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "print(\"📁 훈련 데이터 경로 설정 완료!\")\n",
        "print(f\"Train: {train_dir}\")\n",
        "print(f\"Validation: {validation_dir}\")\n",
        "print(f\"Test: {test_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 증강 레이어 정의\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(180, 180, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "print(\"✅ 데이터 증강 레이어 정의 완료!\")\n",
        "print(\"- RandomFlip: 수평 뒤집기\")\n",
        "print(\"- RandomRotation: ±10% 회전\")\n",
        "print(\"- RandomZoom: ±10% 확대/축소\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN 모델 구축\n",
        "model = models.Sequential()\n",
        "\n",
        "# 전처리 및 데이터 증강\n",
        "model.add(layers.Rescaling(1./255))  # 픽셀 값을 0-1로 정규화\n",
        "model.add(data_augmentation)\n",
        "\n",
        "# 합성곱 레이어들\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "# 완전연결 레이어들\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))  # 과적합 방지\n",
        "model.add(layers.Dense(128, activation=\"relu\"))\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dense(5, activation=\"softmax\"))  # 5개 클래스 분류\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",  # 정수 라벨용 다중 분류\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"✅ CNN 모델 구축 완료!\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 훈련 데이터셋 생성\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,  # 훈련 데이터의 20%를 추가 검증용으로 사용\n",
        "    seed=123,\n",
        "    subset=\"training\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "# 검증 데이터셋 생성\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split=0.2,\n",
        "    seed=123,\n",
        "    subset=\"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "print(\"✅ 데이터셋 로드 완료!\")\n",
        "print(f\"훈련 데이터셋: {train_ds}\")\n",
        "print(f\"검증 데이터셋: {validation_ds}\")\n",
        "\n",
        "# 클래스 이름 확인\n",
        "class_names = train_ds.class_names\n",
        "print(f\"클래스: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 모델 학습 및 저장\n",
        "\n",
        "실제로 모델을 학습시키고 저장합니다.\n",
        "\n",
        "### 학습 과정:\n",
        "- **에포크**: 30회 반복 학습\n",
        "- **데이터**: 증강된 훈련 데이터 + 검증 데이터\n",
        "- **결과**: 각 에포크마다 훈련/검증 정확도와 손실 출력\n",
        "- **저장**: 학습 완료된 모델을 `flowers_model.keras` 파일로 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 학습 시작\n",
        "print(\"🚀 모델 학습 시작...\")\n",
        "print(\"※ 30 에포크 학습에는 시간이 걸릴 수 있습니다.\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds, \n",
        "    validation_data=validation_ds,\n",
        "    epochs=30,\n",
        "    verbose=1  # 학습 과정 출력\n",
        ")\n",
        "\n",
        "print(\"✅ 모델 학습 완료!\")\n",
        "\n",
        "# 모델 저장\n",
        "model_save_path = \"flowers_model.keras\"\n",
        "model.save(model_save_path)\n",
        "print(f\"💾 모델이 저장되었습니다: {model_save_path}\")\n",
        "\n",
        "# 최종 성능 출력\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "print(f\"\\n📊 최종 성능:\")\n",
        "print(f\"- 훈련 정확도: {final_train_acc:.4f}\")\n",
        "print(f\"- 검증 정확도: {final_val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 결론 및 다음 단계\n",
        "\n",
        "### 완료된 작업:\n",
        "✅ **데이터 전처리**: 이미지 리네이밍 및 Train/Val/Test 분할  \n",
        "✅ **모델 구축**: CNN 아키텍처 설계 및 데이터 증강 적용  \n",
        "✅ **모델 학습**: 30 에포크 학습 및 성능 평가  \n",
        "✅ **모델 저장**: `flowers_model.keras` 파일로 저장  \n",
        "\n",
        "### 다음 단계 제안:\n",
        "1. **성능 개선**:\n",
        "   - 하이퍼파라미터 튜닝 (학습률, 배치 크기, 에포크 수)\n",
        "   - 더 복잡한 모델 아키텍처 시도 (ResNet, EfficientNet 등)\n",
        "   - 더 다양한 데이터 증강 기법 적용\n",
        "\n",
        "2. **모델 평가**:\n",
        "   - Test 데이터셋으로 최종 성능 평가\n",
        "   - Confusion Matrix 생성\n",
        "   - 잘못 분류된 이미지 분석\n",
        "\n",
        "3. **모델 활용**:\n",
        "   - 새로운 꽃 이미지 예측 함수 구현\n",
        "   - 웹 애플리케이션 또는 API로 배포\n",
        "   - 실시간 이미지 분류 시스템 구축\n",
        "\n",
        "### 학습한 주요 개념:\n",
        "- **CNN 아키텍처**: Conv2D, MaxPooling2D, Dense 레이어\n",
        "- **데이터 증강**: 과적합 방지 및 일반화 성능 향상\n",
        "- **데이터 전처리**: 체계적인 데이터 관리 및 분할\n",
        "- **모델 저장/로드**: 학습된 모델의 재사용\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
