{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 꽃 이미지 분류 딥러닝 프로젝트\n",
        "\n",
        "이 노트북은 꽃 이미지를 분류하는 CNN 모델을 구축하고 학습하는 과정을 담고 있습니다.\n",
        "\n",
        "## 프로젝트 개요\n",
        "- **목표**: 5가지 꽃 종류(daisy, dandelion, rose, sunflower, tulip)를 분류하는 모델 개발\n",
        "- **방법**: Convolutional Neural Network (CNN) 사용\n",
        "- **데이터**: 꽃 이미지 데이터셋\n",
        "- **프레임워크**: TensorFlow/Keras\n",
        "\n",
        "## 프로젝트 구조\n",
        "1. 라이브러리 임포트 및 환경 설정\n",
        "2. 데이터 전처리 함수 정의\n",
        "3. 데이터셋 구성 및 분할\n",
        "4. 딥러닝 모델 구축\n",
        "5. 모델 학습 및 저장\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 라이브러리 임포트 및 환경 설정\n",
        "\n",
        "필요한 라이브러리들을 임포트합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "라이브러리 임포트 완료!\n",
            "TensorFlow 버전: 2.15.1\n",
            "Keras 버전: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "# 딥러닝 관련 라이브러리\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model \n",
        "from keras import models, layers\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "# 데이터 처리 및 시각화 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import PIL.Image as pilimg \n",
        "\n",
        "# 파일 시스템 관련 라이브러리\n",
        "import os\n",
        "import shutil\n",
        "import random \n",
        "import imghdr\n",
        "import pickle\n",
        "\n",
        "print(\"라이브러리 임포트 완료!\")\n",
        "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
        "print(f\"Keras 버전: {keras.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 데이터 전처리 함수 정의\n",
        "\n",
        "이미지 데이터셋을 정리하고 분할하기 위한 함수들을 정의합니다.\n",
        "\n",
        "### 주요 기능:\n",
        "- **이미지 리네이밍**: 클래스별로 일관된 파일명으로 변경\n",
        "- **데이터 분할**: Train/Validation/Test 세트로 분할 (50:25:25 비율)\n",
        "- **디렉토리 구성**: 모델 학습에 적합한 폴더 구조 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "이미지 리네이밍 함수 정의 완료!\n"
          ]
        }
      ],
      "source": [
        "def rename_images_in_class_folder(src_class_dir, class_name, dest_dir):\n",
        "    \"\"\"\n",
        "    특정 클래스 폴더의 이미지들을 'class_name.인덱스.확장자' 형식으로 리네이밍\n",
        "    \n",
        "    Args:\n",
        "        src_class_dir: 원본 클래스 폴더 경로\n",
        "        class_name: 클래스명 (예: 'daisy')\n",
        "        dest_dir: 리네이밍된 이미지가 저장될 폴더\n",
        "    \"\"\"\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일만 필터링\n",
        "    files = [f for f in os.listdir(src_class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    files.sort()\n",
        "\n",
        "    for idx, fname in enumerate(files):\n",
        "        src_path = os.path.join(src_class_dir, fname)\n",
        "        ext = os.path.splitext(fname)[1].lower()\n",
        "        new_name = f\"{class_name}.{idx}{ext}\"\n",
        "        dst_path = os.path.join(dest_dir, new_name)\n",
        "        shutil.copyfile(src_path, dst_path)\n",
        "\n",
        "    print(f\"✅ {class_name} 리네임 완료: {len(files)}개 처리됨.\")\n",
        "\n",
        "\n",
        "def rename_all_classes(original_root_dir, renamed_root_dir):\n",
        "    \"\"\"\n",
        "    모든 클래스의 이미지들을 리네이밍하여 하나의 폴더에 통합\n",
        "    \n",
        "    Args:\n",
        "        original_root_dir: 원본 데이터셋 폴더 (클래스별 하위 폴더 포함)\n",
        "        renamed_root_dir: 리네이밍된 이미지들이 저장될 폴더\n",
        "    \"\"\"\n",
        "    classes = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
        "\n",
        "    # 기존 폴더가 있으면 삭제 후 새로 생성\n",
        "    if os.path.exists(renamed_root_dir):\n",
        "        shutil.rmtree(renamed_root_dir)\n",
        "    os.makedirs(renamed_root_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in classes:\n",
        "        src_class_dir = os.path.join(original_root_dir, class_name)\n",
        "        rename_images_in_class_folder(src_class_dir, class_name, renamed_root_dir)\n",
        "\n",
        "print(\"이미지 리네이밍 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 분할 함수 정의 완료!\n"
          ]
        }
      ],
      "source": [
        "def copy_images_by_class(class_name, original_dataset_dir, dest_dirs, split_ratio=(0.5, 0.25, 0.25)):\n",
        "    \"\"\"\n",
        "    특정 클래스의 이미지들을 Train/Validation/Test로 분할 복사\n",
        "    \n",
        "    Args:\n",
        "        class_name: 클래스명\n",
        "        original_dataset_dir: 리네이밍된 이미지들이 있는 폴더\n",
        "        dest_dirs: [train_dir, val_dir, test_dir] 리스트\n",
        "        split_ratio: 분할 비율 (기본값: 50:25:25)\n",
        "    \"\"\"\n",
        "    # 해당 클래스의 이미지 파일들 찾기\n",
        "    image_files = [\n",
        "        f for f in os.listdir(original_dataset_dir)\n",
        "        if f.startswith(f\"{class_name}.\") and f.lower().endswith(('.jpg', '.jpeg', '.png')) \n",
        "        and os.path.isfile(os.path.join(original_dataset_dir, f))\n",
        "    ]\n",
        "    image_files.sort()\n",
        "    random.shuffle(image_files)  # 랜덤 셔플\n",
        "\n",
        "    # 분할 인덱스 계산\n",
        "    total = len(image_files)\n",
        "    train_end = int(total * split_ratio[0])\n",
        "    val_end = train_end + int(total * split_ratio[1])\n",
        "\n",
        "    # 분할된 파일 리스트\n",
        "    splits = [image_files[:train_end], image_files[train_end:val_end], image_files[val_end:]]\n",
        "\n",
        "    # 각 세트로 파일 복사\n",
        "    for split, dst_dir in zip(splits, dest_dirs):\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        for fname in split:\n",
        "            src = os.path.join(original_dataset_dir, fname)\n",
        "            dst = os.path.join(dst_dir, fname)\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "def ImageCopy(renamed_dataset_dir, base_dir):\n",
        "    \"\"\"\n",
        "    리네이밍된 이미지들을 Train/Validation/Test 폴더로 분할하여 복사\n",
        "    \n",
        "    Args:\n",
        "        renamed_dataset_dir: 리네이밍된 이미지들이 있는 폴더\n",
        "        base_dir: Train/Val/Test 폴더들이 생성될 기본 경로\n",
        "    \"\"\"\n",
        "    categories = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
        "    sets = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "    # 기존 폴더 삭제 후 새로 생성\n",
        "    if os.path.exists(base_dir):\n",
        "        shutil.rmtree(base_dir)\n",
        "    for set_name in sets:\n",
        "        for category in categories:\n",
        "            os.makedirs(os.path.join(base_dir, set_name, category), exist_ok=True)\n",
        "\n",
        "    # 폴더 경로 설정\n",
        "    train_dir = os.path.join(base_dir, \"train\")\n",
        "    val_dir = os.path.join(base_dir, \"validation\")\n",
        "    test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "    # 각 클래스별로 이미지 분할 복사\n",
        "    for category in categories:\n",
        "        print(f\"🔄 {category} 분할 중...\")\n",
        "        copy_images_by_class(\n",
        "            class_name=category,\n",
        "            original_dataset_dir=renamed_dataset_dir,\n",
        "            dest_dirs=[\n",
        "                os.path.join(train_dir, category),\n",
        "                os.path.join(val_dir, category),\n",
        "                os.path.join(test_dir, category)\n",
        "            ],\n",
        "            split_ratio=(0.5, 0.25, 0.25)\n",
        "        )\n",
        "\n",
        "    print(\"\\n✅ 이미지 분할 복사 완료!\\n\")\n",
        "\n",
        "    # 결과 요약 출력\n",
        "    for set_name in sets:\n",
        "        for category in categories:\n",
        "            dir_path = os.path.join(base_dir, set_name, category)\n",
        "            count = len(os.listdir(dir_path))\n",
        "            print(f\"📁 {set_name}/{category}: {count}개\")\n",
        "\n",
        "print(\"데이터 분할 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 데이터셋 구성 및 분할 실행\n",
        "\n",
        "실제로 데이터 전처리를 수행합니다.\n",
        "\n",
        "### 처리 과정:\n",
        "1. **1단계**: 클래스별 이미지들을 `class_name.index.ext` 형식으로 리네이밍\n",
        "2. **2단계**: 리네이밍된 이미지를 Train(50%) / Validation(25%) / Test(25%) 비율로 분할\n",
        "\n",
        "### 폴더 구조:\n",
        "```\n",
        "flowers_small/\n",
        "├── train/\n",
        "│   ├── daisy/\n",
        "│   ├── dandelion/\n",
        "│   ├── rose/\n",
        "│   ├── sunflower/\n",
        "│   └── tulip/\n",
        "├── validation/\n",
        "│   └── (동일한 구조)\n",
        "└── test/\n",
        "    └── (동일한 구조)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 데이터셋 경로 설정 완료!\n",
            "원본 데이터: ../../data/flowers/train\n",
            "리네이밍 저장: ../../data/flowers_renamed\n",
            "분할 저장: ../../data/flowers_small\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋 경로 설정\n",
        "original_dataset_dir = \"../../data/flowers/train\"           # 원본 데이터셋 폴더 (클래스별 하위 폴더 있음)\n",
        "renamed_root = \"../../data/flowers_renamed\"           # 리네이밍된 이미지들이 저장될 위치\n",
        "base_dir = \"../../data/flowers_small\"                 # 최종 분할된 train/val/test 폴더 생성 위치\n",
        "\n",
        "print(\"📁 데이터셋 경로 설정 완료!\")\n",
        "print(f\"원본 데이터: {original_dataset_dir}\")\n",
        "print(f\"리네이밍 저장: {renamed_root}\")\n",
        "print(f\"분할 저장: {base_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 1단계: 이미지 리네이밍 시작...\n",
            "✅ daisy 리네임 완료: 501개 처리됨.\n",
            "✅ dandelion 리네임 완료: 646개 처리됨.\n",
            "✅ rose 리네임 완료: 497개 처리됨.\n",
            "✅ sunflower 리네임 완료: 495개 처리됨.\n",
            "✅ tulip 리네임 완료: 607개 처리됨.\n",
            "✅ 1단계 완료: 모든 이미지가 리네이밍되었습니다!\n"
          ]
        }
      ],
      "source": [
        "# 1단계: 클래스별 이미지들을 daisy.0.jpg 형식으로 리네이밍 + 통합\n",
        "print(\"🔄 1단계: 이미지 리네이밍 시작...\")\n",
        "rename_all_classes(original_dataset_dir, renamed_root)\n",
        "print(\"✅ 1단계 완료: 모든 이미지가 리네이밍되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 2단계: 데이터 분할 시작...\n",
            "🔄 daisy 분할 중...\n",
            "🔄 dandelion 분할 중...\n",
            "🔄 rose 분할 중...\n",
            "🔄 sunflower 분할 중...\n",
            "🔄 tulip 분할 중...\n",
            "\n",
            "✅ 이미지 분할 복사 완료!\n",
            "\n",
            "📁 train/daisy: 250개\n",
            "📁 train/dandelion: 323개\n",
            "📁 train/rose: 248개\n",
            "📁 train/sunflower: 247개\n",
            "📁 train/tulip: 303개\n",
            "📁 validation/daisy: 125개\n",
            "📁 validation/dandelion: 161개\n",
            "📁 validation/rose: 124개\n",
            "📁 validation/sunflower: 123개\n",
            "📁 validation/tulip: 151개\n",
            "📁 test/daisy: 126개\n",
            "📁 test/dandelion: 162개\n",
            "📁 test/rose: 125개\n",
            "📁 test/sunflower: 125개\n",
            "📁 test/tulip: 153개\n",
            "✅ 2단계 완료: 데이터 분할이 완료되었습니다!\n"
          ]
        }
      ],
      "source": [
        "# 2단계: 리네이밍된 이미지를 50:25:25 비율로 train/validation/test 분할 복사\n",
        "print(\"🔄 2단계: 데이터 분할 시작...\")\n",
        "ImageCopy(renamed_root, base_dir)\n",
        "print(\"✅ 2단계 완료: 데이터 분할이 완료되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 딥러닝 모델 구축 및 학습\n",
        "\n",
        "CNN(Convolutional Neural Network) 모델을 구축하고 학습합니다.\n",
        "\n",
        "### 모델 구조:\n",
        "1. **데이터 증강(Data Augmentation)**: RandomFlip, RandomRotation, RandomZoom\n",
        "2. **전처리**: Rescaling (0-1 정규화)\n",
        "3. **CNN 레이어들**: \n",
        "   - Conv2D (32, 64, 32 필터) + MaxPooling2D\n",
        "   - Flatten + Dropout (0.5)\n",
        "   - Dense (128, 64 유닛) + 출력층 (5 클래스)\n",
        "\n",
        "### 학습 설정:\n",
        "- **옵티마이저**: Adam\n",
        "- **손실 함수**: Sparse Categorical Crossentropy\n",
        "- **평가 지표**: Accuracy\n",
        "- **에포크**: 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 훈련 데이터 경로 설정 완료!\n",
            "Train: ../../data/flowers_small\\train\n",
            "Validation: ../../data/flowers_small\\validation\n",
            "Test: ../../data/flowers_small\\test\n"
          ]
        }
      ],
      "source": [
        "# 분할된 데이터셋 경로 설정\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "print(\"📁 훈련 데이터 경로 설정 완료!\")\n",
        "print(f\"Train: {train_dir}\")\n",
        "print(f\"Validation: {validation_dir}\")\n",
        "print(f\"Test: {test_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 데이터 증강 레이어 정의 완료!\n",
            "- RandomFlip: 수평 뒤집기\n",
            "- RandomRotation: ±10% 회전\n",
            "- RandomZoom: ±10% 확대/축소\n"
          ]
        }
      ],
      "source": [
        "# 데이터 증강 레이어 정의\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(180, 180, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "print(\"✅ 데이터 증강 레이어 정의 완료!\")\n",
        "print(\"- RandomFlip: 수평 뒤집기\")\n",
        "print(\"- RandomRotation: ±10% 회전\")\n",
        "print(\"- RandomZoom: ±10% 확대/축소\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ CNN 모델 구축 완료!\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_2 (Rescaling)     (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 89, 89, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 43, 43, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 41, 41, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 20, 20, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               1638528   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1684965 (6.43 MB)\n",
            "Trainable params: 1684965 (6.43 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CNN 모델 구축\n",
        "model = models.Sequential()\n",
        "\n",
        "# 전처리 및 데이터 증강\n",
        "model.add(layers.Rescaling(1./255, input_shape=(180, 180, 3)))  # 픽셀 값을 0-1로 정규화\n",
        "model.add(data_augmentation)\n",
        "\n",
        "# 합성곱 레이어들\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "# 완전연결 레이어들\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))  # 과적합 방지\n",
        "model.add(layers.Dense(128, activation=\"relu\"))\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dense(5, activation=\"softmax\"))  # 5개 클래스 분류\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",  # 정수 라벨용 다중 분류\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"✅ CNN 모델 구축 완료!\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1371 files belonging to 5 classes.\n",
            "Using 1097 files for training.\n",
            "Found 684 files belonging to 5 classes.\n",
            "Using 136 files for validation.\n",
            "✅ 데이터셋 로드 완료!\n",
            "훈련 데이터셋: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "검증 데이터셋: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "클래스: ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
          ]
        }
      ],
      "source": [
        "# 훈련 데이터셋 생성\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,  # 훈련 데이터의 20%를 추가 검증용으로 사용\n",
        "    seed=123,\n",
        "    subset=\"training\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "# 검증 데이터셋 생성\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split=0.2,\n",
        "    seed=123,\n",
        "    subset=\"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "print(\"✅ 데이터셋 로드 완료!\")\n",
        "print(f\"훈련 데이터셋: {train_ds}\")\n",
        "print(f\"검증 데이터셋: {validation_ds}\")\n",
        "\n",
        "# 클래스 이름 확인\n",
        "class_names = train_ds.class_names\n",
        "print(f\"클래스: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 모델 학습 및 저장\n",
        "\n",
        "실제로 모델을 학습시키고 저장합니다.\n",
        "\n",
        "### 학습 과정:\n",
        "- **에포크**: 30회 반복 학습\n",
        "- **데이터**: 증강된 훈련 데이터 + 검증 데이터\n",
        "- **결과**: 각 에포크마다 훈련/검증 정확도와 손실 출력\n",
        "- **저장**: 학습 완료된 모델을 `flowers_model.keras` 파일로 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 모델 학습 시작...\n",
            "※ 30 에포크 학습에는 시간이 걸릴 수 있습니다.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 10s 150ms/step - loss: 1.5175 - accuracy: 0.2963 - val_loss: 1.3357 - val_accuracy: 0.4485\n",
            "Epoch 2/30\n",
            "69/69 [==============================] - 9s 126ms/step - loss: 1.2177 - accuracy: 0.4804 - val_loss: 1.1943 - val_accuracy: 0.5147\n",
            "Epoch 3/30\n",
            "69/69 [==============================] - 9s 135ms/step - loss: 1.1484 - accuracy: 0.5059 - val_loss: 1.0937 - val_accuracy: 0.5588\n",
            "Epoch 4/30\n",
            "69/69 [==============================] - 9s 127ms/step - loss: 1.0494 - accuracy: 0.5789 - val_loss: 1.0503 - val_accuracy: 0.5809\n",
            "Epoch 5/30\n",
            "69/69 [==============================] - 9s 129ms/step - loss: 0.9967 - accuracy: 0.5953 - val_loss: 1.0241 - val_accuracy: 0.6029\n",
            "Epoch 6/30\n",
            "69/69 [==============================] - 10s 138ms/step - loss: 0.9207 - accuracy: 0.6317 - val_loss: 1.0208 - val_accuracy: 0.5735\n",
            "Epoch 7/30\n",
            "69/69 [==============================] - 10s 140ms/step - loss: 0.8801 - accuracy: 0.6545 - val_loss: 1.0698 - val_accuracy: 0.5882\n",
            "Epoch 8/30\n",
            "69/69 [==============================] - 10s 138ms/step - loss: 0.8451 - accuracy: 0.6809 - val_loss: 0.9543 - val_accuracy: 0.6471\n",
            "Epoch 9/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.7953 - accuracy: 0.7119 - val_loss: 1.0664 - val_accuracy: 0.6397\n",
            "Epoch 10/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.7632 - accuracy: 0.6919 - val_loss: 1.0247 - val_accuracy: 0.6838\n",
            "Epoch 11/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.7459 - accuracy: 0.7101 - val_loss: 0.9751 - val_accuracy: 0.6544\n",
            "Epoch 12/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.6960 - accuracy: 0.7320 - val_loss: 0.9237 - val_accuracy: 0.6471\n",
            "Epoch 13/30\n",
            "69/69 [==============================] - 10s 142ms/step - loss: 0.6917 - accuracy: 0.7284 - val_loss: 0.9316 - val_accuracy: 0.6544\n",
            "Epoch 14/30\n",
            "69/69 [==============================] - 10s 138ms/step - loss: 0.6630 - accuracy: 0.7384 - val_loss: 0.9189 - val_accuracy: 0.6765\n",
            "Epoch 15/30\n",
            "69/69 [==============================] - 10s 138ms/step - loss: 0.6443 - accuracy: 0.7338 - val_loss: 0.9837 - val_accuracy: 0.6544\n",
            "Epoch 16/30\n",
            "69/69 [==============================] - 10s 140ms/step - loss: 0.6245 - accuracy: 0.7475 - val_loss: 1.1378 - val_accuracy: 0.5809\n",
            "Epoch 17/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.5761 - accuracy: 0.7721 - val_loss: 1.1977 - val_accuracy: 0.6029\n",
            "Epoch 18/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.5582 - accuracy: 0.7876 - val_loss: 1.1921 - val_accuracy: 0.6618\n",
            "Epoch 19/30\n",
            "69/69 [==============================] - 10s 143ms/step - loss: 0.5794 - accuracy: 0.7685 - val_loss: 1.1158 - val_accuracy: 0.6250\n",
            "Epoch 20/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.5308 - accuracy: 0.7840 - val_loss: 1.0374 - val_accuracy: 0.6471\n",
            "Epoch 21/30\n",
            "69/69 [==============================] - 10s 139ms/step - loss: 0.5072 - accuracy: 0.7958 - val_loss: 1.2467 - val_accuracy: 0.5809\n",
            "Epoch 22/30\n",
            "69/69 [==============================] - 10s 141ms/step - loss: 0.5129 - accuracy: 0.7949 - val_loss: 1.2162 - val_accuracy: 0.6471\n",
            "Epoch 23/30\n",
            "69/69 [==============================] - 10s 141ms/step - loss: 0.4561 - accuracy: 0.8304 - val_loss: 1.1439 - val_accuracy: 0.6765\n",
            "Epoch 24/30\n",
            "69/69 [==============================] - 10s 142ms/step - loss: 0.4880 - accuracy: 0.8159 - val_loss: 1.1377 - val_accuracy: 0.6103\n",
            "Epoch 25/30\n",
            "69/69 [==============================] - 10s 145ms/step - loss: 0.4565 - accuracy: 0.8131 - val_loss: 1.1730 - val_accuracy: 0.6176\n",
            "Epoch 26/30\n",
            "69/69 [==============================] - 10s 150ms/step - loss: 0.4277 - accuracy: 0.8405 - val_loss: 1.1075 - val_accuracy: 0.6250\n",
            "Epoch 27/30\n",
            "69/69 [==============================] - 10s 147ms/step - loss: 0.4055 - accuracy: 0.8478 - val_loss: 1.3248 - val_accuracy: 0.6324\n",
            "Epoch 28/30\n",
            "69/69 [==============================] - 10s 151ms/step - loss: 0.4494 - accuracy: 0.8168 - val_loss: 1.1459 - val_accuracy: 0.6471\n",
            "Epoch 29/30\n",
            "69/69 [==============================] - 10s 145ms/step - loss: 0.3977 - accuracy: 0.8469 - val_loss: 1.1835 - val_accuracy: 0.6471\n",
            "Epoch 30/30\n",
            "69/69 [==============================] - 10s 145ms/step - loss: 0.3768 - accuracy: 0.8605 - val_loss: 1.2935 - val_accuracy: 0.6324\n",
            "✅ 모델 학습 완료!\n",
            "💾 모델이 저장되었습니다: flowers_model.keras\n",
            "\n",
            "📊 최종 성능:\n",
            "- 훈련 정확도: 0.8605\n",
            "- 검증 정확도: 0.6324\n"
          ]
        }
      ],
      "source": [
        "# 모델 학습 시작\n",
        "print(\"🚀 모델 학습 시작...\")\n",
        "print(\"※ 30 에포크 학습에는 시간이 걸릴 수 있습니다.\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds, \n",
        "    validation_data=validation_ds,\n",
        "    epochs=30,\n",
        "    verbose=1  # 학습 과정 출력\n",
        ")\n",
        "\n",
        "print(\"✅ 모델 학습 완료!\")\n",
        "\n",
        "# 모델 저장\n",
        "model_save_path = \"flowers_model.keras\"\n",
        "model.save(model_save_path)\n",
        "print(f\"💾 모델이 저장되었습니다: {model_save_path}\")\n",
        "\n",
        "# 최종 성능 출력\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "print(f\"\\n📊 최종 성능:\")\n",
        "print(f\"- 훈련 정확도: {final_train_acc:.4f}\")\n",
        "print(f\"- 검증 정확도: {final_val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 결론 및 다음 단계\n",
        "\n",
        "### 완료된 작업:\n",
        "✅ **데이터 전처리**: 이미지 리네이밍 및 Train/Val/Test 분할  \n",
        "✅ **모델 구축**: CNN 아키텍처 설계 및 데이터 증강 적용  \n",
        "✅ **모델 학습**: 30 에포크 학습 및 성능 평가  \n",
        "✅ **모델 저장**: `flowers_model.keras` 파일로 저장  \n",
        "\n",
        "### 다음 단계 제안:\n",
        "1. **성능 개선**:\n",
        "   - 하이퍼파라미터 튜닝 (학습률, 배치 크기, 에포크 수)\n",
        "   - 더 복잡한 모델 아키텍처 시도 (ResNet, EfficientNet 등)\n",
        "   - 더 다양한 데이터 증강 기법 적용\n",
        "\n",
        "2. **모델 평가**:\n",
        "   - Test 데이터셋으로 최종 성능 평가\n",
        "   - Confusion Matrix 생성\n",
        "   - 잘못 분류된 이미지 분석\n",
        "\n",
        "3. **모델 활용**:\n",
        "   - 새로운 꽃 이미지 예측 함수 구현\n",
        "   - 웹 애플리케이션 또는 API로 배포\n",
        "   - 실시간 이미지 분류 시스템 구축\n",
        "\n",
        "### 학습한 주요 개념:\n",
        "- **CNN 아키텍처**: Conv2D, MaxPooling2D, Dense 레이어\n",
        "- **데이터 증강**: 과적합 방지 및 일반화 성능 향상\n",
        "- **데이터 전처리**: 체계적인 데이터 관리 및 분할\n",
        "- **모델 저장/로드**: 학습된 모델의 재사용\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
