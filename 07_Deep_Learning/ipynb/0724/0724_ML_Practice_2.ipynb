{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# VGG19 Transfer Learning을 활용한 꽃 이미지 분류 프로젝트\n",
        "\n",
        "이 노트북은 VGG19 사전학습 모델을 사용한 **인라인 방식**의 Transfer Learning으로 5가지 꽃 종류를 분류하는 다중 분류 프로젝트입니다.\n",
        "\n",
        "## 프로젝트 개요\n",
        "- **목표**: VGG19 사전학습 모델을 활용한 5가지 꽃 종류 분류\n",
        "- **방법**: Transfer Learning (인라인 방식)\n",
        "- **클래스**: Daisy, Dandelion, Rose, Sunflower, Tulip (5개)\n",
        "- **데이터**: Flowers 데이터셋\n",
        "- **프레임워크**: TensorFlow/Keras\n",
        "\n",
        "## 이진 분류 vs 다중 분류\n",
        "\n",
        "### 🌸 다중 분류 (이 프로젝트)\n",
        "- **클래스 수**: 5개 (daisy, dandelion, rose, sunflower, tulip)\n",
        "- **출력층**: Dense(5, activation=\"softmax\")\n",
        "- **손실 함수**: sparse_categorical_crossentropy\n",
        "- **라벨 형태**: 정수형 (0, 1, 2, 3, 4)\n",
        "\n",
        "### 🐱🐶 이진 분류 (이전 프로젝트)\n",
        "- **클래스 수**: 2개 (cat, dog)\n",
        "- **출력층**: Dense(1, activation=\"sigmoid\")\n",
        "- **손실 함수**: binary_crossentropy\n",
        "- **라벨 형태**: 확률값 (0~1)\n",
        "\n",
        "## 프로젝트 구조\n",
        "1. 라이브러리 임포트 및 데이터 탐색\n",
        "2. 데이터 전처리 및 분할\n",
        "3. VGG19 인라인 모델 구축\n",
        "4. 모델 학습 및 저장\n",
        "5. 결과 분석 및 시각화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 라이브러리 임포트 및 환경 설정\n",
        "\n",
        "필요한 라이브러리들을 임포트하고 데이터셋의 기본 정보를 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 딥러닝 관련 라이브러리\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model \n",
        "from keras import models, layers\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "# 데이터 처리 및 시각화 라이브러리\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image as pilimg\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "# 파일 시스템 관련 라이브러리\n",
        "import os\n",
        "import shutil\n",
        "import imghdr\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"라이브러리 임포트 완료!\")\n",
        "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
        "print(f\"Keras 버전: {keras.__version__}\")\n",
        "\n",
        "# 경고 메시지 제거 (선택사항)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 경로 설정 및 기본 정보 확인\n",
        "base_path = \"../../data/flowers\"\n",
        "\n",
        "print(\"🌸 Flowers 데이터셋 기본 정보:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 각 클래스별 이미지 개수 확인\n",
        "flower_classes = [\"daisy\", \"dandelion\", \"sunflower\", \"rose\", \"tulip\"]\n",
        "total_images = 0\n",
        "\n",
        "for flower_class in flower_classes:\n",
        "    class_path = os.path.join(base_path, flower_class)\n",
        "    if os.path.exists(class_path):\n",
        "        count = len(os.listdir(class_path))\n",
        "        total_images += count\n",
        "        print(f\"📁 {flower_class.capitalize():>10}: {count:>4}개 이미지\")\n",
        "    else:\n",
        "        print(f\"❌ {flower_class} 폴더를 찾을 수 없습니다!\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"📊 총 이미지 수: {total_images}개\")\n",
        "print(f\"🏷️ 클래스 수: {len(flower_classes)}개\")\n",
        "print(f\"📈 클래스당 평균: {total_images // len(flower_classes)}개\")\n",
        "\n",
        "# 클래스 라벨링 정보\n",
        "print(f\"\\n🏷️ 클래스 라벨 매핑 (알파벳 순서):\")\n",
        "sorted_classes = sorted(flower_classes)\n",
        "for i, class_name in enumerate(sorted_classes):\n",
        "    print(f\"   {i}: {class_name}\")\n",
        "\n",
        "print(\"\\n✅ 데이터셋 탐색 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 데이터 전처리 및 분할\n",
        "\n",
        "꽃 이미지 데이터셋을 모델 학습에 적합한 형태로 전처리하고 Train/Validation/Test로 분할합니다.\n",
        "\n",
        "### 전처리 과정:\n",
        "1. **이미지 리네이밍**: `class_name.index.ext` 형식으로 통일 (예: `daisy.0.jpg`)\n",
        "2. **데이터 분할**: Train(50%) / Validation(25%) / Test(25%) 비율로 분할\n",
        "3. **폴더 구조 생성**: 케라스 `image_dataset_from_directory`에 적합한 구조\n",
        "\n",
        "### 최종 폴더 구조:\n",
        "```\n",
        "flowers_small/\n",
        "├── train/\n",
        "│   ├── daisy/      # 라벨: 0\n",
        "│   ├── dandelion/  # 라벨: 1  \n",
        "│   ├── rose/       # 라벨: 2\n",
        "│   ├── sunflower/  # 라벨: 3\n",
        "│   └── tulip/      # 라벨: 4\n",
        "├── validation/\n",
        "│   └── (동일한 구조)\n",
        "└── test/\n",
        "    └── (동일한 구조)\n",
        "```\n",
        "\n",
        "**중요**: 케라스는 폴더 이름을 **알파벳 순서**로 정렬하여 자동 라벨링합니다!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rename_images_in_class_folder(src_class_dir, class_name, dest_dir):\n",
        "    \"\"\"\n",
        "    특정 클래스 폴더의 이미지들을 'class_name.인덱스.확장자' 형식으로 리네이밍\n",
        "    \n",
        "    Args:\n",
        "        src_class_dir: 원본 클래스 폴더 경로\n",
        "        class_name: 클래스명 (예: 'daisy')\n",
        "        dest_dir: 리네이밍된 이미지가 저장될 폴더\n",
        "    \"\"\"\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일만 필터링\n",
        "    files = [f for f in os.listdir(src_class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    files.sort()\n",
        "\n",
        "    for idx, fname in enumerate(files):\n",
        "        src_path = os.path.join(src_class_dir, fname)\n",
        "        ext = os.path.splitext(fname)[1].lower()\n",
        "        new_name = f\"{class_name}.{idx}{ext}\"\n",
        "        dst_path = os.path.join(dest_dir, new_name)\n",
        "        shutil.copyfile(src_path, dst_path)\n",
        "\n",
        "    print(f\"✅ {class_name} 리네임 완료: {len(files)}개 처리됨.\")\n",
        "\n",
        "\n",
        "def rename_all_classes(original_root_dir, renamed_root_dir):\n",
        "    \"\"\"\n",
        "    모든 클래스의 이미지들을 리네이밍하여 하나의 폴더에 통합\n",
        "    \n",
        "    Args:\n",
        "        original_root_dir: 원본 데이터셋 폴더 (클래스별 하위 폴더 포함)\n",
        "        renamed_root_dir: 리네이밍된 이미지들이 저장될 폴더\n",
        "    \"\"\"\n",
        "    classes = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
        "\n",
        "    # 기존 폴더가 있으면 삭제 후 새로 생성\n",
        "    if os.path.exists(renamed_root_dir):\n",
        "        shutil.rmtree(renamed_root_dir)\n",
        "    os.makedirs(renamed_root_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in classes:\n",
        "        src_class_dir = os.path.join(original_root_dir, class_name)\n",
        "        rename_images_in_class_folder(src_class_dir, class_name, renamed_root_dir)\n",
        "\n",
        "print(\"이미지 리네이밍 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def copy_images_by_class(class_name, original_dataset_dir, dest_dirs, split_ratio=(0.5, 0.25, 0.25)):\n",
        "    \"\"\"\n",
        "    특정 클래스의 이미지들을 Train/Validation/Test로 분할 복사\n",
        "    \n",
        "    Args:\n",
        "        class_name: 클래스명\n",
        "        original_dataset_dir: 리네이밍된 이미지들이 있는 폴더\n",
        "        dest_dirs: [train_dir, val_dir, test_dir] 리스트\n",
        "        split_ratio: 분할 비율 (기본값: 50:25:25)\n",
        "    \"\"\"\n",
        "    # 해당 클래스의 이미지 파일들 찾기\n",
        "    image_files = [\n",
        "        f for f in os.listdir(original_dataset_dir)\n",
        "        if f.startswith(f\"{class_name}.\") and f.lower().endswith(('.jpg', '.jpeg', '.png')) \n",
        "        and os.path.isfile(os.path.join(original_dataset_dir, f))\n",
        "    ]\n",
        "    image_files.sort()\n",
        "    random.shuffle(image_files)  # 랜덤 셔플\n",
        "\n",
        "    # 분할 인덱스 계산\n",
        "    total = len(image_files)\n",
        "    train_end = int(total * split_ratio[0])\n",
        "    val_end = train_end + int(total * split_ratio[1])\n",
        "\n",
        "    # 분할된 파일 리스트\n",
        "    splits = [image_files[:train_end], image_files[train_end:val_end], image_files[val_end:]]\n",
        "\n",
        "    # 각 세트로 파일 복사\n",
        "    for split, dst_dir in zip(splits, dest_dirs):\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        for fname in split:\n",
        "            src = os.path.join(original_dataset_dir, fname)\n",
        "            dst = os.path.join(dst_dir, fname)\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "def ImageCopy(renamed_dataset_dir, base_dir):\n",
        "    \"\"\"\n",
        "    리네이밍된 이미지들을 Train/Validation/Test 폴더로 분할하여 복사\n",
        "    \n",
        "    Args:\n",
        "        renamed_dataset_dir: 리네이밍된 이미지들이 있는 폴더\n",
        "        base_dir: Train/Val/Test 폴더들이 생성될 기본 경로\n",
        "    \"\"\"\n",
        "    categories = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
        "    sets = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "    # 기존 폴더 삭제 후 새로 생성\n",
        "    if os.path.exists(base_dir):\n",
        "        shutil.rmtree(base_dir)\n",
        "    for set_name in sets:\n",
        "        for category in categories:\n",
        "            os.makedirs(os.path.join(base_dir, set_name, category), exist_ok=True)\n",
        "\n",
        "    # 폴더 경로 설정\n",
        "    train_dir = os.path.join(base_dir, \"train\")\n",
        "    val_dir = os.path.join(base_dir, \"validation\")\n",
        "    test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "    # 각 클래스별로 이미지 분할 복사\n",
        "    for category in categories:\n",
        "        print(f\"🔄 {category} 분할 중...\")\n",
        "        copy_images_by_class(\n",
        "            class_name=category,\n",
        "            original_dataset_dir=renamed_dataset_dir,\n",
        "            dest_dirs=[\n",
        "                os.path.join(train_dir, category),\n",
        "                os.path.join(val_dir, category),\n",
        "                os.path.join(test_dir, category)\n",
        "            ],\n",
        "            split_ratio=(0.5, 0.25, 0.25)\n",
        "        )\n",
        "\n",
        "    print(\"\\n✅ 이미지 분할 복사 완료!\\n\")\n",
        "\n",
        "    # 결과 요약 출력\n",
        "    for set_name in sets:\n",
        "        for category in categories:\n",
        "            dir_path = os.path.join(base_dir, set_name, category)\n",
        "            count = len(os.listdir(dir_path))\n",
        "            print(f\"📁 {set_name}/{category}: {count}개\")\n",
        "\n",
        "print(\"데이터 분할 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 전처리 실행\n",
        "print(\"🔄 꽃 이미지 데이터 전처리 시작...\\n\")\n",
        "\n",
        "# 경로 설정\n",
        "original_dataset_dir = \"../../data/flowers\"           # 원본 데이터셋 폴더 (클래스별 하위 폴더 있음)\n",
        "renamed_root = \"../../data/flowers_renamed\"           # 리네이밍된 이미지들이 저장될 위치\n",
        "base_dir = \"../../data/flowers_small\"                 # 최종 분할된 train/val/test 폴더 생성 위치\n",
        "\n",
        "print(f\"📁 경로 설정:\")\n",
        "print(f\"   원본 데이터: {original_dataset_dir}\")\n",
        "print(f\"   리네이밍 저장: {renamed_root}\")\n",
        "print(f\"   분할 저장: {base_dir}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"1단계: 클래스별 이미지들을 daisy.0.jpg 형식으로 리네임 + 통합\")\n",
        "print(\"=\"*60)\n",
        "rename_all_classes(original_dataset_dir, renamed_root)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"2단계: 리네이밍된 이미지를 50:25:25 비율로 train/validation/test 분할 복사\")\n",
        "print(\"=\"*60)\n",
        "ImageCopy(renamed_root, base_dir)\n",
        "\n",
        "print(\"\\n✅ 모든 데이터 전처리 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 로더 생성\n",
        "base_dir = Path(base_dir)\n",
        "\n",
        "print(\"📁 데이터셋 로더 생성 중...\")\n",
        "\n",
        "# batch_size에 지정된 만큼 폴더로부터 이미지를 읽어옵니다\n",
        "# image_size에 지정한 크기로 자동 리사이징됩니다\n",
        "# 케라스는 폴더명을 알파벳 순서로 정렬하여 자동 라벨링합니다\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='int'  # 다중 분류용 정수 라벨\n",
        ")\n",
        "\n",
        "validation_ds = image_dataset_from_directory(\n",
        "    base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "test_ds = image_dataset_from_directory(\n",
        "    base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "print(\"✅ 데이터셋 로더 생성 완료!\")\n",
        "\n",
        "# 클래스 이름 및 라벨 매핑 확인\n",
        "class_names = train_ds.class_names\n",
        "print(f\"\\n🏷️ 클래스 정보:\")\n",
        "print(f\"   클래스 이름: {class_names}\")\n",
        "print(f\"   클래스 수: {len(class_names)}개\")\n",
        "\n",
        "print(f\"\\n📊 라벨 매핑 (알파벳 순서):\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"   {i}: {class_name}\")\n",
        "\n",
        "print(f\"\\n📁 데이터셋 정보:\")\n",
        "print(f\"   Train: {train_ds}\")\n",
        "print(f\"   Validation: {validation_ds}\")\n",
        "print(f\"   Test: {test_ds}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. VGG19 인라인 모델 구축 (다중 분류)\n",
        "\n",
        "VGG19 사전학습 모델을 사용하여 5가지 꽃을 분류하는 다중 분류 모델을 구축합니다.\n",
        "\n",
        "### 다중 분류 모델의 특징:\n",
        "- **출력층**: Dense(5, activation=\"softmax\") - 5개 클래스 확률 출력\n",
        "- **손실 함수**: sparse_categorical_crossentropy - 정수 라벨 다중 분류\n",
        "- **라벨 형태**: 정수 (0: daisy, 1: dandelion, 2: rose, 3: sunflower, 4: tulip)\n",
        "\n",
        "### 모델 구조:\n",
        "```\n",
        "입력 이미지 (180x180x3)\n",
        "    ↓\n",
        "데이터 증강 (RandomFlip, RandomRotation, RandomZoom)\n",
        "    ↓\n",
        "VGG19 전처리 (ImageNet 정규화)\n",
        "    ↓\n",
        "VGG19 CNN (동결) → 특성 추출 (5x5x512)\n",
        "    ↓\n",
        "Flatten → Dense(256) → Dense(128) → Dense(64) → Dense(5, softmax)\n",
        "```\n",
        "\n",
        "### 이진 분류 vs 다중 분류 비교:\n",
        "\n",
        "| 구분 | 이진 분류 (개-고양이) | 다중 분류 (꽃 5종) |\n",
        "|------|---------------------|-------------------|\n",
        "| **클래스 수** | 2개 | 5개 |\n",
        "| **출력층** | Dense(1, sigmoid) | Dense(5, softmax) |\n",
        "| **손실 함수** | binary_crossentropy | sparse_categorical_crossentropy |\n",
        "| **라벨 형태** | 0 또는 1 | 0, 1, 2, 3, 4 |\n",
        "| **출력 해석** | 확률값 (0~1) | 각 클래스별 확률 분포 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_flower_classification_model():\n",
        "    \"\"\"\n",
        "    VGG19를 사용한 꽃 분류 인라인 모델 생성\n",
        "    \n",
        "    Returns:\n",
        "        keras.Model: 컴파일된 다중 분류 모델\n",
        "    \"\"\"\n",
        "    print(\"🔧 VGG19 사전학습 모델 로드 중...\")\n",
        "    \n",
        "    # VGG19 사전학습 모델 로드\n",
        "    conv_base = keras.applications.vgg19.VGG19(\n",
        "        weights=\"imagenet\",        # ImageNet 가중치 사용\n",
        "        include_top=False,         # 상단 분류층 제외 (CNN 부분만)\n",
        "        input_shape=(180, 180, 3)  # 입력 크기 지정\n",
        "    )\n",
        "    \n",
        "    print(\"📊 VGG19 모델 정보:\")\n",
        "    print(f\"   입력 크기: {conv_base.input_shape}\")\n",
        "    print(f\"   출력 크기: {conv_base.output_shape}\")\n",
        "    \n",
        "    # VGG19 가중치 동결 확인\n",
        "    conv_base.trainable = True\n",
        "    print(f\"   동결 전 훈련 가능한 가중치: {len(conv_base.trainable_weights)}개\")\n",
        "    \n",
        "    conv_base.trainable = False  # VGG19 가중치 동결\n",
        "    print(f\"   동결 후 훈련 가능한 가중치: {len(conv_base.trainable_weights)}개\")\n",
        "    print(\"✅ VGG19 가중치 동결 완료!\")\n",
        "    \n",
        "    # 데이터 증강 레이어 정의\n",
        "    data_augmentation = keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),      # 수평 뒤집기\n",
        "        layers.RandomRotation(0.2),          # ±20% 회전\n",
        "        layers.RandomZoom(0.4),              # ±40% 확대/축소\n",
        "    ], name=\"data_augmentation\")\n",
        "    \n",
        "    print(\"🔄 데이터 증강 레이어 정의 완료!\")\n",
        "    \n",
        "    # 전체 모델 구축\n",
        "    print(\"🏗️ 인라인 모델 구축 중...\")\n",
        "    \n",
        "    inputs = keras.Input(shape=(180, 180, 3), name=\"input_layer\")\n",
        "    \n",
        "    # 1. 데이터 증강 적용\n",
        "    x = data_augmentation(inputs)\n",
        "    \n",
        "    # 2. VGG19 전처리 (ImageNet 정규화)\n",
        "    x = keras.applications.vgg19.preprocess_input(x)\n",
        "    \n",
        "    # 3. VGG19 특성 추출 (동결된 상태)\n",
        "    x = conv_base(x)\n",
        "    \n",
        "    # 4. 분류 네트워크 (다중 분류용)\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "    x = layers.Dense(256, activation=\"relu\", name=\"dense_256\")(x)\n",
        "    x = layers.Dense(128, activation=\"relu\", name=\"dense_128\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_64\")(x)\n",
        "    outputs = layers.Dense(5, activation=\"softmax\", name=\"output_5_classes\")(x)  # 5개 클래스 softmax\n",
        "    \n",
        "    # 모델 생성\n",
        "    model = keras.Model(inputs, outputs, name=\"VGG19_Flower_Classifier\")\n",
        "    \n",
        "    # 모델 컴파일 (다중 분류용 설정)\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",  # 정수 라벨 다중 분류\n",
        "        optimizer=\"adam\",                       # Adam 옵티마이저\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    print(\"✅ 꽃 분류 인라인 모델 구축 완료!\")\n",
        "    return model\n",
        "\n",
        "# 모델 생성\n",
        "model = create_flower_classification_model()\n",
        "\n",
        "# VGG19 구조 간략 확인\n",
        "print(\"\\n📋 VGG19 구조 요약 (마지막 몇 개 레이어):\")\n",
        "conv_base.summary()\n",
        "\n",
        "print(\"\\n📋 전체 모델 구조:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 모델 학습 및 저장\n",
        "\n",
        "구축된 꽃 분류 모델을 학습시키고 최적 모델을 자동 저장합니다.\n",
        "\n",
        "### 학습 설정:\n",
        "- **에포크**: 10회 반복 학습\n",
        "- **데이터**: 원본 이미지에 실시간 증강 적용\n",
        "- **콜백**: ModelCheckpoint로 최적 모델 자동 저장\n",
        "- **모니터링**: 검증 손실(val_loss) 기준으로 최적 모델 선정\n",
        "- **저장 파일**: `꽃.keras` (모델), `꽃.bin` (학습 기록)\n",
        "\n",
        "### 다중 분류 모델 학습의 특징:\n",
        "1. **Softmax 출력**: 5개 클래스의 확률 분포 출력\n",
        "2. **Sparse Categorical Crossentropy**: 정수 라벨에 최적화된 손실 함수\n",
        "3. **클래스별 성능**: 각 꽃 종류별로 정확도가 다를 수 있음\n",
        "4. **과적합 방지**: 데이터 증강으로 일반화 성능 향상\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_flower_model(model, train_ds, validation_ds, epochs=10):\n",
        "    \"\"\"\n",
        "    꽃 분류 모델 학습 함수\n",
        "    \n",
        "    Args:\n",
        "        model: 컴파일된 keras 모델\n",
        "        train_ds: 훈련 데이터셋\n",
        "        validation_ds: 검증 데이터셋\n",
        "        epochs: 학습 에포크 수\n",
        "        \n",
        "    Returns:\n",
        "        history: 학습 기록\n",
        "    \"\"\"\n",
        "    print(\"🚀 꽃 분류 모델 학습 시작...\")\n",
        "    print(f\"   에포크: {epochs}회\")\n",
        "    print(f\"   클래스: {len(train_ds.class_names)}개 (다중 분류)\")\n",
        "    print(\"   ※ 인라인 방식은 시간이 오래 걸릴 수 있습니다.\")\n",
        "    \n",
        "    # 콜백 설정 (최적 모델 자동 저장)\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=\"꽃.keras\",              # 모델 저장 경로\n",
        "            save_best_only=True,             # 최고 성능 모델만 저장\n",
        "            monitor=\"val_loss\",              # 검증 손실 기준\n",
        "            verbose=1,                       # 저장 시 메시지 출력\n",
        "            save_format='keras'              # 저장 형식\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # 모델 학습\n",
        "    history = model.fit(\n",
        "        train_ds,                        # 훈련 데이터\n",
        "        epochs=epochs,                   # 에포크 수\n",
        "        validation_data=validation_ds,   # 검증 데이터\n",
        "        callbacks=callbacks,             # 콜백 함수\n",
        "        verbose=1                        # 학습 과정 출력\n",
        "    )\n",
        "    \n",
        "    print(\"✅ 모델 학습 완료!\")\n",
        "    \n",
        "    # 학습 기록 저장\n",
        "    with open(\"꽃.bin\", \"wb\") as file:\n",
        "        pickle.dump(history.history, file)\n",
        "    print(\"💾 학습 기록 저장 완료: 꽃.bin\")\n",
        "    \n",
        "    # 최종 성능 출력\n",
        "    final_train_acc = history.history['accuracy'][-1]\n",
        "    final_val_acc = history.history['val_accuracy'][-1]\n",
        "    final_train_loss = history.history['loss'][-1]\n",
        "    final_val_loss = history.history['val_loss'][-1]\n",
        "    \n",
        "    print(f\"\\n📊 최종 학습 결과:\")\n",
        "    print(f\"   훈련 정확도: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "    print(f\"   검증 정확도: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "    print(f\"   훈련 손실: {final_train_loss:.4f}\")\n",
        "    print(f\"   검증 손실: {final_val_loss:.4f}\")\n",
        "    \n",
        "    return history\n",
        "\n",
        "# 모델 학습 실행\n",
        "print(\"=\"*70)\n",
        "print(\"🌸 꽃 분류 모델 학습 시작\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "history = train_flower_model(model, train_ds, validation_ds, epochs=10)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ 꽃 분류 모델 학습 완료!\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 결과 분석 및 시각화\n",
        "\n",
        "학습 과정과 결과를 시각화하고 다중 분류 모델의 성능을 분석합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_flower_training_results(history):\n",
        "    \"\"\"\n",
        "    꽃 분류 모델의 학습 과정을 시각화\n",
        "    \n",
        "    Args:\n",
        "        history: model.fit()에서 반환된 History 객체 또는 딕셔너리\n",
        "    \"\"\"\n",
        "    if history is None:\n",
        "        print(\"❌ 학습 기록이 없습니다.\")\n",
        "        return\n",
        "    \n",
        "    # history 객체에서 딕셔너리 추출\n",
        "    if hasattr(history, 'history'):\n",
        "        hist_dict = history.history\n",
        "    else:\n",
        "        hist_dict = history\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # 정확도 그래프\n",
        "    ax1.plot(hist_dict['accuracy'], 'bo-', label='Training Accuracy', linewidth=2, markersize=6)\n",
        "    ax1.plot(hist_dict['val_accuracy'], 'ro-', label='Validation Accuracy', linewidth=2, markersize=6)\n",
        "    ax1.set_title('🌸 Flower Classification Accuracy', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim([0, 1])\n",
        "    \n",
        "    # 손실 그래프\n",
        "    ax2.plot(hist_dict['loss'], 'bo-', label='Training Loss', linewidth=2, markersize=6)\n",
        "    ax2.plot(hist_dict['val_loss'], 'ro-', label='Validation Loss', linewidth=2, markersize=6)\n",
        "    ax2.set_title('🌸 Flower Classification Loss', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 최종 성능 출력\n",
        "    final_train_acc = hist_dict['accuracy'][-1]\n",
        "    final_val_acc = hist_dict['val_accuracy'][-1]\n",
        "    final_train_loss = hist_dict['loss'][-1]\n",
        "    final_val_loss = hist_dict['val_loss'][-1]\n",
        "    \n",
        "    print(\"📊 다중 분류 모델 최종 성능:\")\n",
        "    print(f\"   훈련 정확도: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "    print(f\"   검증 정확도: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "    print(f\"   훈련 손실: {final_train_loss:.4f}\")\n",
        "    print(f\"   검증 손실: {final_val_loss:.4f}\")\n",
        "    \n",
        "    # 과적합 분석\n",
        "    if final_train_acc - final_val_acc > 0.1:\n",
        "        print(\"⚠️ 과적합이 감지되었습니다. 더 많은 데이터 증강이나 정규화가 필요할 수 있습니다.\")\n",
        "    else:\n",
        "        print(\"✅ 적절한 학습이 이루어졌습니다.\")\n",
        "\n",
        "# 학습 결과 시각화\n",
        "if 'history' in locals() and history is not None:\n",
        "    print(\"📈 꽃 분류 모델 학습 과정 시각화:\")\n",
        "    plot_flower_training_results(history)\n",
        "else:\n",
        "    print(\"ℹ️ 학습 기록을 시각화하려면 먼저 모델을 학습하세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_flower_model_on_test(model_path=\"꽃.keras\"):\n",
        "    \"\"\"\n",
        "    저장된 꽃 분류 모델을 로드하여 테스트 데이터로 평가\n",
        "    \n",
        "    Args:\n",
        "        model_path: 저장된 모델 파일 경로\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 저장된 모델 로드\n",
        "        print(\"📥 저장된 꽃 분류 모델 로드 중...\")\n",
        "        best_model = keras.models.load_model(model_path)\n",
        "        print(\"✅ 모델 로드 완료!\")\n",
        "        \n",
        "        # 테스트 데이터로 평가\n",
        "        print(\"🔍 테스트 데이터로 다중 분류 성능 평가 중...\")\n",
        "        test_loss, test_accuracy = best_model.evaluate(test_ds, verbose=1)\n",
        "        \n",
        "        print(f\"\\n🎯 꽃 분류 테스트 결과:\")\n",
        "        print(f\"   테스트 손실: {test_loss:.4f}\")\n",
        "        print(f\"   테스트 정확도: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "        \n",
        "        # 클래스별 예측 분석\n",
        "        print(\"\\n🔍 클래스별 예측 분석을 위해 일부 테스트 데이터 예측...\")\n",
        "        \n",
        "        # 첫 번째 배치만 예측해보기\n",
        "        for images, labels in test_ds.take(1):\n",
        "            predictions = best_model.predict(images, verbose=0)\n",
        "            predicted_classes = np.argmax(predictions, axis=1)\n",
        "            \n",
        "            print(f\"\\n📊 첫 번째 배치 예측 결과 (처음 10개):\")\n",
        "            class_names_list = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "            \n",
        "            for i in range(min(10, len(images))):\n",
        "                true_class = labels[i].numpy()\n",
        "                pred_class = predicted_classes[i]\n",
        "                confidence = predictions[i][pred_class]\n",
        "                \n",
        "                true_name = class_names_list[true_class]\n",
        "                pred_name = class_names_list[pred_class]\n",
        "                \n",
        "                status = \"✅\" if true_class == pred_class else \"❌\"\n",
        "                print(f\"   {status} 실제: {true_name:>10} | 예측: {pred_name:>10} (신뢰도: {confidence:.3f})\")\n",
        "            \n",
        "            break\n",
        "        \n",
        "        return best_model, test_accuracy\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(\"❌ 저장된 모델이 없습니다. 먼저 모델을 학습하세요!\")\n",
        "        return None, None\n",
        "\n",
        "# 테스트 평가 실행\n",
        "print(\"🧪 테스트 데이터로 꽃 분류 모델 최종 평가:\")\n",
        "best_model, test_acc = evaluate_flower_model_on_test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 결론 및 다중 분류 vs 이진 분류 비교\n",
        "\n",
        "### 완료된 작업:\n",
        "✅ **다중 분류 Transfer Learning 구현**: VGG19를 활용한 5가지 꽃 분류  \n",
        "✅ **인라인 방식 적용**: 실시간 데이터 증강 및 end-to-end 학습  \n",
        "✅ **데이터 전처리**: 체계적인 이미지 리네이밍 및 분할  \n",
        "✅ **모델 최적화**: ModelCheckpoint로 최적 모델 자동 저장  \n",
        "✅ **성능 평가**: 테스트 데이터로 다중 분류 정확도 측정  \n",
        "\n",
        "### 🌸 다중 분류 vs 🐱🐶 이진 분류 심화 비교\n",
        "\n",
        "| 특성 | 다중 분류 (꽃 5종) | 이진 분류 (개-고양이) |\n",
        "|------|-------------------|---------------------|\n",
        "| **클래스 수** | 5개 | 2개 |\n",
        "| **출력층 구조** | Dense(5, softmax) | Dense(1, sigmoid) |\n",
        "| **출력 해석** | 5개 확률의 합=1 | 단일 확률값 (0~1) |\n",
        "| **손실 함수** | sparse_categorical_crossentropy | binary_crossentropy |\n",
        "| **라벨 형태** | 정수 (0,1,2,3,4) | 이진 (0 또는 1) |\n",
        "| **예측 방법** | argmax(predictions) | predictions > 0.5 |\n",
        "| **난이도** | 상대적으로 어려움 | 상대적으로 쉬움 |\n",
        "| **클래스 불균형 가능성** | 5개 클래스 간 불균형 | 2개 클래스 간 불균형 |\n",
        "\n",
        "### 다중 분류의 특징과 도전 과제:\n",
        "\n",
        "#### 🎯 장점:\n",
        "- **실용성**: 실제 문제에서 2개 이상의 클래스가 일반적\n",
        "- **확장성**: 클래스 추가가 상대적으로 용이\n",
        "- **정보량**: 더 세분화된 분류 정보 제공\n",
        "\n",
        "#### ⚠️ 도전 과제:\n",
        "- **복잡성 증가**: 클래스 수가 늘어날수록 학습 난이도 상승\n",
        "- **클래스 불균형**: 일부 클래스의 데이터가 부족할 수 있음\n",
        "- **혼동 행렬**: 어떤 클래스들이 서로 혼동되는지 분석 필요\n",
        "- **성능 평가**: 전체 정확도 외에 클래스별 성능 분석 필요\n",
        "\n",
        "### 실무 적용 가이드:\n",
        "\n",
        "#### 🌸 다중 분류 프로젝트에 적합한 경우:\n",
        "- **상품 분류**: 패션, 전자제품 등 다양한 카테고리\n",
        "- **의료 영상**: 여러 질병 유형 진단\n",
        "- **자연어 처리**: 감정 분석, 토픽 분류\n",
        "- **이미지 분류**: 동물, 식물, 객체 인식\n",
        "\n",
        "#### 🐱🐶 이진 분류 프로젝트에 적합한 경우:\n",
        "- **정상/비정상 판별**: 의료 진단, 품질 검사\n",
        "- **스팸 필터링**: 스팸/정상 메일 구분\n",
        "- **승인/거부**: 대출 심사, 입학 허가\n",
        "- **긍정/부정**: 리뷰 감정 분석\n",
        "\n",
        "### 다음 단계 제안:\n",
        "1. **클래스별 성능 분석**: Confusion Matrix로 혼동되는 클래스 파악\n",
        "2. **데이터 증강 개선**: 클래스별 특성에 맞는 증강 기법 적용\n",
        "3. **앙상블 모델**: 여러 모델의 예측을 결합하여 성능 향상\n",
        "4. **Fine-tuning**: VGG19 상위 레이어도 함께 학습\n",
        "5. **다른 아키텍처**: ResNet, EfficientNet 등 비교 실험\n",
        "\n",
        "### 학습한 핵심 개념:\n",
        "- **다중 분류**: Softmax와 Sparse Categorical Crossentropy\n",
        "- **클래스 라벨링**: 알파벳 순서 자동 라벨링 시스템\n",
        "- **데이터 전처리**: 체계적인 이미지 리네이밍 및 분할\n",
        "- **Transfer Learning**: 사전학습 모델의 도메인 적응\n",
        "- **모델 평가**: 다중 클래스 환경에서의 성능 측정\n",
        "\n",
        "### 💡 핵심 교훈:\n",
        "이진 분류에서 다중 분류로 확장하는 것은 단순히 출력층만 바꾸는 것이 아니라, 데이터 처리부터 성능 평가까지 전체 파이프라인의 이해가 필요합니다. 실무에서는 대부분 다중 분류 문제이므로, 이 프로젝트를 통해 익힌 기술들이 매우 유용할 것입니다.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
