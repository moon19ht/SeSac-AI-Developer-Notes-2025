{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Transfer Learning ì¸ë¼ì¸ ë°©ì‹ - ê°œ-ê³ ì–‘ì´ ë¶„ë¥˜ í”„ë¡œì íŠ¸\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ VGG19 ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ì‚¬ìš©í•œ **ì¸ë¼ì¸(Inline) ë°©ì‹**ì˜ Transfer Learningìœ¼ë¡œ ê°œì™€ ê³ ì–‘ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "## í”„ë¡œì íŠ¸ ê°œìš”\n",
        "- **ëª©í‘œ**: VGG19 ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•œ ê°œ-ê³ ì–‘ì´ ì´ì§„ ë¶„ë¥˜\n",
        "- **ë°©ë²•**: Transfer Learning (ì¸ë¼ì¸ ë°©ì‹)\n",
        "- **ë°ì´í„°**: Cats and Dogs ë°ì´í„°ì…‹\n",
        "- **í”„ë ˆì„ì›Œí¬**: TensorFlow/Keras\n",
        "\n",
        "## ì¸ë¼ì¸ ë°©ì‹ vs íˆ¬ìŠ¤í…Œì´ì§€ ë°©ì‹\n",
        "\n",
        "### ğŸ”„ ì¸ë¼ì¸ ë°©ì‹ (ì´ í”„ë¡œì íŠ¸)\n",
        "- **ë°©ë²•**: VGG19ë¥¼ ì „ì²´ ëª¨ë¸ì— í¬í•¨ì‹œì¼œ end-to-end í•™ìŠµ\n",
        "- **ì¥ì **: \n",
        "  - ì›ë³¸ ì´ë¯¸ì§€ì— ë°ì´í„° ì¦ê°•ì´ ì§ì ‘ ì ìš©\n",
        "  - ê³¼ì í•© ë°©ì§€ íš¨ê³¼\n",
        "  - ì‹¤ë¬´ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë°©ì‹\n",
        "- **ë‹¨ì **: íˆ¬ìŠ¤í…Œì´ì§€ ë°©ì‹ë³´ë‹¤ í•™ìŠµ ì†ë„ê°€ ëŠë¦¼\n",
        "\n",
        "### âš¡ íˆ¬ìŠ¤í…Œì´ì§€ ë°©ì‹ (ì´ì „ í”„ë¡œì íŠ¸)\n",
        "- **ë°©ë²•**: VGG19 íŠ¹ì„±ì„ ë¯¸ë¦¬ ì¶”ì¶œí•˜ì—¬ numpy ë°°ì—´ë¡œ ì €ì¥ â†’ ë¶„ë¥˜ í•™ìŠµ\n",
        "- **ì¥ì **: í›ˆë ¨ ì†ë„ê°€ ë§¤ìš° ë¹ ë¦„\n",
        "- **ë‹¨ì **: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë§ìŒ, ë°ì´í„° ì¦ê°• ì œí•œì \n",
        "\n",
        "## í”„ë¡œì íŠ¸ êµ¬ì¡°\n",
        "1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
        "2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• \n",
        "3. VGG19 ì¸ë¼ì¸ ëª¨ë¸ êµ¬ì¶•\n",
        "4. ëª¨ë¸ í•™ìŠµ ë° ì €ì¥\n",
        "5. ê²°ê³¼ ë¶„ì„ ë° ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
        "\n",
        "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë”¥ëŸ¬ë‹ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras import models, layers\n",
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "# ë°ì´í„° ì²˜ë¦¬ ë° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# íŒŒì¼ ì‹œìŠ¤í…œ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "import gdown  # êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œìš©\n",
        "\n",
        "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")\n",
        "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
        "print(f\"Keras ë²„ì „: {keras.__version__}\")\n",
        "\n",
        "# ê²½ê³  ë©”ì‹œì§€ ì œê±° (ì„ íƒì‚¬í•­)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• \n",
        "\n",
        "Cats and Dogs ë°ì´í„°ì…‹ì„ Train/Validation/Testë¡œ ë¶„í• í•˜ê³  ë°ì´í„° ë¡œë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ë°ì´í„° êµ¬ì¡°:\n",
        "- **ì›ë³¸**: `cats_and_dogs/train/` (ì´ 25,000ì¥)\n",
        "- **ë¶„í•  í›„**: \n",
        "  - Train: 0~999ë²ˆ ì´ë¯¸ì§€ (ê° í´ë˜ìŠ¤ 1,000ì¥)\n",
        "  - Validation: 1000~1499ë²ˆ ì´ë¯¸ì§€ (ê° í´ë˜ìŠ¤ 500ì¥)\n",
        "  - Test: 1500~1999ë²ˆ ì´ë¯¸ì§€ (ê° í´ë˜ìŠ¤ 500ì¥)\n",
        "\n",
        "### í´ë” êµ¬ì¡°:\n",
        "```\n",
        "cats_and_dogs_small/\n",
        "â”œâ”€â”€ train/\n",
        "â”‚   â”œâ”€â”€ cat/    # ìë™ ë¼ë²¨ë§: 0\n",
        "â”‚   â””â”€â”€ dog/    # ìë™ ë¼ë²¨ë§: 1\n",
        "â”œâ”€â”€ validation/\n",
        "â”‚   â”œâ”€â”€ cat/\n",
        "â”‚   â””â”€â”€ dog/\n",
        "â””â”€â”€ test/\n",
        "    â”œâ”€â”€ cat/\n",
        "    â””â”€â”€ dog/\n",
        "```\n",
        "\n",
        "**ì¤‘ìš”**: ì¼€ë¼ìŠ¤ëŠ” í´ë” ì´ë¦„ì„ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìë™ ë¼ë²¨ë§í•©ë‹ˆë‹¤!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n",
        "original_dir = pathlib.Path(\"../../data/cats_and_dogs/train\")\n",
        "new_base_dir = pathlib.Path(\"../../data/cats_and_dogs/cats_and_dogs_small\")\n",
        "\n",
        "print(\"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • ì™„ë£Œ!\")\n",
        "print(f\"ì›ë³¸ ë°ì´í„°: {original_dir}\")\n",
        "print(f\"ë¶„í•  ì €ì¥: {new_base_dir}\")\n",
        "\n",
        "# ì„ íƒì‚¬í•­: êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
        "# gdown.download(id='18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd', output='dogs-vs-cats.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_subset(subset_name, start_index, end_index):\n",
        "    \"\"\"\n",
        "    íŠ¹ì • ë²”ìœ„ì˜ ì´ë¯¸ì§€ë“¤ì„ ì§€ì •ëœ í´ë”ë¡œ ë³µì‚¬\n",
        "    \n",
        "    Args:\n",
        "        subset_name: 'train', 'validation', 'test'\n",
        "        start_index: ì‹œì‘ ì¸ë±ìŠ¤\n",
        "        end_index: ë ì¸ë±ìŠ¤ (í¬í•¨ë˜ì§€ ì•ŠìŒ)\n",
        "    \"\"\"\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        # ëª©ì ì§€ í´ë” ìƒì„± (WindowsPath ê°ì²´ ì‚¬ìš©)\n",
        "        dir_path = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        \n",
        "        # íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì˜ˆ: cat.0.jpg, cat.1.jpg, ...)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        \n",
        "        # íŒŒì¼ ë³µì‚¬\n",
        "        for fname in fnames:\n",
        "            src_path = original_dir / fname\n",
        "            dst_path = dir_path / fname\n",
        "            if src_path.exists():  # ì›ë³¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ë³µì‚¬\n",
        "                shutil.copyfile(src_path, dst_path)\n",
        "        \n",
        "        print(f\"âœ… {subset_name}/{category}: {len(fnames)}ê°œ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ\")\n",
        "\n",
        "print(\"ë°ì´í„° ë¶„í•  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¶„í•  ì‹¤í–‰\n",
        "print(\"ğŸ”„ ë°ì´í„° ë¶„í•  ì‹œì‘...\")\n",
        "\n",
        "# Train ì„¸íŠ¸: ê° í´ë˜ìŠ¤ 1,000ì¥ (0~999)\n",
        "make_subset(\"train\", 0, 1000)\n",
        "\n",
        "# Validation ì„¸íŠ¸: ê° í´ë˜ìŠ¤ 500ì¥ (1000~1499)\n",
        "make_subset(\"validation\", 1000, 1500)\n",
        "\n",
        "# Test ì„¸íŠ¸: ê° í´ë˜ìŠ¤ 500ì¥ (1500~1999)\n",
        "make_subset(\"test\", 1500, 2000)\n",
        "\n",
        "print(\"\\nâœ… ëª¨ë“  ë°ì´í„° ë¶„í•  ì™„ë£Œ!\")\n",
        "print(f\"ğŸ“Š ì´ ë°ì´í„°: Train({1000*2}), Validation({500*2}), Test({500*2})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ ë¡œë” ìƒì„±\n",
        "# batch_sizeì— ì§€ì •ëœ ë§Œí¼ í´ë”ë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.\n",
        "# image_sizeì— ì§€ì •í•œ í¬ê¸°ë¡œ ìë™ ë¦¬ì‚¬ì´ì§•ë©ë‹ˆë‹¤.\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='binary'  # ì´ì§„ ë¶„ë¥˜ (0: cat, 1: dog)\n",
        ")\n",
        "\n",
        "validation_ds = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='binary'\n",
        ")\n",
        "\n",
        "test_ds = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='binary'\n",
        ")\n",
        "\n",
        "print(\"âœ… ë°ì´í„°ì…‹ ë¡œë” ìƒì„± ì™„ë£Œ!\")\n",
        "print(f\"ğŸ“ Train: {train_ds}\")\n",
        "print(f\"ğŸ“ Validation: {validation_ds}\")\n",
        "print(f\"ğŸ“ Test: {test_ds}\")\n",
        "\n",
        "# í´ë˜ìŠ¤ ì´ë¦„ í™•ì¸ (ì•ŒíŒŒë²³ ìˆœì„œë¡œ ìë™ ë¼ë²¨ë§)\n",
        "class_names = train_ds.class_names\n",
        "print(f\"ğŸ·ï¸ í´ë˜ìŠ¤: {class_names}\")  # ['cat', 'dog'] â†’ [0, 1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. VGG19 ì¸ë¼ì¸ ëª¨ë¸ êµ¬ì¶•\n",
        "\n",
        "VGG19 ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ì „ì²´ ëª¨ë¸ì— í¬í•¨ì‹œì¼œ end-to-end í•™ìŠµì´ ê°€ëŠ¥í•œ ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ì¸ë¼ì¸ ë°©ì‹ì˜ íŠ¹ì§•:\n",
        "1. **ëª¨ë¸ í†µí•©**: VGG19ê°€ ì „ì²´ ëª¨ë¸ì˜ ì¼ë¶€ê°€ ë¨\n",
        "2. **ì‹¤ì‹œê°„ ì „ì²˜ë¦¬**: ì›ë³¸ ì´ë¯¸ì§€ì— ì§ì ‘ ë°ì´í„° ì¦ê°• ì ìš©\n",
        "3. **ë™ê²° í•™ìŠµ**: VGG19 ê°€ì¤‘ì¹˜ëŠ” ê³ ì •, ë¶„ë¥˜ì¸µë§Œ í•™ìŠµ\n",
        "4. **End-to-End**: ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì²˜ë¦¬\n",
        "\n",
        "### ëª¨ë¸ êµ¬ì¡°:\n",
        "```\n",
        "ì…ë ¥ ì´ë¯¸ì§€ (180x180x3)\n",
        "    â†“\n",
        "ë°ì´í„° ì¦ê°• (RandomFlip, RandomRotation, RandomZoom)\n",
        "    â†“\n",
        "VGG19 ì „ì²˜ë¦¬ (ImageNet ì •ê·œí™”)\n",
        "    â†“\n",
        "VGG19 CNN (ë™ê²°) â†’ íŠ¹ì„± ì¶”ì¶œ (5x5x512)\n",
        "    â†“\n",
        "Flatten â†’ Dense(256) â†’ Dense(128) â†’ Dense(64) â†’ Dense(1, sigmoid)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_inline_model():\n",
        "    \"\"\"\n",
        "    VGG19ë¥¼ í¬í•¨í•œ ì¸ë¼ì¸ ë°©ì‹ì˜ Transfer Learning ëª¨ë¸ ìƒì„±\n",
        "    \n",
        "    Returns:\n",
        "        keras.Model: ì»´íŒŒì¼ëœ ì¸ë¼ì¸ ëª¨ë¸\n",
        "    \"\"\"\n",
        "    print(\"ğŸ”§ VGG19 ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "    \n",
        "    # VGG19 ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ\n",
        "    conv_base = keras.applications.vgg19.VGG19(\n",
        "        weights=\"imagenet\",        # ImageNet ê°€ì¤‘ì¹˜ ì‚¬ìš©\n",
        "        include_top=False,         # ìƒë‹¨ ë¶„ë¥˜ì¸µ ì œì™¸ (CNN ë¶€ë¶„ë§Œ)\n",
        "        input_shape=(180, 180, 3)  # ì…ë ¥ í¬ê¸°ëŠ” ë°ì´í„°ì…‹ê³¼ ì¼ì¹˜í•´ì•¼ í•¨\n",
        "    )\n",
        "    \n",
        "    print(\"ğŸ“Š VGG19 ëª¨ë¸ ì •ë³´:\")\n",
        "    print(f\"   ì…ë ¥ í¬ê¸°: {conv_base.input_shape}\")\n",
        "    print(f\"   ì¶œë ¥ í¬ê¸°: {conv_base.output_shape}\")\n",
        "    \n",
        "    # VGG19 ê°€ì¤‘ì¹˜ ë™ê²° ìƒíƒœ í™•ì¸\n",
        "    conv_base.trainable = True\n",
        "    print(f\"   ë™ê²° ì „ í›ˆë ¨ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜: {len(conv_base.trainable_weights)}ê°œ\")\n",
        "    \n",
        "    conv_base.trainable = False  # VGG19 ê°€ì¤‘ì¹˜ ë™ê²°\n",
        "    print(f\"   ë™ê²° í›„ í›ˆë ¨ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜: {len(conv_base.trainable_weights)}ê°œ\")\n",
        "    \n",
        "    print(\"âœ… VGG19 ê°€ì¤‘ì¹˜ ë™ê²° ì™„ë£Œ! (íŠ¹ì„± ì¶”ì¶œê¸°ë¡œë§Œ ì‚¬ìš©)\")\n",
        "    \n",
        "    return conv_base\n",
        "\n",
        "# VGG19 ëª¨ë¸ ìƒì„±\n",
        "conv_base = create_inline_model()\n",
        "\n",
        "# VGG19 êµ¬ì¡° í™•ì¸\n",
        "print(\"\\nğŸ“‹ VGG19 ëª¨ë¸ êµ¬ì¡° ìš”ì•½:\")\n",
        "conv_base.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_complete_model(conv_base):\n",
        "    \"\"\"\n",
        "    VGG19 ê¸°ë°˜ì˜ ì™„ì „í•œ ì¸ë¼ì¸ ëª¨ë¸ êµ¬ì¶•\n",
        "    \n",
        "    Args:\n",
        "        conv_base: ë™ê²°ëœ VGG19 ëª¨ë¸\n",
        "        \n",
        "    Returns:\n",
        "        keras.Model: ì™„ì„±ëœ ì¸ë¼ì¸ ëª¨ë¸\n",
        "    \"\"\"\n",
        "    print(\"ğŸ—ï¸ ì¸ë¼ì¸ ëª¨ë¸ êµ¬ì¶• ì¤‘...\")\n",
        "    \n",
        "    # ë°ì´í„° ì¦ê°• ë ˆì´ì–´ ì •ì˜\n",
        "    data_augmentation = keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),      # ìˆ˜í‰ ë’¤ì§‘ê¸°\n",
        "        layers.RandomRotation(0.2),          # Â±20% íšŒì „ (72ë„)\n",
        "        layers.RandomZoom(0.4),              # Â±40% í™•ëŒ€/ì¶•ì†Œ\n",
        "    ], name=\"data_augmentation\")\n",
        "    \n",
        "    # ì „ì²´ ëª¨ë¸ êµ¬ì¶•\n",
        "    inputs = keras.Input(shape=(180, 180, 3), name=\"input_layer\")\n",
        "    \n",
        "    # 1. ë°ì´í„° ì¦ê°• ì ìš© (ì›ë³¸ ì´ë¯¸ì§€ì— ì§ì ‘ ì ìš©!)\n",
        "    x = data_augmentation(inputs)\n",
        "    \n",
        "    # 2. VGG19 ì „ì²˜ë¦¬ (ImageNet ì •ê·œí™”)\n",
        "    x = keras.applications.vgg19.preprocess_input(x)\n",
        "    \n",
        "    # 3. VGG19 íŠ¹ì„± ì¶”ì¶œ (ë™ê²°ëœ ìƒíƒœ)\n",
        "    x = conv_base(x)  # ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ì§€ë§Œ ë” ì •í™•í•œ íŠ¹ì„± ì¶”ì¶œ\n",
        "    \n",
        "    # 4. ë¶„ë¥˜ ë„¤íŠ¸ì›Œí¬\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "    x = layers.Dense(256, activation=\"relu\", name=\"dense_256\")(x)\n",
        "    x = layers.Dense(128, activation=\"relu\", name=\"dense_128\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_64\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
        "    \n",
        "    # ëª¨ë¸ ìƒì„±\n",
        "    model = keras.Model(inputs, outputs, name=\"VGG19_Inline_Model\")\n",
        "    \n",
        "    # ëª¨ë¸ ì»´íŒŒì¼\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=\"rmsprop\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    print(\"âœ… ì¸ë¼ì¸ ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ!\")\n",
        "    return model\n",
        "\n",
        "# ì™„ì „í•œ ëª¨ë¸ êµ¬ì¶•\n",
        "model = build_complete_model(conv_base)\n",
        "\n",
        "print(\"\\nğŸ“‹ ì™„ì„±ëœ ëª¨ë¸ êµ¬ì¡°:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. ëª¨ë¸ í•™ìŠµ ë° ì €ì¥\n",
        "\n",
        "êµ¬ì¶•ëœ ì¸ë¼ì¸ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  ìµœì  ëª¨ë¸ì„ ìë™ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í•™ìŠµ ì„¤ì •:\n",
        "- **ì—í¬í¬**: 10íšŒ ë°˜ë³µ í•™ìŠµ\n",
        "- **ë°ì´í„°**: ì›ë³¸ ì´ë¯¸ì§€ì— ì‹¤ì‹œê°„ ì¦ê°• ì ìš©\n",
        "- **ì½œë°±**: ModelCheckpointë¡œ ìµœì  ëª¨ë¸ ìë™ ì €ì¥\n",
        "- **ëª¨ë‹ˆí„°ë§**: ê²€ì¦ ì†ì‹¤(val_loss) ê¸°ì¤€ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì„ ì •\n",
        "\n",
        "### ì¸ë¼ì¸ ë°©ì‹ì˜ ì¥ì :\n",
        "1. **ì‹¤ì‹œê°„ ì¦ê°•**: ë§¤ë²ˆ ë‹¤ë¥¸ ì¦ê°•ëœ ì´ë¯¸ì§€ë¡œ í•™ìŠµ\n",
        "2. **ê³¼ì í•© ë°©ì§€**: ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ\n",
        "3. **end-to-end**: ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_inline_model(model, train_ds, validation_ds, epochs=10):\n",
        "    \"\"\"\n",
        "    ì¸ë¼ì¸ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜\n",
        "    \n",
        "    Args:\n",
        "        model: ì»´íŒŒì¼ëœ keras ëª¨ë¸\n",
        "        train_ds: í›ˆë ¨ ë°ì´í„°ì…‹\n",
        "        validation_ds: ê²€ì¦ ë°ì´í„°ì…‹\n",
        "        epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
        "        \n",
        "    Returns:\n",
        "        history: í•™ìŠµ ê¸°ë¡\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ ì¸ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
        "    print(f\"   ì—í¬í¬: {epochs}íšŒ\")\n",
        "    print(\"   â€» ì¸ë¼ì¸ ë°©ì‹ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "    \n",
        "    # ì½œë°± ì„¤ì • (ìµœì  ëª¨ë¸ ìë™ ì €ì¥)\n",
        "    callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "            filepath=\"../../data/Cats_and_Dogs_Pre-Learning.keras\",\n",
        "            save_weights_only=True,  # ê°€ì¤‘ì¹˜ë§Œ ì €ì¥ (ê¶Œì¥)\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # ëª¨ë¸ í•™ìŠµ\n",
        "    history = model.fit(\n",
        "        train_ds,                    # í›ˆë ¨ ë°ì´í„°\n",
        "        epochs=epochs,               # ì—í¬í¬ ìˆ˜\n",
        "        validation_data=validation_ds, # ê²€ì¦ ë°ì´í„°\n",
        "        callbacks=callbacks,         # ì½œë°± í•¨ìˆ˜\n",
        "        verbose=1                    # í•™ìŠµ ê³¼ì • ì¶œë ¥\n",
        "    )\n",
        "    \n",
        "    print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
        "    \n",
        "    # í•™ìŠµ ê¸°ë¡ ì €ì¥\n",
        "    with open(\"../../data/Cats_and_Dogs_Pre-Learning.bin\", \"wb\") as file:\n",
        "        pickle.dump(history.history, file)\n",
        "    print(\"ğŸ’¾ í•™ìŠµ ê¸°ë¡ ì €ì¥ ì™„ë£Œ: Cats_and_Dogs_Pre-Learning.bin\")\n",
        "    \n",
        "    return history\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
        "history = train_inline_model(model, train_ds, validation_ds, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
        "\n",
        "í•™ìŠµ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_results(history):\n",
        "    \"\"\"\n",
        "    í•™ìŠµ ê³¼ì •ì˜ ì •í™•ë„ì™€ ì†ì‹¤ì„ ì‹œê°í™”\n",
        "    \n",
        "    Args:\n",
        "        history: model.fit()ì—ì„œ ë°˜í™˜ëœ History ê°ì²´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬\n",
        "    \"\"\"\n",
        "    \n",
        "    if history is None:\n",
        "        print(\"âŒ í•™ìŠµ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    # history ê°ì²´ì—ì„œ ë”•ì…”ë„ˆë¦¬ ì¶”ì¶œ\n",
        "    if hasattr(history, 'history'):\n",
        "        hist_dict = history.history\n",
        "    else:\n",
        "        hist_dict = history\n",
        "    \n",
        "    \n",
        "    # í•œê¸€ í°íŠ¸ ì„¤ì • (ë‚˜ëˆ”ê³ ë”•)\n",
        "    plt.rcParams['font.family'] = 'NanumGothic'\n",
        "    plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # ì •í™•ë„ ê·¸ë˜í”„\n",
        "    ax1.plot(hist_dict['accuracy'], 'bo-', label='Training Accuracy', linewidth=2)\n",
        "    ax1.plot(hist_dict['val_accuracy'], 'ro-', label='Validation Accuracy', linewidth=2)\n",
        "    ax1.set_title('Model Accuracy (ì¸ë¼ì¸ ë°©ì‹)', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # ì†ì‹¤ ê·¸ë˜í”„\n",
        "    ax2.plot(hist_dict['loss'], 'bo-', label='Training Loss', linewidth=2)\n",
        "    ax2.plot(hist_dict['val_loss'], 'ro-', label='Validation Loss', linewidth=2)\n",
        "    ax2.set_title('Model Loss (ì¸ë¼ì¸ ë°©ì‹)', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥\n",
        "    final_train_acc = hist_dict['accuracy'][-1]\n",
        "    final_val_acc = hist_dict['val_accuracy'][-1]\n",
        "    final_train_loss = hist_dict['loss'][-1]\n",
        "    final_val_loss = hist_dict['val_loss'][-1]\n",
        "    \n",
        "    print(\"ğŸ“Š ìµœì¢… í•™ìŠµ ê²°ê³¼:\")\n",
        "    print(f\"   í›ˆë ¨ ì •í™•ë„: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "    print(f\"   ê²€ì¦ ì •í™•ë„: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "    print(f\"   í›ˆë ¨ ì†ì‹¤: {final_train_loss:.4f}\")\n",
        "    print(f\"   ê²€ì¦ ì†ì‹¤: {final_val_loss:.4f}\")\n",
        "\n",
        "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n",
        "if 'history' in locals() and history is not None:\n",
        "    print(\"ğŸ“ˆ ì¸ë¼ì¸ ë°©ì‹ í•™ìŠµ ê³¼ì • ì‹œê°í™”:\")\n",
        "    plot_training_results(history)\n",
        "else:\n",
        "    print(\"â„¹ï¸ í•™ìŠµ ê¸°ë¡ì„ ì‹œê°í™”í•˜ë ¤ë©´ ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model_on_test(model_path=\"../../data/Cats_and_Dogs_Pre-Learning.keras\"):\n",
        "    \"\"\"\n",
        "    ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€\n",
        "    \n",
        "    Args:\n",
        "        model_path: ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\n",
        "        print(\"ğŸ“¥ ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "        best_model = keras.models.load_model(model_path)\n",
        "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
        "        \n",
        "        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€\n",
        "        print(\"ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ ì¤‘...\")\n",
        "        test_loss, test_accuracy = best_model.evaluate(test_ds, verbose=1)\n",
        "        \n",
        "        print(f\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "        \n",
        "        return best_model, test_accuracy\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”!\")\n",
        "        return None, None\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ í‰ê°€ ì‹¤í–‰\n",
        "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€:\")\n",
        "best_model, test_acc = evaluate_model_on_test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. ê²°ë¡  ë° ì¸ë¼ì¸ vs íˆ¬ìŠ¤í…Œì´ì§€ ë¹„êµ\n",
        "\n",
        "### ì™„ë£Œëœ ì‘ì—…:\n",
        "âœ… **ì¸ë¼ì¸ Transfer Learning êµ¬í˜„**: VGG19ë¥¼ ì „ì²´ ëª¨ë¸ì— í†µí•©  \n",
        "âœ… **ì‹¤ì‹œê°„ ë°ì´í„° ì¦ê°•**: ì›ë³¸ ì´ë¯¸ì§€ì— ì§ì ‘ ì ìš©  \n",
        "âœ… **End-to-End í•™ìŠµ**: ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸  \n",
        "âœ… **ëª¨ë¸ ìµœì í™”**: ModelCheckpointë¡œ ìµœì  ëª¨ë¸ ìë™ ì €ì¥  \n",
        "âœ… **ì„±ëŠ¥ í‰ê°€**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… ì •í™•ë„ ì¸¡ì •  \n",
        "\n",
        "### ğŸ”„ ì¸ë¼ì¸ ë°©ì‹ vs âš¡ íˆ¬ìŠ¤í…Œì´ì§€ ë°©ì‹ ë¹„êµ\n",
        "\n",
        "| íŠ¹ì„± | ì¸ë¼ì¸ ë°©ì‹ (ì´ í”„ë¡œì íŠ¸) | íˆ¬ìŠ¤í…Œì´ì§€ ë°©ì‹ (ì´ì „ í”„ë¡œì íŠ¸) |\n",
        "|------|---------------------------|--------------------------------|\n",
        "| **í•™ìŠµ ì†ë„** | ëŠë¦¼ (ì‹¤ì‹œê°„ VGG19 ì²˜ë¦¬) | ë¹ ë¦„ (ì‚¬ì „ ì¶”ì¶œëœ íŠ¹ì„± ì‚¬ìš©) |\n",
        "| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | ì ìŒ (ë°°ì¹˜ë³„ ì²˜ë¦¬) | ë§ìŒ (ëª¨ë“  íŠ¹ì„±ì„ ë©”ëª¨ë¦¬ì— ì €ì¥) |\n",
        "| **ë°ì´í„° ì¦ê°•** | ì›ë³¸ ì´ë¯¸ì§€ì— ì§ì ‘ ì ìš© | ì¶”ì¶œëœ íŠ¹ì„±ì—ë§Œ ì ìš© (ì œí•œì ) |\n",
        "| **ê³¼ì í•© ë°©ì§€** | ìš°ìˆ˜ (ì‹¤ì‹œê°„ ì¦ê°•) | ë³´í†µ (ì œí•œì  ì¦ê°•) |\n",
        "| **í™•ì¥ì„±** | ìš°ìˆ˜ (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì í•©) | ì œí•œì  (ë©”ëª¨ë¦¬ í•œê³„) |\n",
        "| **ì‹¤ë¬´ í™œìš©ë„** | ë†’ìŒ (ì¼ë°˜ì  ë°©ì‹) | ë‚®ìŒ (í”„ë¡œí† íƒ€ì´í•‘ìš©) |\n",
        "| **ëª¨ë¸ ë°°í¬** | ì‰¬ì›€ (í•˜ë‚˜ì˜ ëª¨ë¸) | ë³µì¡í•¨ (íŠ¹ì„± ì¶”ì¶œ + ë¶„ë¥˜) |\n",
        "\n",
        "### ì–¸ì œ ì–´ë–¤ ë°©ì‹ì„ ì‚¬ìš©í• ê¹Œ?\n",
        "\n",
        "#### ğŸ”„ ì¸ë¼ì¸ ë°©ì‹ ì¶”ì²œ ìƒí™©:\n",
        "- **ì‹¤ë¬´ í”„ë¡œì íŠ¸**: ì‹¤ì œ ì„œë¹„ìŠ¤ì— ë°°í¬í•  ëª¨ë¸\n",
        "- **ëŒ€ìš©ëŸ‰ ë°ì´í„°**: ë©”ëª¨ë¦¬ ì œì•½ì´ ìˆëŠ” í™˜ê²½\n",
        "- **ë†’ì€ ì„±ëŠ¥ ìš”êµ¬**: ê³¼ì í•© ë°©ì§€ê°€ ì¤‘ìš”í•œ ê²½ìš°\n",
        "- **ëª¨ë¸ ë°°í¬**: í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ end-to-end ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°\n",
        "\n",
        "#### âš¡ íˆ¬ìŠ¤í…Œì´ì§€ ë°©ì‹ ì¶”ì²œ ìƒí™©:\n",
        "- **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘**: ì•„ì´ë””ì–´ ê²€ì¦ì´ ëª©ì \n",
        "- **ì†Œê·œëª¨ ë°ì´í„°**: ë©”ëª¨ë¦¬ì— ëª¨ë“  íŠ¹ì„±ì„ ì €ì¥ ê°€ëŠ¥\n",
        "- **ë¹ ë¥¸ ì‹¤í—˜**: ì—¬ëŸ¬ ë¶„ë¥˜ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸\n",
        "- **êµìœ¡ ëª©ì **: Transfer Learning ê°œë… ì´í•´\n",
        "\n",
        "### ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:\n",
        "1. **Fine-tuning êµ¬í˜„**: VGG19 ìƒìœ„ ë ˆì´ì–´ë„ í•¨ê»˜ í•™ìŠµ\n",
        "2. **ë‹¤ë¥¸ ì‚¬ì „í•™ìŠµ ëª¨ë¸**: ResNet, EfficientNet, MobileNet ë¹„êµ\n",
        "3. **ì•™ìƒë¸” ëª¨ë¸**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê²°í•©\n",
        "4. **ì‹¤ì œ ë°°í¬**: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë˜ëŠ” API ì„œë²„ êµ¬ì¶•\n",
        "\n",
        "### í•™ìŠµí•œ í•µì‹¬ ê°œë…:\n",
        "- **ì¸ë¼ì¸ Transfer Learning**: ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸ì— í†µí•©\n",
        "- **ì‹¤ì‹œê°„ ë°ì´í„° ì¦ê°•**: ì›ë³¸ ì´ë¯¸ì§€ì— ì§ì ‘ ì ìš©í•˜ëŠ” ì¦ê°• ê¸°ë²•\n",
        "- **ê°€ì¤‘ì¹˜ ë™ê²°**: ì‚¬ì „í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •í•˜ì—¬ íŠ¹ì„± ì¶”ì¶œê¸°ë¡œ í™œìš©\n",
        "- **End-to-End í•™ìŠµ**: ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì²˜ë¦¬\n",
        "- **ì½œë°± ì‹œìŠ¤í…œ**: í•™ìŠµ ì¤‘ ìë™ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì €ì¥\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
