{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Transfer Learning 인라인 방식 - 개-고양이 분류 프로젝트\n",
        "\n",
        "이 노트북은 VGG19 사전학습 모델을 사용한 **인라인(Inline) 방식**의 Transfer Learning으로 개와 고양이 이미지를 분류하는 프로젝트입니다.\n",
        "\n",
        "## 프로젝트 개요\n",
        "- **목표**: VGG19 사전학습 모델을 활용한 개-고양이 이진 분류\n",
        "- **방법**: Transfer Learning (인라인 방식)\n",
        "- **데이터**: Cats and Dogs 데이터셋\n",
        "- **프레임워크**: TensorFlow/Keras\n",
        "\n",
        "## 인라인 방식 vs 투스테이지 방식\n",
        "\n",
        "### 🔄 인라인 방식 (이 프로젝트)\n",
        "- **방법**: VGG19를 전체 모델에 포함시켜 end-to-end 학습\n",
        "- **장점**: \n",
        "  - 원본 이미지에 데이터 증강이 직접 적용\n",
        "  - 과적합 방지 효과\n",
        "  - 실무에서 가장 많이 사용되는 방식\n",
        "- **단점**: 투스테이지 방식보다 학습 속도가 느림\n",
        "\n",
        "### ⚡ 투스테이지 방식 (이전 프로젝트)\n",
        "- **방법**: VGG19 특성을 미리 추출하여 numpy 배열로 저장 → 분류 학습\n",
        "- **장점**: 훈련 속도가 매우 빠름\n",
        "- **단점**: 메모리 사용량 많음, 데이터 증강 제한적\n",
        "\n",
        "## 프로젝트 구조\n",
        "1. 라이브러리 임포트 및 환경 설정\n",
        "2. 데이터 전처리 및 분할\n",
        "3. VGG19 인라인 모델 구축\n",
        "4. 모델 학습 및 저장\n",
        "5. 결과 분석 및 비교\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 라이브러리 임포트 및 환경 설정\n",
        "\n",
        "필요한 라이브러리들을 임포트합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 딥러닝 관련 라이브러리\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras import models, layers\n",
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "# 데이터 처리 및 시각화 라이브러리\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# 파일 시스템 관련 라이브러리\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "import gdown  # 구글 드라이브에서 데이터 다운로드용\n",
        "\n",
        "print(\"라이브러리 임포트 완료!\")\n",
        "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
        "print(f\"Keras 버전: {keras.__version__}\")\n",
        "\n",
        "# 경고 메시지 제거 (선택사항)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 데이터 전처리 및 분할\n",
        "\n",
        "Cats and Dogs 데이터셋을 Train/Validation/Test로 분할하고 데이터 로더를 생성합니다.\n",
        "\n",
        "### 데이터 구조:\n",
        "- **원본**: `cats_and_dogs/train/` (총 25,000장)\n",
        "- **분할 후**: \n",
        "  - Train: 0~999번 이미지 (각 클래스 1,000장)\n",
        "  - Validation: 1000~1499번 이미지 (각 클래스 500장)\n",
        "  - Test: 1500~1999번 이미지 (각 클래스 500장)\n",
        "\n",
        "### 폴더 구조:\n",
        "```\n",
        "cats_and_dogs_small/\n",
        "├── train/\n",
        "│   ├── cat/    # 자동 라벨링: 0\n",
        "│   └── dog/    # 자동 라벨링: 1\n",
        "├── validation/\n",
        "│   ├── cat/\n",
        "│   └── dog/\n",
        "└── test/\n",
        "    ├── cat/\n",
        "    └── dog/\n",
        "```\n",
        "\n",
        "**중요**: 케라스는 폴더 이름을 오름차순으로 정렬하여 자동 라벨링합니다!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 경로 설정\n",
        "original_dir = pathlib.Path(\"../../data/cats_and_dogs/train\")\n",
        "new_base_dir = pathlib.Path(\"../../data/cats_and_dogs/cats_and_dogs_small\")\n",
        "\n",
        "print(\"📁 데이터셋 경로 설정 완료!\")\n",
        "print(f\"원본 데이터: {original_dir}\")\n",
        "print(f\"분할 저장: {new_base_dir}\")\n",
        "\n",
        "# 선택사항: 구글 드라이브에서 데이터 다운로드\n",
        "# gdown.download(id='18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd', output='dogs-vs-cats.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_subset(subset_name, start_index, end_index):\n",
        "    \"\"\"\n",
        "    특정 범위의 이미지들을 지정된 폴더로 복사\n",
        "    \n",
        "    Args:\n",
        "        subset_name: 'train', 'validation', 'test'\n",
        "        start_index: 시작 인덱스\n",
        "        end_index: 끝 인덱스 (포함되지 않음)\n",
        "    \"\"\"\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        # 목적지 폴더 생성 (WindowsPath 객체 사용)\n",
        "        dir_path = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        \n",
        "        # 파일명 리스트 생성 (예: cat.0.jpg, cat.1.jpg, ...)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        \n",
        "        # 파일 복사\n",
        "        for fname in fnames:\n",
        "            src_path = original_dir / fname\n",
        "            dst_path = dir_path / fname\n",
        "            if src_path.exists():  # 원본 파일이 존재하는 경우에만 복사\n",
        "                shutil.copyfile(src_path, dst_path)\n",
        "        \n",
        "        print(f\"✅ {subset_name}/{category}: {len(fnames)}개 이미지 복사 완료\")\n",
        "\n",
        "print(\"데이터 분할 함수 정의 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 분할 실행\n",
        "print(\"🔄 데이터 분할 시작...\")\n",
        "\n",
        "# Train 세트: 각 클래스 1,000장 (0~999)\n",
        "make_subset(\"train\", 0, 1000)\n",
        "\n",
        "# Validation 세트: 각 클래스 500장 (1000~1499)\n",
        "make_subset(\"validation\", 1000, 1500)\n",
        "\n",
        "# Test 세트: 각 클래스 500장 (1500~1999)\n",
        "make_subset(\"test\", 1500, 2000)\n",
        "\n",
        "print(\"\\n✅ 모든 데이터 분할 완료!\")\n",
        "print(f\"📊 총 데이터: Train({1000*2}), Validation({500*2}), Test({500*2})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 로더 생성\n",
        "# batch_size에 지정된 만큼 폴더로부터 이미지를 읽어옵니다.\n",
        "# image_size에 지정한 크기로 자동 리사이징됩니다.\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='binary'  # 이진 분류 (0: cat, 1: dog)\n",
        ")\n",
        "\n",
        "validation_ds = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='binary'\n",
        ")\n",
        "\n",
        "test_ds = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    label_mode='binary'\n",
        ")\n",
        "\n",
        "print(\"✅ 데이터셋 로더 생성 완료!\")\n",
        "print(f\"📁 Train: {train_ds}\")\n",
        "print(f\"📁 Validation: {validation_ds}\")\n",
        "print(f\"📁 Test: {test_ds}\")\n",
        "\n",
        "# 클래스 이름 확인 (알파벳 순서로 자동 라벨링)\n",
        "class_names = train_ds.class_names\n",
        "print(f\"🏷️ 클래스: {class_names}\")  # ['cat', 'dog'] → [0, 1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. VGG19 인라인 모델 구축\n",
        "\n",
        "VGG19 사전학습 모델을 전체 모델에 포함시켜 end-to-end 학습이 가능한 모델을 구축합니다.\n",
        "\n",
        "### 인라인 방식의 특징:\n",
        "1. **모델 통합**: VGG19가 전체 모델의 일부가 됨\n",
        "2. **실시간 전처리**: 원본 이미지에 직접 데이터 증강 적용\n",
        "3. **동결 학습**: VGG19 가중치는 고정, 분류층만 학습\n",
        "4. **End-to-End**: 입력부터 출력까지 하나의 모델로 처리\n",
        "\n",
        "### 모델 구조:\n",
        "```\n",
        "입력 이미지 (180x180x3)\n",
        "    ↓\n",
        "데이터 증강 (RandomFlip, RandomRotation, RandomZoom)\n",
        "    ↓\n",
        "VGG19 전처리 (ImageNet 정규화)\n",
        "    ↓\n",
        "VGG19 CNN (동결) → 특성 추출 (5x5x512)\n",
        "    ↓\n",
        "Flatten → Dense(256) → Dense(128) → Dense(64) → Dense(1, sigmoid)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_inline_model():\n",
        "    \"\"\"\n",
        "    VGG19를 포함한 인라인 방식의 Transfer Learning 모델 생성\n",
        "    \n",
        "    Returns:\n",
        "        keras.Model: 컴파일된 인라인 모델\n",
        "    \"\"\"\n",
        "    print(\"🔧 VGG19 사전학습 모델 로드 중...\")\n",
        "    \n",
        "    # VGG19 사전학습 모델 로드\n",
        "    conv_base = keras.applications.vgg19.VGG19(\n",
        "        weights=\"imagenet\",        # ImageNet 가중치 사용\n",
        "        include_top=False,         # 상단 분류층 제외 (CNN 부분만)\n",
        "        input_shape=(180, 180, 3)  # 입력 크기는 데이터셋과 일치해야 함\n",
        "    )\n",
        "    \n",
        "    print(\"📊 VGG19 모델 정보:\")\n",
        "    print(f\"   입력 크기: {conv_base.input_shape}\")\n",
        "    print(f\"   출력 크기: {conv_base.output_shape}\")\n",
        "    \n",
        "    # VGG19 가중치 동결 상태 확인\n",
        "    conv_base.trainable = True\n",
        "    print(f\"   동결 전 훈련 가능한 가중치: {len(conv_base.trainable_weights)}개\")\n",
        "    \n",
        "    conv_base.trainable = False  # VGG19 가중치 동결\n",
        "    print(f\"   동결 후 훈련 가능한 가중치: {len(conv_base.trainable_weights)}개\")\n",
        "    \n",
        "    print(\"✅ VGG19 가중치 동결 완료! (특성 추출기로만 사용)\")\n",
        "    \n",
        "    return conv_base\n",
        "\n",
        "# VGG19 모델 생성\n",
        "conv_base = create_inline_model()\n",
        "\n",
        "# VGG19 구조 확인\n",
        "print(\"\\n📋 VGG19 모델 구조 요약:\")\n",
        "conv_base.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_complete_model(conv_base):\n",
        "    \"\"\"\n",
        "    VGG19 기반의 완전한 인라인 모델 구축\n",
        "    \n",
        "    Args:\n",
        "        conv_base: 동결된 VGG19 모델\n",
        "        \n",
        "    Returns:\n",
        "        keras.Model: 완성된 인라인 모델\n",
        "    \"\"\"\n",
        "    print(\"🏗️ 인라인 모델 구축 중...\")\n",
        "    \n",
        "    # 데이터 증강 레이어 정의\n",
        "    data_augmentation = keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),      # 수평 뒤집기\n",
        "        layers.RandomRotation(0.2),          # ±20% 회전 (72도)\n",
        "        layers.RandomZoom(0.4),              # ±40% 확대/축소\n",
        "    ], name=\"data_augmentation\")\n",
        "    \n",
        "    # 전체 모델 구축\n",
        "    inputs = keras.Input(shape=(180, 180, 3), name=\"input_layer\")\n",
        "    \n",
        "    # 1. 데이터 증강 적용 (원본 이미지에 직접 적용!)\n",
        "    x = data_augmentation(inputs)\n",
        "    \n",
        "    # 2. VGG19 전처리 (ImageNet 정규화)\n",
        "    x = keras.applications.vgg19.preprocess_input(x)\n",
        "    \n",
        "    # 3. VGG19 특성 추출 (동결된 상태)\n",
        "    x = conv_base(x)  # 시간이 오래 걸리지만 더 정확한 특성 추출\n",
        "    \n",
        "    # 4. 분류 네트워크\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "    x = layers.Dense(256, activation=\"relu\", name=\"dense_256\")(x)\n",
        "    x = layers.Dense(128, activation=\"relu\", name=\"dense_128\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_64\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
        "    \n",
        "    # 모델 생성\n",
        "    model = keras.Model(inputs, outputs, name=\"VGG19_Inline_Model\")\n",
        "    \n",
        "    # 모델 컴파일\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=\"rmsprop\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    print(\"✅ 인라인 모델 구축 완료!\")\n",
        "    return model\n",
        "\n",
        "# 완전한 모델 구축\n",
        "model = build_complete_model(conv_base)\n",
        "\n",
        "print(\"\\n📋 완성된 모델 구조:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 모델 학습 및 저장\n",
        "\n",
        "구축된 인라인 모델을 학습시키고 최적 모델을 자동 저장합니다.\n",
        "\n",
        "### 학습 설정:\n",
        "- **에포크**: 10회 반복 학습\n",
        "- **데이터**: 원본 이미지에 실시간 증강 적용\n",
        "- **콜백**: ModelCheckpoint로 최적 모델 자동 저장\n",
        "- **모니터링**: 검증 손실(val_loss) 기준으로 최적 모델 선정\n",
        "\n",
        "### 인라인 방식의 장점:\n",
        "1. **실시간 증강**: 매번 다른 증강된 이미지로 학습\n",
        "2. **과적합 방지**: 데이터 증강으로 일반화 성능 향상\n",
        "3. **end-to-end**: 입력부터 출력까지 하나의 파이프라인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_inline_model(model, train_ds, validation_ds, epochs=10):\n",
        "    \"\"\"\n",
        "    인라인 모델 학습 함수\n",
        "    \n",
        "    Args:\n",
        "        model: 컴파일된 keras 모델\n",
        "        train_ds: 훈련 데이터셋\n",
        "        validation_ds: 검증 데이터셋\n",
        "        epochs: 학습 에포크 수\n",
        "        \n",
        "    Returns:\n",
        "        history: 학습 기록\n",
        "    \"\"\"\n",
        "    print(\"🚀 인라인 모델 학습 시작...\")\n",
        "    print(f\"   에포크: {epochs}회\")\n",
        "    print(\"   ※ 인라인 방식은 시간이 오래 걸릴 수 있습니다.\")\n",
        "    \n",
        "    # 콜백 설정 (최적 모델 자동 저장)\n",
        "    callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "            filepath=\"../../data/Cats_and_Dogs_Pre-Learning.keras\",\n",
        "            save_weights_only=True,  # 가중치만 저장 (권장)\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # 모델 학습\n",
        "    history = model.fit(\n",
        "        train_ds,                    # 훈련 데이터\n",
        "        epochs=epochs,               # 에포크 수\n",
        "        validation_data=validation_ds, # 검증 데이터\n",
        "        callbacks=callbacks,         # 콜백 함수\n",
        "        verbose=1                    # 학습 과정 출력\n",
        "    )\n",
        "    \n",
        "    print(\"✅ 모델 학습 완료!\")\n",
        "    \n",
        "    # 학습 기록 저장\n",
        "    with open(\"../../data/Cats_and_Dogs_Pre-Learning.bin\", \"wb\") as file:\n",
        "        pickle.dump(history.history, file)\n",
        "    print(\"💾 학습 기록 저장 완료: Cats_and_Dogs_Pre-Learning.bin\")\n",
        "    \n",
        "    return history\n",
        "\n",
        "# 모델 학습 실행\n",
        "history = train_inline_model(model, train_ds, validation_ds, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 결과 분석 및 시각화\n",
        "\n",
        "학습 과정과 결과를 시각화하고 분석합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_results(history):\n",
        "    \"\"\"\n",
        "    학습 과정의 정확도와 손실을 시각화\n",
        "    \n",
        "    Args:\n",
        "        history: model.fit()에서 반환된 History 객체 또는 딕셔너리\n",
        "    \"\"\"\n",
        "    \n",
        "    if history is None:\n",
        "        print(\"❌ 학습 기록이 없습니다.\")\n",
        "        return\n",
        "    \n",
        "    # history 객체에서 딕셔너리 추출\n",
        "    if hasattr(history, 'history'):\n",
        "        hist_dict = history.history\n",
        "    else:\n",
        "        hist_dict = history\n",
        "    \n",
        "    \n",
        "    # 한글 폰트 설정 (나눔고딕)\n",
        "    plt.rcParams['font.family'] = 'NanumGothic'\n",
        "    plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # 정확도 그래프\n",
        "    ax1.plot(hist_dict['accuracy'], 'bo-', label='Training Accuracy', linewidth=2)\n",
        "    ax1.plot(hist_dict['val_accuracy'], 'ro-', label='Validation Accuracy', linewidth=2)\n",
        "    ax1.set_title('Model Accuracy (인라인 방식)', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 손실 그래프\n",
        "    ax2.plot(hist_dict['loss'], 'bo-', label='Training Loss', linewidth=2)\n",
        "    ax2.plot(hist_dict['val_loss'], 'ro-', label='Validation Loss', linewidth=2)\n",
        "    ax2.set_title('Model Loss (인라인 방식)', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 최종 성능 출력\n",
        "    final_train_acc = hist_dict['accuracy'][-1]\n",
        "    final_val_acc = hist_dict['val_accuracy'][-1]\n",
        "    final_train_loss = hist_dict['loss'][-1]\n",
        "    final_val_loss = hist_dict['val_loss'][-1]\n",
        "    \n",
        "    print(\"📊 최종 학습 결과:\")\n",
        "    print(f\"   훈련 정확도: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
        "    print(f\"   검증 정확도: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "    print(f\"   훈련 손실: {final_train_loss:.4f}\")\n",
        "    print(f\"   검증 손실: {final_val_loss:.4f}\")\n",
        "\n",
        "# 학습 결과 시각화\n",
        "if 'history' in locals() and history is not None:\n",
        "    print(\"📈 인라인 방식 학습 과정 시각화:\")\n",
        "    plot_training_results(history)\n",
        "else:\n",
        "    print(\"ℹ️ 학습 기록을 시각화하려면 먼저 모델을 학습하세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model_on_test(model_path=\"../../data/Cats_and_Dogs_Pre-Learning.keras\"):\n",
        "    \"\"\"\n",
        "    저장된 모델을 로드하여 테스트 데이터로 평가\n",
        "    \n",
        "    Args:\n",
        "        model_path: 저장된 모델 파일 경로\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 저장된 모델 로드\n",
        "        print(\"📥 저장된 모델 로드 중...\")\n",
        "        best_model = keras.models.load_model(model_path)\n",
        "        print(\"✅ 모델 로드 완료!\")\n",
        "        \n",
        "        # 테스트 데이터로 평가\n",
        "        print(\"🔍 테스트 데이터 평가 중...\")\n",
        "        test_loss, test_accuracy = best_model.evaluate(test_ds, verbose=1)\n",
        "        \n",
        "        print(f\"\\n🎯 테스트 결과:\")\n",
        "        print(f\"   테스트 손실: {test_loss:.4f}\")\n",
        "        print(f\"   테스트 정확도: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "        \n",
        "        return best_model, test_accuracy\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(\"❌ 저장된 모델이 없습니다. 먼저 모델을 학습하세요!\")\n",
        "        return None, None\n",
        "\n",
        "# 테스트 평가 실행\n",
        "print(\"🧪 테스트 데이터로 최종 평가:\")\n",
        "best_model, test_acc = evaluate_model_on_test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 결론 및 인라인 vs 투스테이지 비교\n",
        "\n",
        "### 완료된 작업:\n",
        "✅ **인라인 Transfer Learning 구현**: VGG19를 전체 모델에 통합  \n",
        "✅ **실시간 데이터 증강**: 원본 이미지에 직접 적용  \n",
        "✅ **End-to-End 학습**: 입력부터 출력까지 하나의 파이프라인  \n",
        "✅ **모델 최적화**: ModelCheckpoint로 최적 모델 자동 저장  \n",
        "✅ **성능 평가**: 테스트 데이터로 최종 정확도 측정  \n",
        "\n",
        "### 🔄 인라인 방식 vs ⚡ 투스테이지 방식 비교\n",
        "\n",
        "| 특성 | 인라인 방식 (이 프로젝트) | 투스테이지 방식 (이전 프로젝트) |\n",
        "|------|---------------------------|--------------------------------|\n",
        "| **학습 속도** | 느림 (실시간 VGG19 처리) | 빠름 (사전 추출된 특성 사용) |\n",
        "| **메모리 사용** | 적음 (배치별 처리) | 많음 (모든 특성을 메모리에 저장) |\n",
        "| **데이터 증강** | 원본 이미지에 직접 적용 | 추출된 특성에만 적용 (제한적) |\n",
        "| **과적합 방지** | 우수 (실시간 증강) | 보통 (제한적 증강) |\n",
        "| **확장성** | 우수 (대용량 데이터셋 적합) | 제한적 (메모리 한계) |\n",
        "| **실무 활용도** | 높음 (일반적 방식) | 낮음 (프로토타이핑용) |\n",
        "| **모델 배포** | 쉬움 (하나의 모델) | 복잡함 (특성 추출 + 분류) |\n",
        "\n",
        "### 언제 어떤 방식을 사용할까?\n",
        "\n",
        "#### 🔄 인라인 방식 추천 상황:\n",
        "- **실무 프로젝트**: 실제 서비스에 배포할 모델\n",
        "- **대용량 데이터**: 메모리 제약이 있는 환경\n",
        "- **높은 성능 요구**: 과적합 방지가 중요한 경우\n",
        "- **모델 배포**: 하나의 모델로 end-to-end 처리가 필요한 경우\n",
        "\n",
        "#### ⚡ 투스테이지 방식 추천 상황:\n",
        "- **빠른 프로토타이핑**: 아이디어 검증이 목적\n",
        "- **소규모 데이터**: 메모리에 모든 특성을 저장 가능\n",
        "- **빠른 실험**: 여러 분류 모델을 빠르게 테스트\n",
        "- **교육 목적**: Transfer Learning 개념 이해\n",
        "\n",
        "### 다음 단계 제안:\n",
        "1. **Fine-tuning 구현**: VGG19 상위 레이어도 함께 학습\n",
        "2. **다른 사전학습 모델**: ResNet, EfficientNet, MobileNet 비교\n",
        "3. **앙상블 모델**: 여러 모델의 예측을 결합\n",
        "4. **실제 배포**: 웹 애플리케이션 또는 API 서버 구축\n",
        "\n",
        "### 학습한 핵심 개념:\n",
        "- **인라인 Transfer Learning**: 사전학습 모델을 전체 파이프라인에 통합\n",
        "- **실시간 데이터 증강**: 원본 이미지에 직접 적용하는 증강 기법\n",
        "- **가중치 동결**: 사전학습된 가중치를 고정하여 특성 추출기로 활용\n",
        "- **End-to-End 학습**: 입력부터 출력까지 하나의 모델로 처리\n",
        "- **콜백 시스템**: 학습 중 자동으로 최적 모델 저장\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
