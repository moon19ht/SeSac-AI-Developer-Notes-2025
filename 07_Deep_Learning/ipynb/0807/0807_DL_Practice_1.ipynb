{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글 자연어 처리 실습 - KoNLPy 활용\n",
    "\n",
    "## 개요\n",
    "KoNLPy를 사용한 한글 자연어 처리 실습입니다.\n",
    "- 형태소 분석\n",
    "- 품사 태깅\n",
    "- 명사 추출\n",
    "- 정규화\n",
    "- 어간 추출\n",
    "- 정규식을 이용한 텍스트 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KoNLPy 설치 및 환경 설정\n",
    "\n",
    "KoNLPy는 한글 자연어처리를 도와주는 모듈로, Java 라이브러리를 기반으로 합니다.\n",
    "\n",
    "### 설치 방법:\n",
    "1. Java를 먼저 설치하고 환경변수 등록\n",
    "2. CMD 관리자권한으로 실행\n",
    "3. `conda activate mytensorflow`\n",
    "4. `pip install konlpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt   # 옛날에 twitter => Okt\n",
    "import re  # 정규식을 사용하기 위한 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 기본 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텍스트:\n",
      "한글 자연어 처리는 매우 어렵습니다. ㅜㅜ  네이버 영화평론 분석을 해보겠습니다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"한글 자연어 처리는 매우 어렵습니다. ㅜㅜ  네이버 영화평론 분석을 해보겠습니다\"\n",
    "\n",
    "okt = Okt()\n",
    "print(\"원본 텍스트:\")\n",
    "print(text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 형태소 분석\n",
    "텍스트를 의미있는 단위인 형태소로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석\n",
      "['한글', '자연어', '처리', '는', '매우', '어렵습니다', '.', 'ㅜㅜ', '네이버', '영화평론', '분석', '을', '해보겠습니다']\n"
     ]
    }
   ],
   "source": [
    "print(\"형태소 분석\")\n",
    "morphs_result = okt.morphs(text)\n",
    "print(morphs_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 품사 태깅\n",
    "한글을 쪼개서 품사를 부여합니다. (예: 자연어 → 명사)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사태깅\n",
      "[('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('매우', 'Noun'), ('어렵습니다', 'Adjective'), ('.', 'Punctuation'), ('ㅜㅜ', 'KoreanParticle'), ('네이버', 'Noun'), ('영화평론', 'Noun'), ('분석', 'Noun'), ('을', 'Josa'), ('해보겠습니다', 'Verb')]\n"
     ]
    }
   ],
   "source": [
    "print(\"품사태깅\")\n",
    "pos_result = okt.pos(text)\n",
    "print(pos_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명사추출\n",
      "['한글', '자연어', '처리', '매우', '네이버', '영화평론', '분석']\n"
     ]
    }
   ],
   "source": [
    "print(\"명사추출\")\n",
    "nouns_result = okt.nouns(text)\n",
    "print(nouns_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 정규화\n",
    "줄임말이나 인터넷 용어를 표준형으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화\n",
      "한글 자연어 처리는 매우 어렵습니다. ㅜㅜ  네이버 영화평론 분석을 해보겠습니다\n"
     ]
    }
   ],
   "source": [
    "print(\"정규화\")\n",
    "normalize_result = okt.normalize(text)\n",
    "print(normalize_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 어간 추출\n",
    "동사와 형용사의 원형을 복원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간추출\n",
      "['한글', '자연어', '처리', '는', '매우', '어렵다', '.', 'ㅜㅜ', '네이버', '영화평론', '분석', '을', '해보다']\n"
     ]
    }
   ],
   "source": [
    "print(\"어간추출\")\n",
    "stem_result = okt.morphs(text, stem=True)\n",
    "print(stem_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 정규식을 이용한 텍스트 전처리\n",
    "\n",
    "정규식으로 불필요한 문자들을 제거합니다. (영어에서 구두점 제거와 유사)\n",
    "\n",
    "### re.sub() 함수 사용법:\n",
    "```python\n",
    "re.sub(r\"패턴\", \"대체할문자열\", \"내용\", count=0)\n",
    "```\n",
    "- 패턴: 찾을 정규식 패턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    텍스트 전처리 함수\n",
    "    - 대문자를 소문자로 변환\n",
    "    - 한글, 영어, 숫자, 공백만 남기고 나머지 제거\n",
    "    \"\"\"\n",
    "    text = text.lower()  # 대문자를 -> 소문자로 바꿔서 처리하자\n",
    "    text = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9\\s]\", \"\", text)\n",
    "    # r -> escape문자를 무력화   \\n  -> 줄바꿈 기호  패턴에 \\ 를 직접사용할 경우에 escape문자로 인식하면안된다\n",
    "    # [] -> 필요한 문자열들을 묶어준다. or\n",
    "    # [^가-힣] : 한글만  ^ - 를 제외하고 , [^] 제외하고의 의미   ^[] 시작하는 의미\n",
    "    # [^가-힣]  : 완성형 한글만 인식함\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 정규식 전처리 적용 및 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텍스트:\n",
      "ㅋㅋ AI는 인간의 일을 대체하게 될겁니다. 장점도 있고 단점도 있습니다. ! 인간의 반복적이고 힘든일을 대체했으면 ~\n",
      "\n",
      "전처리 후 텍스트:\n",
      "ㅋㅋ ai는 인간의 일을 대체하게 될겁니다 장점도 있고 단점도 있습니다  인간의 반복적이고 힘든일을 대체했으면 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text2 = \"ㅋㅋ AI는 인간의 일을 대체하게 될겁니다. 장점도 있고 단점도 있습니다. ! 인간의 반복적이고 힘든일을 대체했으면 ~\"\n",
    "\n",
    "print(\"원본 텍스트:\")\n",
    "print(text2)\n",
    "print()\n",
    "\n",
    "cleaned_text = clean_text(text2)\n",
    "print(\"전처리 후 텍스트:\")\n",
    "print(cleaned_text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 텍스트의 형태소 분석:\n",
      "['ㅋㅋ', 'ai', '는', '인간', '의', '일', '을', '대체', '하게', '될', '겁니다', '장점', '도', '있고', '단점', '도', '있습니다', '인간', '의', '반복', '적', '이고', '힘든', '일', '을', '대체', '했으면']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "print(\"전처리된 텍스트의 형태소 분석:\")\n",
    "cleaned_morphs = okt.morphs(cleaned_text)\n",
    "print(cleaned_morphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 결과 비교 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전처리 전후 비교 ===\n",
      "원본: ㅋㅋ AI는 인간의 일을 대체하게 될겁니다. 장점도 있고 단점도 있습니다. ! 인간의 반복적이고 힘든일을 대체했으면 ~\n",
      "전처리 후: ㅋㅋ ai는 인간의 일을 대체하게 될겁니다 장점도 있고 단점도 있습니다  인간의 반복적이고 힘든일을 대체했으면 \n",
      "\n",
      "=== 형태소 분석 결과 비교 ===\n",
      "원본 형태소: ['ㅋㅋ', 'AI', '는', '인간', '의', '일', '을', '대체', '하게', '될', '겁니다', '.', '장점', '도', '있고', '단점', '도', '있습니다', '.', '!', '인간', '의', '반복', '적', '이고', '힘든', '일', '을', '대체', '했으면', '~']\n",
      "전처리 후 형태소: ['ㅋㅋ', 'ai', '는', '인간', '의', '일', '을', '대체', '하게', '될', '겁니다', '장점', '도', '있고', '단점', '도', '있습니다', '인간', '의', '반복', '적', '이고', '힘든', '일', '을', '대체', '했으면']\n",
      "\n",
      "=== 명사 추출 결과 비교 ===\n",
      "원본 명사: ['인간', '일', '대체', '장점', '단점', '인간', '반복', '일', '대체']\n",
      "전처리 후 명사: ['인간', '일', '대체', '장점', '단점', '인간', '반복', '일', '대체']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 전처리 전후 비교 ===\")\n",
    "print(f\"원본: {text2}\")\n",
    "print(f\"전처리 후: {cleaned_text}\")\n",
    "print()\n",
    "\n",
    "print(\"=== 형태소 분석 결과 비교 ===\")\n",
    "original_morphs = okt.morphs(text2)\n",
    "print(f\"원본 형태소: {original_morphs}\")\n",
    "print(f\"전처리 후 형태소: {cleaned_morphs}\")\n",
    "print()\n",
    "\n",
    "print(\"=== 명사 추출 결과 비교 ===\")\n",
    "original_nouns = okt.nouns(text2)\n",
    "cleaned_nouns = okt.nouns(cleaned_text)\n",
    "print(f\"원본 명사: {original_nouns}\")\n",
    "print(f\"전처리 후 명사: {cleaned_nouns}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
