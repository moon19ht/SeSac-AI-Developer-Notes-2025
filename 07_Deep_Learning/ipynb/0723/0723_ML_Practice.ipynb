{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7eb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 모델을 가져다 사용하기 (특성추출, 미세조정)\n",
    "# 1. 특성추출하기 - CNN하고 완전피드포워딩  합성곱신경망(CNN) + 완전피드포워딩\n",
    "\n",
    "# 2. 이미 학습된 모델을 불러와서 CNN 파트랑 완전연결망을 쪼개서\n",
    "#    CNN으로부터 득성을 추출한 다음에 완전연결망한테 보내서 다시 학습(분류학습)을 한다.\n",
    "#    CNN이 시간이 많이 걸린다. => CNN 재활용을 하면 학습시간도 적게 걸리고, 예측률도 더 높아진다.\n",
    "#    이미 수십만장의 사진을 가지고 학습한 모델을 갖다 쓴다.\n",
    "#    장점) 데이터셋이 적을 경우(1000장)\n",
    "#         이미 학습된 모델을 사용함으로써 학습시간을 줄여준다.\n",
    "#         컴퓨터 자원이 작아도 학습이 가능하다. \n",
    "# VGG19, ResNet, MobileLet 등 이미지셋 모델들이 있다.\n",
    "# https://hwanny-yy.tistory.com/11\n",
    "\n",
    "'''\n",
    "1. 투스테이지(cats_and_dogs.ipynb)\n",
    "CNN 동결 VGG19의 특징을 미리 계산하고 numpy배열로 바꾼다. 저장된 특성으로 분류학습을 다시한다.\n",
    "장점 : 훈련속도가 빠르다.\n",
    "단점 : 메모리를 많이 차지한다.\n",
    "       학습하고자 하는 데이터셋이 커지면 힘들다. 데이터 증강 적용방식이 내 데이터가 아니라 추출한 특성에 적용된다.\n",
    "\n",
    "2. 인라인(cats_and_dogs2.ipynb)\n",
    "VGG19의 특징 추출부분을 전체 모델 안에 포함시킨다. 분류학습을 한다.\n",
    "장점 : 원본이미지에 데이터 증강이 바로 적용된다. 모델의 과대적합을 막을 수 있다. 사람들이 많이 쓰는 방법이다.\n",
    "단점 : 속도는 투스테이지보다 느리다. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d74065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown # 케라스 만든 사람들이 케라스에 있는 데이터셋 업어오기 위해 사용함\n",
    "# gdown.download(id='18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd', output='dogs-vs-cats.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096932ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19\n",
    "import os, shutil, pathlib\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "original_dir = pathlib.Path(\"../../data/cats_and_dogs/train\")\n",
    "new_base_dir = pathlib.Path(\"../../data/cats_and_dogs/cats_and_dogs_small\")\n",
    "\n",
    "# 폴더로 옮기기\n",
    "def make_subset(subset_name, start_index, end_index): # make_subset(\"train\", 0, 1000)\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir/subset_name/category\n",
    "        os.makedirs(dir, exist_ok=True) # 디렉토리가 없을 경우 새로 디렉토리를 만들어라\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir/fname, dst=dir/fname)\n",
    "\n",
    "make_subset(\"train\", 0, 1000)\n",
    "make_subset(\"validation\", 1000, 1500)\n",
    "make_subset(\"test\", 1500, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    new_base_dir/\"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=16\n",
    ")\n",
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "    new_base_dir/\"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=16\n",
    ")\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    new_base_dir/\"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 이미지 모델 가져오기\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "conv_base = keras.applications.vgg19.VGG19(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False, # CNN만 가져와라, CNN이 하단에 있음\n",
    "    input_shape=(180, 180, 3) # 입력할 데이터 크기를 주어야 한다.\n",
    "    # 데이터셋에서 지정한 크기와 일치해야 한다.\n",
    ")\n",
    "\n",
    "conv_base.summary() # CNN 요약 확인하기\n",
    "# block5_pool(MaxPooling2D) (None, 5, 5, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdf419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 주로 CNN으로부터 특징을 추출해서 전달하는 함수\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset: # 예측할 때 처럼 폴더로부터 16개의 이미지와 라벨을 가져온다.\n",
    "        preprocessed_images = keras.applications.vgg19.preprocess_input(images)\n",
    "        print(images.shape, preprocessed_images.shape)\n",
    "        # plt.imshow(preprocessed_images[0])\n",
    "        # plt.show()\n",
    "        # break\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "def deeplearning():\n",
    "    train_features, train_labels,validation_features, validation_labels, test_features, test_labels = load_features()\n",
    "\n",
    "    # 특성추출, 불러오기, 예측\n",
    "    data_augmentation = keras.Sequential(\n",
    "            [\n",
    "                layers.RandomFlip(\"horizontal\"), # 이미지를 수평으로 무작위로 뒤집습니다.\n",
    "                layers.RandomRotation(0.1),                                 # 이미지를 최대 2pi 라디안의 10 (즉, 36도)까지 무작위로 회전\n",
    "                layers.RandomZoom(0.1),                                     # 이미지를 최대 10%까지 무작위로 확대하거나 축소한다.\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # 맨 마지막 block\n",
    "    inputs = keras.Input(shape=(5, 5, 512))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    # 학습이 과소가 되었던, 과대가 되었던 학습이 끝나야 저장이 되는데\n",
    "    # 과대적합이 되는 시점에서 저장을 할 수 있다.\n",
    "    # model이 학습하는 도중에 과대적합이 되는 걸 확인할 수 있다.\n",
    "    # 콜백함수에 저장할 파일명을 전달하면 자동으로 호출을 한다.\n",
    "    # list 형태로 받아간다.\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"특성추출.keras\",\n",
    "            save_best_only=True, # 가장 적합할 때 저장하기\n",
    "            monitor=\"val_loss\" # 검증데이터의 손실로스값이 최적화일 때\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(train_features, train_labels, \n",
    "                        epochs=5, callbacks=callbacks,\n",
    "                        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea479e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_features():\n",
    "    train_features, train_labels = get_features_and_labels(train_ds)\n",
    "    validation_features, validation_labels = get_features_and_labels(validation_ds)\n",
    "    test_features, test_labels = get_features_and_labels(test_ds)\n",
    "\n",
    "    data = [train_features, train_labels, validation_features, validation_labels, test_features, test_labels]\n",
    "    with open(\"개고양이특성.bin\", \"wb\") as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def load_features():\n",
    "    with open(\"개고양이특성.bin\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    return data[0], data[1], data[2], data[3], data[4], data[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(): # 예측하기\n",
    "    model = keras.models.load_model(\"특성추출.keras\")\n",
    "    train_features, train_labels,validation_features, validation_labels, test_features, test_labels = load_features()\n",
    "\n",
    "    test_pred = model.predict(test_features)\n",
    "    test_pred = (test_pred>0.5).astype(\"int\").flatten()\n",
    "    print(test_pred[:20])\n",
    "    print(test_labels[:20])\n",
    "    match_count = np.sum(test_pred == test_labels)\n",
    "    print(\"맞춘개수 : \", match_count)\n",
    "    print(\"틀린개수 : \", len(test_labels)-match_count)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    while True:\n",
    "        print(\"1.특징추출\")\n",
    "        print(\"2.학습\")\n",
    "        print(\"3.예측\")\n",
    "        sel = input(\"선택 : \")\n",
    "        if sel == \"1\":\n",
    "            save_features()\n",
    "        elif sel == \"2\":\n",
    "            deeplearning()\n",
    "        elif sel == \"3\":\n",
    "            Predict()\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
