{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d129fa5d",
   "metadata": {},
   "source": [
    "# Iris 꽃 분류 딥러닝 모델\n",
    "\n",
    "## 🌸 프로젝트 개요\n",
    "이 노트북에서는 Scikit-learn의 Iris 데이터셋을 사용하여 꽃의 품종(Setosa, Versicolor, Virginica)을 분류하는 딥러닝 모델을 구현합니다.\n",
    "\n",
    "## 📚 학습 목표\n",
    "- Scikit-learn 데이터셋을 딥러닝에 활용하는 방법\n",
    "- 원-핫 인코딩(One-Hot Encoding)의 필요성과 적용\n",
    "- StandardScaler를 사용한 데이터 정규화\n",
    "- 작은 데이터셋에 대한 딥러닝 모델 설계\n",
    "\n",
    "## 📁 데이터셋 정보\n",
    "- **데이터셋**: Iris 꽃 데이터셋 (150개 샘플)\n",
    "- **특성**: 4개 (꽃받침 길이/너비, 꽃잎 길이/너비)\n",
    "- **클래스**: 3개 (Setosa, Versicolor, Virginica)\n",
    "- **분할**: 훈련 70% / 테스트 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17758da",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트 및 시드 설정\n",
    "\n",
    "딥러닝 모델 구현과 데이터 전처리에 필요한 라이브러리를 임포트하고 재현 가능한 결과를 위해 랜덤 시드를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8facc761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 버전: 2.19.0\n",
      "✅ 라이브러리 임포트 완료!\n"
     ]
    }
   ],
   "source": [
    "# 데이터 처리 및 분할 라이브러리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 딥러닝 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 재현 가능한 결과를 위한 랜덤 시드 설정\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "print(\"TensorFlow 버전:\", tf.__version__)\n",
    "print(\"✅ 라이브러리 임포트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce5591",
   "metadata": {},
   "source": [
    "## 2. Iris 데이터셋 로드 및 탐색\n",
    "\n",
    "Scikit-learn의 Iris 데이터셋을 로드하고 데이터의 구조와 특성을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7394dc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Iris 데이터셋 기본 정보:\n",
      "특성 데이터 형태: (150, 4)\n",
      "타겟 데이터 형태: (150,)\n",
      "특성 이름: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "클래스 이름: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "📈 클래스별 분포:\n",
      "   0: setosa - 50개\n",
      "   1: versicolor - 50개\n",
      "   2: virginica - 50개\n",
      "\n",
      "✅ 데이터셋 로드 완료! (총 150개 샘플)\n"
     ]
    }
   ],
   "source": [
    "# Iris 데이터셋 로드\n",
    "iris = load_iris()\n",
    "\n",
    "# 특성(X)과 타겟(y) 분리\n",
    "X = iris['data']      # 꽃의 특성 데이터 (4개 특성)\n",
    "y = iris['target']    # 꽃의 품종 라벨 (3개 클래스)\n",
    "\n",
    "# 데이터셋 기본 정보 확인\n",
    "print(\"📊 Iris 데이터셋 기본 정보:\")\n",
    "print(f\"특성 데이터 형태: {X.shape}\")\n",
    "print(f\"타겟 데이터 형태: {y.shape}\")\n",
    "print(f\"특성 이름: {iris.feature_names}\")\n",
    "print(f\"클래스 이름: {iris.target_names}\")\n",
    "\n",
    "print(f\"\\n📈 클래스별 분포:\")\n",
    "import numpy as np\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for i, (cls, count) in enumerate(zip(iris.target_names, counts)):\n",
    "    print(f\"   {i}: {cls} - {count}개\")\n",
    "\n",
    "print(f\"\\n✅ 데이터셋 로드 완료! (총 {len(X)}개 샘플)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20b431",
   "metadata": {},
   "source": [
    "## 3. 데이터 분할 (훈련/테스트)\n",
    "\n",
    "모델의 일반화 성능을 평가하기 위해 데이터를 훈련셋과 테스트셋으로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ade6914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 데이터 분할 결과:\n",
      "훈련 특성 데이터: (105, 4)\n",
      "훈련 타겟 데이터: (105,)\n",
      "테스트 특성 데이터: (45, 4)\n",
      "테스트 타겟 데이터: (45,)\n",
      "\n",
      "📈 분할 비율:\n",
      "훈련셋: 105개 (70.0%)\n",
      "테스트셋: 45개 (30.0%)\n",
      "\n",
      "✅ 데이터 분할 완료!\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 훈련셋과 테스트셋으로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    random_state=1,    # 재현 가능한 결과를 위한 시드\n",
    "    test_size=0.3      # 테스트셋 비율 30%\n",
    ")\n",
    "\n",
    "# 분할 결과 확인\n",
    "print(\"📊 데이터 분할 결과:\")\n",
    "print(f\"훈련 특성 데이터: {X_train.shape}\")\n",
    "print(f\"훈련 타겟 데이터: {y_train.shape}\")\n",
    "print(f\"테스트 특성 데이터: {X_test.shape}\")\n",
    "print(f\"테스트 타겟 데이터: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\n📈 분할 비율:\")\n",
    "print(f\"훈련셋: {len(X_train)}개 ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"테스트셋: {len(X_test)}개 ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n✅ 데이터 분할 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6d7ef",
   "metadata": {},
   "source": [
    "## 4. 특성 데이터 정규화 (StandardScaler)\n",
    "\n",
    "딥러닝 모델의 학습 효율성을 높이기 위해 특성 데이터를 표준화합니다.\n",
    "\n",
    "### 정규화가 필요한 이유:\n",
    "- 각 특성의 스케일이 다를 때 학습이 불안정해질 수 있음\n",
    "- 경사하강법의 수렴 속도를 향상시킴\n",
    "- 모든 특성을 동등하게 처리하여 편향 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e277e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 전 데이터 범위:\n",
      "X_train 최솟값: [4.3 2.  1.  0.1]\n",
      "X_train 최댓값: [7.7 4.4 6.9 2.5]\n",
      "\n",
      "정규화 후 데이터 범위:\n",
      "X_train_scaled 평균: [-0. -0.  0. -0.]\n",
      "X_train_scaled 표준편차: [1. 1. 1. 1.]\n",
      "\n",
      "📊 데이터 형태 확인:\n",
      "훈련 데이터: (105, 4)\n",
      "테스트 데이터: (45, 4)\n",
      "\n",
      "✅ 특성 데이터 정규화 완료!\n",
      "📝 StandardScaler: 평균=0, 표준편차=1로 정규화\n"
     ]
    }
   ],
   "source": [
    "# 정규화 전 데이터 범위 확인\n",
    "print(\"정규화 전 데이터 범위:\")\n",
    "print(f\"X_train 최솟값: {X_train.min(axis=0)}\")\n",
    "print(f\"X_train 최댓값: {X_train.max(axis=0)}\")\n",
    "\n",
    "# StandardScaler를 사용한 정규화\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터로 스케일러를 학습하고 변환\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터는 훈련 데이터의 스케일로 변환 (fit 없이 transform만)\n",
    "# ⚠️ 주의: 원본 코드에서는 fit_transform을 사용했지만, \n",
    "# 올바른 방법은 transform만 사용하는 것입니다.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 정규화 후 데이터 범위 확인\n",
    "print(f\"\\n정규화 후 데이터 범위:\")\n",
    "print(f\"X_train_scaled 평균: {X_train_scaled.mean(axis=0).round(3)}\")\n",
    "print(f\"X_train_scaled 표준편차: {X_train_scaled.std(axis=0).round(3)}\")\n",
    "\n",
    "print(f\"\\n📊 데이터 형태 확인:\")\n",
    "print(f\"훈련 데이터: {X_train_scaled.shape}\")\n",
    "print(f\"테스트 데이터: {X_test_scaled.shape}\")\n",
    "\n",
    "print(\"\\n✅ 특성 데이터 정규화 완료!\")\n",
    "print(\"📝 StandardScaler: 평균=0, 표준편차=1로 정규화\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547b638",
   "metadata": {},
   "source": [
    "## 5. 타겟 데이터 원-핫 인코딩\n",
    "\n",
    "딥러닝에서 다중분류를 위해 정수 라벨을 원-핫 인코딩 형태로 변환합니다.\n",
    "\n",
    "### 원-핫 인코딩이란?\n",
    "- **정수 라벨**: [0, 1, 2]\n",
    "- **원-핫 인코딩**: [[1,0,0], [0,1,0], [0,0,1]]\n",
    "- categorical_crossentropy 손실함수 사용 시 필수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dceece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 전:\n",
      "y_train 형태: (105,)\n",
      "y_train 샘플: [2 0 0 0 1 0 0 2 2 2]\n",
      "고유값: [0 1 2]\n",
      "\n",
      "원-핫 인코딩 후:\n",
      "y_train_encoded 형태: (105, 3)\n",
      "y_train_encoded 샘플:\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "\n",
      "📊 변환 결과:\n",
      "훈련 라벨: (105, 3)\n",
      "테스트 라벨: (45, 3)\n",
      "\n",
      "📝 변환 예시:\n",
      "원본 라벨 0 → 원-핫: [1. 0. 0.]\n",
      "원본 라벨 1 → 원-핫: [0. 1. 0.]\n",
      "원본 라벨 2 → 원-핫: [0. 0. 1.]\n",
      "\n",
      "✅ 원-핫 인코딩 완료!\n"
     ]
    }
   ],
   "source": [
    "# 원-핫 인코딩 전 라벨 확인\n",
    "print(\"원-핫 인코딩 전:\")\n",
    "print(f\"y_train 형태: {y_train.shape}\")\n",
    "print(f\"y_train 샘플: {y_train[:10]}\")\n",
    "print(f\"고유값: {np.unique(y_train)}\")\n",
    "\n",
    "# 타겟 라벨을 원-핫 인코딩으로 변환\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "# 원-핫 인코딩 후 라벨 확인\n",
    "print(f\"\\n원-핫 인코딩 후:\")\n",
    "print(f\"y_train_encoded 형태: {y_train_encoded.shape}\")\n",
    "print(f\"y_train_encoded 샘플:\")\n",
    "print(y_train_encoded[:5])\n",
    "\n",
    "print(f\"\\n📊 변환 결과:\")\n",
    "print(f\"훈련 라벨: {y_train_encoded.shape}\")\n",
    "print(f\"테스트 라벨: {y_test_encoded.shape}\")\n",
    "\n",
    "# 변환 확인 예시\n",
    "print(f\"\\n📝 변환 예시:\")\n",
    "for i in range(3):\n",
    "    original = np.where(y_train == i)[0][0]  # 각 클래스의 첫 번째 샘플 인덱스\n",
    "    print(f\"원본 라벨 {i} → 원-핫: {y_train_encoded[original]}\")\n",
    "\n",
    "print(\"\\n✅ 원-핫 인코딩 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f721e",
   "metadata": {},
   "source": [
    "## 6. 딥러닝 모델 구조 설계\n",
    "\n",
    "Iris 데이터셋 분류를 위한 다층 퍼셉트론 모델을 설계합니다.\n",
    "\n",
    "### 모델 구조:\n",
    "- **입력층**: 4개 뉴런 (4개 특성)\n",
    "- **은닉층 1**: 64개 뉴런 + ReLU 활성화 함수\n",
    "- **은닉층 2**: 64개 뉴런 + ReLU 활성화 함수  \n",
    "- **은닉층 3**: 128개 뉴런 + ReLU 활성화 함수\n",
    "- **출력층**: 3개 뉴런 + Softmax 활성화 함수 (3개 클래스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2ce50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ 모델 구조:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 신경망 모델 구조 설계 완료!\n",
      "\n",
      "📝 모델 설계 포인트:\n",
      "- 작은 데이터셋이므로 과적합을 방지하기 위해 적당한 크기의 네트워크 사용\n",
      "- ReLU 활성화 함수로 학습 효율성 증대\n",
      "- Softmax 출력층으로 다중분류 확률 출력\n"
     ]
    }
   ],
   "source": [
    "# Sequential 모델을 사용하여 신경망 구조 설계\n",
    "network = keras.models.Sequential([\n",
    "    # 은닉층 1: 64개 뉴런, ReLU 활성화 함수\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    # 은닉층 2: 64개 뉴런, ReLU 활성화 함수 (추가 은닉층)\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    # 은닉층 3: 128개 뉴런, ReLU 활성화 함수 (더 많은 뉴런으로 복잡성 증가)\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    # 출력층: 3개 뉴런 (3개 클래스), Softmax 활성화 함수\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "print(\"🏗️ 모델 구조:\")\n",
    "network.summary()\n",
    "\n",
    "print(\"\\n✅ 신경망 모델 구조 설계 완료!\")\n",
    "print(\"\\n📝 모델 설계 포인트:\")\n",
    "print(\"- 작은 데이터셋이므로 과적합을 방지하기 위해 적당한 크기의 네트워크 사용\")\n",
    "print(\"- ReLU 활성화 함수로 학습 효율성 증대\")\n",
    "print(\"- Softmax 출력층으로 다중분류 확률 출력\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ded6f",
   "metadata": {},
   "source": [
    "## 7. 모델 컴파일 설정\n",
    "\n",
    "모델을 학습할 수 있도록 옵티마이저, 손실함수, 평가지표를 설정합니다.\n",
    "\n",
    "### 설정 요소:\n",
    "- **옵티마이저**: RMSprop (가중치 업데이트 방법)\n",
    "- **손실함수**: categorical_crossentropy (원-핫 인코딩된 다중분류용)\n",
    "- **평가지표**: accuracy (정확도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372f60fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 컴파일 완료!\n",
      "\n",
      "📝 손실함수 비교:\n",
      "- categorical_crossentropy: 라벨이 원-핫 인코딩 형태 ([1,0,0], [0,1,0], ...)\n",
      "- sparse_categorical_crossentropy: 라벨이 정수 형태 (0, 1, 2, ...)\n",
      "  → 현재는 라벨을 원-핫 인코딩했으므로 categorical_crossentropy 사용\n",
      "\n",
      "🎯 모델 학습 준비 완료!\n",
      "입력 데이터: (105, 4)\n",
      "출력 데이터: (105, 3)\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일 설정\n",
    "network.compile(\n",
    "    optimizer='rmsprop',                  # 옵티마이저: RMSprop\n",
    "    loss='categorical_crossentropy',      # 손실함수: 원-핫 인코딩된 다중분류용\n",
    "    metrics=['accuracy']                  # 평가지표: 정확도\n",
    ")\n",
    "\n",
    "print(\"✅ 모델 컴파일 완료!\")\n",
    "print(\"\\n📝 손실함수 비교:\")\n",
    "print(\"- categorical_crossentropy: 라벨이 원-핫 인코딩 형태 ([1,0,0], [0,1,0], ...)\")\n",
    "print(\"- sparse_categorical_crossentropy: 라벨이 정수 형태 (0, 1, 2, ...)\")\n",
    "print(\"  → 현재는 라벨을 원-핫 인코딩했으므로 categorical_crossentropy 사용\")\n",
    "\n",
    "print(f\"\\n🎯 모델 학습 준비 완료!\")\n",
    "print(f\"입력 데이터: {X_train_scaled.shape}\")\n",
    "print(f\"출력 데이터: {y_train_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be5652",
   "metadata": {},
   "source": [
    "## 8. 모델 학습 실행\n",
    "\n",
    "fit() 함수를 사용하여 모델을 학습시킵니다.\n",
    "\n",
    "### 학습 매개변수:\n",
    "- **epochs**: 30 (전체 데이터셋을 30번 반복 학습)\n",
    "- **batch_size**: 100 (한 번에 100개 샘플씩 처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93c218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 모델 학습을 시작합니다...\n",
      "⏰ Iris 데이터셋은 작으므로 빠르게 학습됩니다.\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0578 - loss: 1.1517 \n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5613 - loss: 1.0150\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6063 - loss: 0.9203\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6838 - loss: 0.8377\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7806 - loss: 0.7653\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8871 - loss: 0.7038\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9419 - loss: 0.6502\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9419 - loss: 0.6035\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9225 - loss: 0.5602\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9129 - loss: 0.5205\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9225 - loss: 0.4840\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9225 - loss: 0.4504\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9129 - loss: 0.4188\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9129 - loss: 0.3913\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9225 - loss: 0.3661\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9225 - loss: 0.3437\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9322 - loss: 0.3223\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9225 - loss: 0.3030\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9322 - loss: 0.2857\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9322 - loss: 0.2695\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9419 - loss: 0.2549\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9613 - loss: 0.2411\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9613 - loss: 0.2281\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9613 - loss: 0.2151\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9516 - loss: 0.2036\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9419 - loss: 0.1919\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9516 - loss: 0.1812\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9516 - loss: 0.1723\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9710 - loss: 0.1612\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9613 - loss: 0.1534\n",
      "\n",
      "✅ 모델 학습 완료!\n",
      "\n",
      "📝 배치 크기 참고사항:\n",
      "- 설정된 배치 크기: 100\n",
      "- 실제 훈련 데이터 크기: 105\n",
      "- 훈련 데이터가 배치 크기보다 작으므로 실제로는 전체 배치로 학습됨\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 실행\n",
    "print(\"🚀 모델 학습을 시작합니다...\")\n",
    "print(\"⏰ Iris 데이터셋은 작으므로 빠르게 학습됩니다.\")\n",
    "\n",
    "history = network.fit(\n",
    "    X_train_scaled,      # X: 정규화된 훈련 특성 데이터\n",
    "    y_train_encoded,     # y: 원-핫 인코딩된 훈련 라벨\n",
    "    epochs=30,           # 학습 회수 (30 에포크)\n",
    "    batch_size=100,      # 배치 크기 (전체 데이터보다 큰 값이므로 실제로는 전체 배치)\n",
    "    verbose=1            # 학습 진행 상황 출력\n",
    ")\n",
    "\n",
    "print(\"\\n✅ 모델 학습 완료!\")\n",
    "print(\"\\n📝 배치 크기 참고사항:\")\n",
    "print(f\"- 설정된 배치 크기: 100\")\n",
    "print(f\"- 실제 훈련 데이터 크기: {len(X_train_scaled)}\")\n",
    "print(\"- 훈련 데이터가 배치 크기보다 작으므로 실제로는 전체 배치로 학습됨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de228826",
   "metadata": {},
   "source": [
    "## 9. 모델 성능 평가\n",
    "\n",
    "evaluate() 함수를 사용하여 훈련셋과 테스트셋에서의 모델 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d5e9867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 훈련셋 성능:\n",
      "   손실(Loss): 0.1430\n",
      "   정확도(Accuracy): 0.9524 (95.24%)\n",
      "\n",
      "📊 테스트셋 성능:\n",
      "   손실(Loss): 0.2610\n",
      "   정확도(Accuracy): 0.8667 (86.67%)\n",
      "\n",
      "📈 성능 분석:\n",
      "   정확도 차이: 0.0857 (8.57%p)\n",
      "   ✅ 적절한 일반화 성능을 보입니다.\n",
      "\n",
      "🎉 Iris 꽃 분류 딥러닝 모델 구현 완료!\n",
      "📊 최종 테스트 정확도: 86.7%\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋 성능 평가\n",
    "train_loss, train_acc = network.evaluate(X_train_scaled, y_train_encoded, verbose=0)\n",
    "print(\"📊 훈련셋 성능:\")\n",
    "print(f\"   손실(Loss): {train_loss:.4f}\")\n",
    "print(f\"   정확도(Accuracy): {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "\n",
    "# 테스트셋 성능 평가\n",
    "test_loss, test_acc = network.evaluate(X_test_scaled, y_test_encoded, verbose=0)\n",
    "print(\"\\n📊 테스트셋 성능:\")\n",
    "print(f\"   손실(Loss): {test_loss:.4f}\")\n",
    "print(f\"   정확도(Accuracy): {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# 성능 차이 분석\n",
    "accuracy_diff = train_acc - test_acc\n",
    "print(f\"\\n📈 성능 분석:\")\n",
    "print(f\"   정확도 차이: {accuracy_diff:.4f} ({accuracy_diff*100:.2f}%p)\")\n",
    "\n",
    "if accuracy_diff > 0.1:  # 10% 이상 차이\n",
    "    print(\"   ⚠️  과적합(Overfitting) 가능성이 있습니다.\")\n",
    "elif accuracy_diff < -0.05:  # 테스트가 훈련보다 5% 이상 좋음\n",
    "    print(\"   🤔 테스트셋 성능이 더 좋습니다. 데이터 분할을 다시 확인해보세요.\")\n",
    "else:\n",
    "    print(\"   ✅ 적절한 일반화 성능을 보입니다.\")\n",
    "\n",
    "print(f\"\\n🎉 Iris 꽃 분류 딥러닝 모델 구현 완료!\")\n",
    "print(f\"📊 최종 테스트 정확도: {test_acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901996b",
   "metadata": {},
   "source": [
    "## 📚 학습 요약 및 MNIST와의 비교\n",
    "\n",
    "### ✅ Iris 딥러닝 구현 내용:\n",
    "1. **Scikit-learn 데이터셋 로드**\n",
    "2. **데이터 분할 (70% 훈련 / 30% 테스트)**\n",
    "3. **StandardScaler를 이용한 특성 정규화**\n",
    "4. **원-핫 인코딩을 통한 라벨 변환**\n",
    "5. **다층 퍼셉트론 모델 설계**\n",
    "6. **모델 학습 및 성능 평가**\n",
    "\n",
    "### 🔄 MNIST와 Iris의 차이점:\n",
    "\n",
    "| 구분 | MNIST | Iris |\n",
    "|------|-------|------|\n",
    "| **데이터 크기** | 70,000개 | 150개 |\n",
    "| **입력 차원** | 784 (28×28 이미지) | 4 (수치형 특성) |\n",
    "| **클래스 수** | 10개 (0~9 숫자) | 3개 (꽃 품종) |\n",
    "| **전처리** | 차원변환 + 0~1 정규화 | StandardScaler 정규화 |\n",
    "| **라벨 형태** | 정수 → sparse_categorical_crossentropy | 원-핫 → categorical_crossentropy |\n",
    "| **학습 시간** | 상대적으로 오래 걸림 | 매우 빠름 |\n",
    "\n",
    "### 🎯 딥러닝 vs 전통적 머신러닝:\n",
    "- **작은 데이터셋 (Iris)**: 전통적 머신러닝이 더 효과적일 수 있음\n",
    "- **큰 데이터셋 (MNIST)**: 딥러닝의 장점이 더 잘 드러남\n",
    "- **복잡한 패턴**: 딥러닝이 우수한 성능 발휘\n",
    "\n",
    "### 📝 핵심 학습 포인트:\n",
    "1. **데이터 전처리의 중요성** (정규화, 인코딩)\n",
    "2. **손실함수 선택** (sparse vs categorical)\n",
    "3. **모델 크기 조절** (데이터 크기에 맞는 네트워크)\n",
    "4. **과적합 주의** (작은 데이터셋에서 특히 중요)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
