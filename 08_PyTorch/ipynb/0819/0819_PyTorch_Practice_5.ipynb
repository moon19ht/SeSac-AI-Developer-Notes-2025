{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST ì†ê¸€ì”¨ ìˆ«ì ë¶„ë¥˜ - PyTorch ì™„ì „ êµ¬í˜„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ MNIST ì†ê¸€ì”¨ ìˆ«ì ë¶„ë¥˜ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ êµ¬í˜„í•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©í‘œ\n",
    "- PyTorchë¥¼ ì´ìš©í•œ ì™„ì „ì—°ê²° ì‹ ê²½ë§ êµ¬í˜„\n",
    "- MNIST ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "- ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "- ëª¨ë¸ ì €ì¥/ë¡œë“œ ë° ì‹¤ì œ ì´ë¯¸ì§€ ì˜ˆì¸¡\n",
    "\n",
    "## í•™ìŠµ ë‚´ìš©\n",
    "1. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë” ìƒì„±\n",
    "2. ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ ì„¤ê³„\n",
    "3. í›ˆë ¨ ë£¨í”„ êµ¬í˜„\n",
    "4. ëª¨ë¸ í‰ê°€ ë° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms \n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‹ ê²½ë§ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜\n",
    "\n",
    "MNIST ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì™„ì „ì—°ê²° ì‹ ê²½ë§ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì•„í‚¤í…ì²˜:\n",
    "- ì…ë ¥ì¸µ: 784ê°œ ë‰´ëŸ° (28Ã—28 í”½ì…€)\n",
    "- ì€ë‹‰ì¸µ: 500ê°œ ë‰´ëŸ° + ReLU í™œì„±í™” í•¨ìˆ˜\n",
    "- ì¶œë ¥ì¸µ: 10ê°œ ë‰´ëŸ° (0~9 ìˆ«ì í´ë˜ìŠ¤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    \"\"\"MNIST ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì™„ì „ì—°ê²° ì‹ ê²½ë§\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=28*28, hidden_size=500, num_classes=10):\n",
    "        \"\"\"\n",
    "        ì‹ ê²½ë§ ë ˆì´ì–´ ì´ˆê¸°í™”\n",
    "        Args:\n",
    "            input_size: ì…ë ¥ í¬ê¸° (28x28 = 784)\n",
    "            hidden_size: ì€ë‹‰ì¸µ í¬ê¸°\n",
    "            num_classes: ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜ (0~9 ìˆ«ì)\n",
    "        \"\"\"\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        \n",
    "        # ì™„ì „ì—°ê²°ì¸µ ì •ì˜\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 784 -> 500\n",
    "        self.relu = nn.ReLU()  # í™œì„±í™” í•¨ìˆ˜\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # 500 -> 10\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        ìˆœì „íŒŒ í•¨ìˆ˜\n",
    "        Args:\n",
    "            x: ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ [batch_size, 1, 28, 28]\n",
    "        Returns:\n",
    "            ì¶œë ¥ í…ì„œ [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # ì´ë¯¸ì§€ë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ í‰íƒ„í™”\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ì™„ì „ì—°ê²°ì¸µê³¼ í™œì„±í™” í•¨ìˆ˜\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # ë‘ ë²ˆì§¸ ì™„ì „ì—°ê²°ì¸µ (ì¶œë ¥ì¸µ)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(\"ImageClassifier í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST ë¶„ë¥˜ê¸° í´ë˜ìŠ¤ ì •ì˜\n",
    "\n",
    "ì „ì²´ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier:\n",
    "    \"\"\"MNIST ì†ê¸€ì”¨ ìˆ«ì ë¶„ë¥˜ë¥¼ ìœ„í•œ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size=64, learning_rate=0.001, epochs=5):\n",
    "        \"\"\"\n",
    "        ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "        Args:\n",
    "            batch_size: ë°°ì¹˜ í¬ê¸°\n",
    "            learning_rate: í•™ìŠµë¥ \n",
    "            epochs: ì—í¬í¬ ìˆ˜\n",
    "        \"\"\"\n",
    "        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU, ì•„ë‹ˆë©´ CPU)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}\")\n",
    "        \n",
    "        # ë°ì´í„° ì „ì²˜ë¦¬ ë³€í™˜ ì •ì˜\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜ (0~1 ì‚¬ì´ ê°’)\n",
    "            transforms.Normalize((0.5,), (0.5,))  # í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5ë¡œ ì •ê·œí™”\n",
    "        ])\n",
    "        \n",
    "        # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
    "        self.model = None\n",
    "        self.criterion = None\n",
    "        self.optimizer = None\n",
    "        \n",
    "        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”\n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "\n",
    "print(\"MNISTClassifier í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° ì¤€ë¹„ ë©”ì„œë“œ\n",
    "\n",
    "MNIST ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë°ì´í„° ë¡œë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(self):\n",
    "    \"\"\"MNIST ë°ì´í„°ì…‹ ì¤€ë¹„ ë° ë°ì´í„° ë¡œë” ìƒì„±\"\"\"\n",
    "    print(\"ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "    \n",
    "    # í›ˆë ¨ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n",
    "    train_dataset = datasets.MNIST(\n",
    "        root=\"./data\", \n",
    "        train=True, \n",
    "        transform=self.transform, \n",
    "        download=True\n",
    "    )\n",
    "    self.train_loader = DataLoader(\n",
    "        dataset=train_dataset, \n",
    "        batch_size=self.batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root=\"./data\", \n",
    "        train=False, \n",
    "        transform=self.transform, \n",
    "        download=True\n",
    "    )\n",
    "    self.test_loader = DataLoader(\n",
    "        dataset=test_dataset, \n",
    "        batch_size=self.batch_size, \n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}ê°œ\")\n",
    "\n",
    "# MNISTClassifier í´ë˜ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€\n",
    "MNISTClassifier.prepare_data = prepare_data\n",
    "print(\"prepare_data ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ êµ¬ì¶• ë©”ì„œë“œ\n",
    "\n",
    "ì‹ ê²½ë§ ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(self):\n",
    "    \"\"\"ì‹ ê²½ë§ ëª¨ë¸ ìƒì„± ë° ì´ˆê¸°í™”\"\"\"\n",
    "    print(\"ëª¨ë¸ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # ëª¨ë¸ ìƒì„± ë° ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "    self.model = ImageClassifier().to(self.device)\n",
    "    \n",
    "    # ì†ì‹¤í•¨ìˆ˜ ì •ì˜ (ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ìš©)\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # ì˜µí‹°ë§ˆì´ì € ì •ì˜ (Adam ì‚¬ìš©)\n",
    "    self.optimizer = torch.optim.Adam(\n",
    "        self.model.parameters(), \n",
    "        lr=self.learning_rate\n",
    "    )\n",
    "    \n",
    "    print(\"ëª¨ë¸ ìƒì„± ì™„ë£Œ\")\n",
    "    print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "\n",
    "# MNISTClassifier í´ë˜ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€\n",
    "MNISTClassifier.build_model = build_model\n",
    "print(\"build_model ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í›ˆë ¨ ë©”ì„œë“œ\n",
    "\n",
    "ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤. ë°°ì¹˜ë³„ ì§„í–‰ìƒí™©ê³¼ ì—í¬í¬ë³„ í‰ê·  ì†ì‹¤ì„ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "    \"\"\"ëª¨ë¸ í›ˆë ¨\"\"\"\n",
    "    print(f\"{self.epochs} ì—í¬í¬ ë™ì•ˆ í›ˆë ¨ ì‹œì‘...\")\n",
    "    \n",
    "    self.model.train()  # í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    train_losses = []  # ì†ì‹¤ ê¸°ë¡ìš©\n",
    "    \n",
    "    for epoch in range(self.epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # ìˆœì „íŒŒ\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            # ì—­ì „íŒŒ\n",
    "            self.optimizer.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "            loss.backward()  # ì—­ì „íŒŒ ìˆ˜í–‰\n",
    "            self.optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # ì§„í–‰ ìƒí™© ì¶œë ¥ (100 ë°°ì¹˜ë§ˆë‹¤)\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f'ì—í¬í¬ [{epoch+1}/{self.epochs}] '\n",
    "                      f'ë°°ì¹˜ [{batch_idx+1}/{len(self.train_loader)}] '\n",
    "                      f'ì†ì‹¤: {loss.item():.4f}')\n",
    "        \n",
    "        # ì—í¬í¬ë³„ í‰ê·  ì†ì‹¤ ì¶œë ¥\n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        print(f'ì—í¬í¬ {epoch+1} ì™„ë£Œ - í‰ê·  ì†ì‹¤: {avg_loss:.4f}')\n",
    "    \n",
    "    print(\"í›ˆë ¨ ì™„ë£Œ!\")\n",
    "    \n",
    "    # ì†ì‹¤ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', linewidth=2)\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# MNISTClassifier í´ë˜ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€\n",
    "MNISTClassifier.train = train\n",
    "print(\"train ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ ì €ì¥/ë¡œë“œ ë©”ì„œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(self, filepath=\"mnist_model.pth\"):\n",
    "    \"\"\"í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥\"\"\"\n",
    "    torch.save(self.model.state_dict(), filepath)\n",
    "    print(f\"ëª¨ë¸ì´ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "def load_model(self, filepath=\"mnist_model.pth\"):\n",
    "    \"\"\"ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"ëª¨ë¸ íŒŒì¼ '{filepath}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    if self.model is None:\n",
    "        self.model = ImageClassifier().to(self.device)\n",
    "        \n",
    "    self.model.load_state_dict(torch.load(filepath, map_location=self.device))\n",
    "    self.model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    print(f\"ëª¨ë¸ì´ {filepath}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# MNISTClassifier í´ë˜ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€\n",
    "MNISTClassifier.save_model = save_model\n",
    "MNISTClassifier.load_model = load_model\n",
    "print(\"save_model, load_model ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ëª¨ë¸ í‰ê°€ ë©”ì„œë“œ\n",
    "\n",
    "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í‰ê°€\"\"\"\n",
    "    if self.model is None:\n",
    "        raise ValueError(\"ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    print(\"ëª¨ë¸ í‰ê°€ ì¤‘...\")\n",
    "    self.model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * 10  # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°ìš©\n",
    "    class_total = [0] * 10\n",
    "    \n",
    "    with torch.no_grad():  # ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”\n",
    "        for images, labels in self.test_loader:\n",
    "            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            outputs = self.model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"ì „ì²´ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    \n",
    "    # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì¶œë ¥\n",
    "    print(\"\\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:\")\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            class_acc = 100 * class_correct[i] / class_total[i]\n",
    "            print(f\"ìˆ«ì {i}: {class_acc:.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# MNISTClassifier í´ë˜ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€\n",
    "MNISTClassifier.evaluate = evaluate\n",
    "print(\"evaluate ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ ë©”ì„œë“œ\n",
    "\n",
    "ì™¸ë¶€ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(self, image_path):\n",
    "    \"\"\"ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡\"\"\"\n",
    "    if self.model is None:\n",
    "        raise ValueError(\"ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"ì´ë¯¸ì§€ íŒŒì¼ '{image_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ ë° í‘ë°±ìœ¼ë¡œ ë³€í™˜\n",
    "        image = Image.open(image_path).convert('L')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"ì´ë¯¸ì§€ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    \n",
    "    # ì˜ˆì¸¡ìš© ì „ì²˜ë¦¬ (í¬ê¸° ì¡°ì • í¬í•¨)\n",
    "    predict_transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),  # MNIST í¬ê¸°ë¡œ ì¡°ì •\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
    "    image_tensor = predict_transform(image).unsqueeze(0).to(self.device)\n",
    "    \n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = self.model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # ê²°ê³¼ ì‹œê°í™”\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # ì›ë³¸ ì´ë¯¸ì§€\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€\n",
    "    plt.subplot(1, 3, 2)\n",
    "    processed_img = image_tensor.cpu().squeeze().numpy()\n",
    "    plt.imshow(processed_img, cmap='gray')\n",
    "    plt.title('Processed Image (28x28)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # ì˜ˆì¸¡ í™•ë¥ \n",
    "    plt.subplot(1, 3, 3)\n",
    "    probs = probabilities.cpu().numpy()[0]\n",
    "    plt.bar(range(10), probs)\n",
    "    plt.title(f'Prediction: {predicted_class} (Confidence: {confidence:.3f})')\n",
    "    plt.xlabel('Digit')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xticks(range(10))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ì˜ˆì¸¡ ê²°ê³¼: {predicted_class}\")\n",
    "    print(f\"ì‹ ë¢°ë„: {confidence:.4f}\")\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# MNISTClassifier í´ë˜ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€\n",
    "MNISTClassifier.predict_image = predict_image\n",
    "print(\"predict_image ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ë°ì´í„° ì‹œê°í™” í•¨ìˆ˜\n",
    "\n",
    "MNIST ë°ì´í„° ìƒ˜í”Œì„ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(train_loader, num_samples=8):\n",
    "    \"\"\"MNIST ë°ì´í„° ìƒ˜í”Œ ì‹œê°í™”\"\"\"\n",
    "    # ì²« ë²ˆì§¸ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°\n",
    "    data_iter = iter(train_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        # ì •ê·œí™” í•´ì œ (0.5 í‰ê· , 0.5 í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”ë˜ì—ˆìŒ)\n",
    "        img = images[i].squeeze() * 0.5 + 0.5\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Label: {labels[i].item()}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('MNIST Dataset Samples')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"visualize_samples í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ì‹¤ìŠµ ì‹¤í–‰\n",
    "\n",
    "ì´ì œ ëª¨ë“  êµ¬ì„±ìš”ì†Œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "classifier = MNISTClassifier(batch_size=64, learning_rate=0.001, epochs=3)\n",
    "print(\"ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 ë°ì´í„° ì¤€ë¹„ ë° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì¤€ë¹„\n",
    "classifier.prepare_data()\n",
    "\n",
    "# ë°ì´í„° ìƒ˜í”Œ ì‹œê°í™”\n",
    "print(\"\\në°ì´í„° ìƒ˜í”Œ ì‹œê°í™”:\")\n",
    "visualize_samples(classifier.train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 ëª¨ë¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ìƒì„±\n",
    "classifier.build_model()\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° í™•ì¸\n",
    "print(\"\\nëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(classifier.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 ëª¨ë¸ í›ˆë ¨ (ì„ íƒì  ì‹¤í–‰)\n",
    "\n",
    "**ì£¼ì˜**: ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ í›ˆë ¨ì´ ì‹œì‘ë©ë‹ˆë‹¤. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ì‹¤í–‰ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)\n",
    "train_losses = classifier.train()\n",
    "classifier.save_model(\"mnist_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 ëª¨ë¸ í‰ê°€ (ì„ íƒì  ì‹¤í–‰)\n",
    "\n",
    "í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤. ì‚¬ì „ì— í›ˆë ¨ëœ ëª¨ë¸ì´ ìˆë‹¤ë©´ ë¡œë“œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í‰ê°€ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)\n",
    "try:\n",
    "    # ì €ì¥ëœ ëª¨ë¸ì´ ìˆë‹¤ë©´ ë¡œë“œ\n",
    "    classifier.load_model(\"mnist_model.pth\")\n",
    "    accuracy = classifier.evaluate()\n",
    "except FileNotFoundError:\n",
    "    print(\"ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í›ˆë ¨ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "except Exception as e:\n",
    "    print(f\"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6 ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ (ì„ íƒì  ì‹¤í–‰)\n",
    "\n",
    "ì™¸ë¶€ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ ì˜ˆì‹œ\n",
    "try:\n",
    "    # ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)\n",
    "    image_path = './data/mnist_data/1.jpg'  # ì˜ˆì‹œ ê²½ë¡œ\n",
    "    \n",
    "    # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ\n",
    "    if classifier.model is None:\n",
    "        classifier.load_model(\"mnist_model.pth\")\n",
    "    \n",
    "    predicted_class, confidence = classifier.predict_image(image_path)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}\")\n",
    "    print(\"ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì¤€ë¹„í•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ì˜ˆì‹œ\n",
    "\n",
    "ì €ì¥ëœ ëª¨ë¸ ì—†ì´ë„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ëª‡ ê°œ ìƒ˜í”Œì„ ê°€ì ¸ì™€ ì˜ˆì¸¡í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_sample_data(classifier, num_samples=5):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œì„ ê°€ì ¸ì™€ ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
    "    if classifier.model is None:\n",
    "        print(\"ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°\n",
    "    data_iter = iter(classifier.test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    classifier.model.eval()\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "        images_device = images.to(classifier.device)\n",
    "        outputs = classifier.model(images_device)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            plt.subplot(2, num_samples, i + 1)\n",
    "            # ì´ë¯¸ì§€ ì‹œê°í™”\n",
    "            img = images[i].squeeze() * 0.5 + 0.5  # ì •ê·œí™” í•´ì œ\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            \n",
    "            actual = labels[i].item()\n",
    "            pred = predicted[i].item()\n",
    "            conf = probabilities[i][pred].item()\n",
    "            \n",
    "            # ì •ë‹µê³¼ ì˜ˆì¸¡ì´ ê°™ìœ¼ë©´ ì´ˆë¡ìƒ‰, ë‹¤ë¥´ë©´ ë¹¨ê°„ìƒ‰\n",
    "            color = 'green' if actual == pred else 'red'\n",
    "            plt.title(f'Actual: {actual}\\nPred: {pred} ({conf:.3f})', color=color)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # í™•ë¥  ë¶„í¬ ê·¸ë˜í”„\n",
    "            plt.subplot(2, num_samples, i + 1 + num_samples)\n",
    "            probs = probabilities[i].cpu().numpy()\n",
    "            bars = plt.bar(range(10), probs)\n",
    "            bars[pred].set_color('red')  # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ëŠ” ë¹¨ê°„ìƒ‰\n",
    "            if actual != pred:\n",
    "                bars[actual].set_color('green')  # ì‹¤ì œ í´ë˜ìŠ¤ëŠ” ì´ˆë¡ìƒ‰\n",
    "            plt.ylim(0, 1)\n",
    "            plt.xlabel('Digit')\n",
    "            plt.ylabel('Probability')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ (ëª¨ë¸ì´ ì´ˆê¸°í™”ëœ ê²½ìš°)\n",
    "if classifier.model is not None:\n",
    "    print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒ˜í”Œë¡œ ì˜ˆì¸¡ ìˆ˜í–‰:\")\n",
    "    test_with_sample_data(classifier)\n",
    "else:\n",
    "    print(\"ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € build_model()ì„ ì‹¤í–‰í•˜ê±°ë‚˜ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì •ë¦¬ ë° í•µì‹¬ ê°œë…\n",
    "\n",
    "ì´ ì‹¤ìŠµì—ì„œ í•™ìŠµí•œ ë‚´ìš©:\n",
    "\n",
    "### ğŸ¯ ì£¼ìš” í•™ìŠµ ë‚´ìš©\n",
    "\n",
    "1. **PyTorch ì‹ ê²½ë§ êµ¬ì¡°**\n",
    "   - `nn.Module` ìƒì†ì„ í†µí•œ ëª¨ë¸ ì •ì˜\n",
    "   - `forward()` ë©”ì„œë“œë¥¼ í†µí•œ ìˆœì „íŒŒ êµ¬í˜„\n",
    "   - ì™„ì „ì—°ê²°ì¸µ(`nn.Linear`)ê³¼ í™œì„±í™” í•¨ìˆ˜(`nn.ReLU`) ì‚¬ìš©\n",
    "\n",
    "2. **ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**\n",
    "   - `torchvision.datasets`ë¥¼ ì´ìš©í•œ MNIST ë°ì´í„° ë¡œë“œ\n",
    "   - `transforms`ë¥¼ ì´ìš©í•œ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ê·œí™”\n",
    "   - `DataLoader`ë¥¼ ì´ìš©í•œ ë°°ì¹˜ ì²˜ë¦¬\n",
    "\n",
    "3. **í›ˆë ¨ ë£¨í”„ êµ¬í˜„**\n",
    "   - ìˆœì „íŒŒ(forward pass) â†’ ì†ì‹¤ ê³„ì‚° â†’ ì—­ì „íŒŒ(backward pass) â†’ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "   - `optimizer.zero_grad()`, `loss.backward()`, `optimizer.step()` íŒ¨í„´\n",
    "\n",
    "4. **ëª¨ë¸ í‰ê°€ ë° ì˜ˆì¸¡**\n",
    "   - `model.eval()`ê³¼ `torch.no_grad()` ì‚¬ìš©\n",
    "   - ì •í™•ë„ ê³„ì‚° ë° í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "   - ì‹¤ì œ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "\n",
    "### ğŸ”§ ì£¼ìš” PyTorch ê°œë…\n",
    "\n",
    "- **ë””ë°”ì´ìŠ¤ ê´€ë¦¬**: CPU/GPU ê°„ í…ì„œ ì´ë™\n",
    "- **ëª¨ë¸ ëª¨ë“œ**: `train()`ê³¼ `eval()` ëª¨ë“œ ì „í™˜\n",
    "- **ì†ì‹¤ í•¨ìˆ˜**: `CrossEntropyLoss`ë¥¼ ì´ìš©í•œ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜\n",
    "- **ì˜µí‹°ë§ˆì´ì €**: Adamì„ ì´ìš©í•œ ê°€ì¤‘ì¹˜ ìµœì í™”\n",
    "- **ëª¨ë¸ ì €ì¥/ë¡œë“œ**: `state_dict()`ë¥¼ ì´ìš©í•œ ëª¨ë¸ ì˜ì†ì„±\n",
    "\n",
    "### ğŸ“Š ì„±ëŠ¥ ê°œì„  ë°©ë²•\n",
    "\n",
    "- ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° (ë” ë§ì€ ì€ë‹‰ì¸µ)\n",
    "- CNN(Convolutional Neural Network) ì‚¬ìš©\n",
    "- ì •ê·œí™” ê¸°ë²• (Dropout, Batch Normalization)\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì—í¬í¬ ìˆ˜)\n",
    "- ë°ì´í„° ì¦ê°• (Data Augmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}