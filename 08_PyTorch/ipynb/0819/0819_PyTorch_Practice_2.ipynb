{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch를 활용한 MPG 연비 예측 회귀 모델\n",
    "\n",
    "이 노트북은 PyTorch를 사용하여 자동차의 MPG(Miles Per Gallon) 연비를 예측하는 회귀 모델을 구현합니다.\n",
    "\n",
    "## 목표\n",
    "- PyTorch의 신경망을 활용한 회귀 문제 해결\n",
    "- 객체 지향 프로그래밍을 통한 모듈화된 코드 작성\n",
    "- 데이터 전처리부터 모델 훈련까지의 전체 파이프라인 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 한글 폰트 설정 (시각화를 위해)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 신경망 모델 정의\n",
    "\n",
    "MPG 예측을 위한 다층 퍼셉트론 모델을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPGRegressor(nn.Module):\n",
    "    \"\"\"연비 예측을 위한 신경망 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=6):\n",
    "        super(MPGRegressor, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),  # 입력층\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),          # 은닉층 1\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),          # 은닉층 2\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)            # 출력층 (연비 예측값)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# 모델 구조 확인\n",
    "model = MPGRegressor(input_size=6)\n",
    "print(\"모델 구조:\")\n",
    "print(model)\n",
    "\n",
    "# 모델 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n총 파라미터 수: {total_params:,}\")\n",
    "print(f\"훈련 가능한 파라미터 수: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 처리 클래스\n",
    "\n",
    "MPG 데이터를 로드하고 전처리하는 클래스를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPGDataProcessor:\n",
    "    \"\"\"MPG 데이터 전처리 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def load_and_preprocess_data(self):\n",
    "        \"\"\"데이터 로드 및 전처리\"\"\"\n",
    "        # 데이터 로드\n",
    "        mpg = pd.read_csv(self.data_path)\n",
    "        print(\"원본 데이터 정보:\")\n",
    "        print(mpg.head())\n",
    "        print(mpg.info())\n",
    "        print(mpg.describe())\n",
    "        \n",
    "        # 결측값 제거\n",
    "        mpg = mpg.dropna(how=\"any\", axis=0)\n",
    "        print(f\"\\n결측값 제거 후 데이터 크기: {mpg.shape}\")\n",
    "        \n",
    "        # 특성과 타겟 분리\n",
    "        X = mpg.iloc[:, 1:7]  # 특성 변수 (cylinders ~ origin)\n",
    "        y = mpg.iloc[:, 0]    # 타겟 변수 (mpg)\n",
    "        \n",
    "        print(f\"\\n특성 데이터 형태: {X.shape}\")\n",
    "        print(f\"타겟 데이터 형태: {y.shape}\")\n",
    "        print(f\"\\n특성 변수명: {list(X.columns)}\")\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def create_data_loaders(self, X, y, test_size=0.2, batch_size=32, random_state=42):\n",
    "        \"\"\"데이터 로더 생성\"\"\"\n",
    "        # 데이터 표준화\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # 훈련/테스트 데이터 분할\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        print(f\"훈련 데이터 크기: {X_train.shape}\")\n",
    "        print(f\"테스트 데이터 크기: {X_test.shape}\")\n",
    "        \n",
    "        # 텐서 변환\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        # 데이터셋 생성\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        \n",
    "        # 데이터 로더 생성\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        return train_loader, test_loader, (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 로드 및 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리 객체 생성 및 데이터 로드\n",
    "data_processor = MPGDataProcessor(\"./data/mpg.csv\")\n",
    "X, y = data_processor.load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 시각화\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('MPG 데이터 특성별 분포', fontsize=16)\n",
    "\n",
    "# 각 특성별 히스토그램\n",
    "for i, column in enumerate(X.columns):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    axes[row, col].hist(X[column], bins=20, alpha=0.7, color='skyblue')\n",
    "    axes[row, col].set_title(f'{column} 분포')\n",
    "    axes[row, col].set_xlabel(column)\n",
    "    axes[row, col].set_ylabel('빈도')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수(MPG) 분포 확인\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y, bins=20, alpha=0.7, color='lightcoral')\n",
    "plt.title('MPG 분포')\n",
    "plt.xlabel('MPG')\n",
    "plt.ylabel('빈도')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(y)\n",
    "plt.title('MPG 박스플롯')\n",
    "plt.ylabel('MPG')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"MPG 통계:\")\n",
    "print(f\"평균: {y.mean():.2f}\")\n",
    "print(f\"표준편차: {y.std():.2f}\")\n",
    "print(f\"최솟값: {y.min():.2f}\")\n",
    "print(f\"최댓값: {y.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 간 상관관계 분석\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_data = pd.concat([X, y], axis=1)\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('특성 간 상관관계 히트맵')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# MPG와 각 특성 간의 상관계수 출력\n",
    "print(\"MPG와 각 특성 간의 상관계수:\")\n",
    "mpg_correlations = correlation_matrix['mpg'].drop('mpg').sort_values(key=abs, ascending=False)\n",
    "for feature, corr in mpg_correlations.items():\n",
    "    print(f\"{feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "train_loader, test_loader, split_data = data_processor.create_data_loaders(X, y)\n",
    "X_train, X_test, y_train, y_test = split_data\n",
    "\n",
    "print(f\"\\n배치 크기: {train_loader.batch_size}\")\n",
    "print(f\"훈련 배치 수: {len(train_loader)}\")\n",
    "print(f\"테스트 배치 수: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 훈련 클래스\n",
    "\n",
    "모델 훈련과 평가를 담당하는 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPGTrainer:\n",
    "    \"\"\"모델 훈련 및 평가 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, model, learning_rate=0.001):\n",
    "        self.model = model\n",
    "        self.criterion = nn.MSELoss()  # 평균 제곱 오차\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.train_losses = []\n",
    "        \n",
    "    def train(self, train_loader, epochs=100):\n",
    "        \"\"\"모델 훈련\"\"\"\n",
    "        print(f\"모델 훈련 시작 (에포크: {epochs})\")\n",
    "        self.model.train()  # 훈련 모드 설정\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                # 기울기 초기화\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # 순전파\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # 역전파 및 최적화\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "            \n",
    "            # 에포크별 평균 손실 저장\n",
    "            avg_loss = total_loss / batch_count\n",
    "            self.train_losses.append(avg_loss)\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:  # 10 에포크마다 출력\n",
    "                print(f'에포크 {epoch+1}/{epochs}, 평균 손실: {avg_loss:.4f}')\n",
    "        \n",
    "        print(\"모델 훈련 완료!\")\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"모델 평가\"\"\"\n",
    "        print(\"\\n모델 평가 시작\")\n",
    "        self.model.eval()  # 평가 모드 설정\n",
    "        \n",
    "        with torch.no_grad():  # 기울기 계산 비활성화\n",
    "            total_loss = 0\n",
    "            total_samples = 0\n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "            \n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                total_samples += inputs.size(0)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                all_predictions.extend(outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # MSE와 RMSE 계산\n",
    "            avg_mse = total_loss / total_samples\n",
    "            rmse = np.sqrt(avg_mse)\n",
    "            \n",
    "            print(f'테스트 데이터 평균 MSE: {avg_mse:.4f}')\n",
    "            print(f'테스트 데이터 RMSE: {rmse:.4f}')\n",
    "            \n",
    "            return avg_mse, rmse, np.array(all_predictions), np.array(all_labels)\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"훈련 과정 시각화\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.train_losses, label='Training Loss', color='blue')\n",
    "        plt.title('훈련 과정의 손실 변화')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 모델 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 모델 인스턴스 생성\n",
    "model = MPGRegressor(input_size=X.shape[1])\n",
    "print(f\"모델 구조:\")\n",
    "print(model)\n",
    "\n",
    "# 훈련 객체 생성\n",
    "trainer = MPGTrainer(model, learning_rate=0.001)\n",
    "\n",
    "# 모델 훈련\n",
    "trainer.train(train_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 훈련 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 과정 시각화\n",
    "trainer.plot_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델 평가 및 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "mse, rmse, predictions, true_values = trainer.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 실제값 vs 예측값 산점도\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(true_values, predictions, alpha=0.6, color='blue')\n",
    "plt.plot([true_values.min(), true_values.max()], [true_values.min(), true_values.max()], 'r--', lw=2)\n",
    "plt.xlabel('실제 MPG')\n",
    "plt.ylabel('예측 MPG')\n",
    "plt.title('실제값 vs 예측값')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 잔차 플롯\n",
    "residuals = true_values.flatten() - predictions.flatten()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(predictions, residuals, alpha=0.6, color='green')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('예측값')\n",
    "plt.ylabel('잔차 (실제값 - 예측값)')\n",
    "plt.title('잔차 플롯')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 잔차 히스토그램\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(residuals, bins=20, alpha=0.7, color='orange')\n",
    "plt.xlabel('잔차')\n",
    "plt.ylabel('빈도')\n",
    "plt.title('잔차 분포')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 통계적 분석\n",
    "from scipy.stats import pearsonr\n",
    "correlation, p_value = pearsonr(true_values.flatten(), predictions.flatten())\n",
    "\n",
    "print(f\"\\n=== 모델 성능 분석 ===\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"상관계수: {correlation:.4f}\")\n",
    "print(f\"결정계수 (R²): {correlation**2:.4f}\")\n",
    "print(f\"평균 절대 오차 (MAE): {np.mean(np.abs(residuals)):.4f}\")\n",
    "print(f\"잔차 평균: {np.mean(residuals):.4f}\")\n",
    "print(f\"잔차 표준편차: {np.std(residuals):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 예측 예시 및 모델 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몇 가지 샘플 예측 결과 확인\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 처음 10개 테스트 샘플 예측\n",
    "    sample_inputs = torch.tensor(X_test[:10], dtype=torch.float32)\n",
    "    sample_predictions = model(sample_inputs)\n",
    "    \n",
    "print(\"=== 샘플 예측 결과 ===\")\n",
    "print(f\"{'인덱스':<5} {'실제값':<8} {'예측값':<8} {'오차':<8}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for i in range(10):\n",
    "    actual = y_test.iloc[i]\n",
    "    predicted = sample_predictions[i].item()\n",
    "    error = abs(actual - predicted)\n",
    "    print(f\"{i:<5} {actual:<8.2f} {predicted:<8.2f} {error:<8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성별 중요도 시각화 (간단한 분석)\n",
    "feature_names = X.columns.tolist()\n",
    "feature_importance = np.abs(correlation_matrix['mpg'].drop('mpg').values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "plt.bar(range(len(feature_importance)), feature_importance[indices], alpha=0.7)\n",
    "plt.xticks(range(len(feature_importance)), [feature_names[i] for i in indices], rotation=45)\n",
    "plt.title('특성별 MPG와의 상관관계 크기')\n",
    "plt.ylabel('절대 상관계수')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"특성 중요도 (절대 상관계수 기준):\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"{i+1}. {feature_names[idx]}: {feature_importance[idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 결론 및 개선 방안\n",
    "\n",
    "### 모델 성능 요약\n",
    "- 본 모델은 PyTorch를 활용하여 자동차의 MPG를 예측하는 회귀 모델을 성공적으로 구현했습니다.\n",
    "- 다층 퍼셉트론 구조를 사용하여 비선형 관계를 학습할 수 있었습니다.\n",
    "\n",
    "### 개선 방안\n",
    "1. **하이퍼파라미터 튜닝**: 학습률, 배치 크기, 네트워크 구조 최적화\n",
    "2. **정규화 기법**: Dropout, Batch Normalization, L1/L2 정규화 적용\n",
    "3. **교차 검증**: K-fold 교차 검증을 통한 더 안정적인 성능 평가\n",
    "4. **앙상블 방법**: 여러 모델의 예측을 결합하여 성능 향상\n",
    "5. **특성 엔지니어링**: 새로운 특성 생성 또는 특성 선택 기법 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 (선택사항)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
    "    'train_losses': trainer.train_losses,\n",
    "    'test_mse': mse,\n",
    "    'test_rmse': rmse\n",
    "}, 'mpg_regressor_model.pth')\n",
    "\n",
    "print(\"모델이 'mpg_regressor_model.pth' 파일로 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}