{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# California Housing Regression (PyTorch)\n",
        "캘리포니아 주택 가격 데이터셋으로 회귀 모델을 학습한다. 데이터 누수 방지, 재현성, 학습 곡선 시각화, 다중 지표 평가를 포함한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 개요\n",
        "- **데이터**: `sklearn.datasets.fetch_california_housing`\n",
        "- **입력 특징**(8개): MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude\n",
        "- **목표**: MedHouseVal (단위: 10만 달러)\n",
        "- **주의**: 스케일러는 **훈련 세트에만** 적합한다. 이후 검증/테스트 세트에는 변환만 적용해 누수를 막는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) 기본 설정\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "set_seed(42)\n",
        "print(f\"사용 디바이스: {DEVICE}\")\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 로드와 전처리\n",
        "- 훈련/검증 분할 후 **훈련 세트 기준으로만** `StandardScaler.fit` 실행.\n",
        "- 텐서 변환 시 `float32` 유지."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing = fetch_california_housing(as_frame=True)\n",
        "X = housing.data.values.astype(np.float32)\n",
        "y = housing.target.values.astype(np.float32).reshape(-1, 1)\n",
        "feature_names = list(housing.feature_names)\n",
        "\n",
        "print(f\"데이터셋 크기: {X.shape}\")\n",
        "print(f\"특성 이름: {feature_names}\")\n",
        "print(f\"타겟 범위: {y.min():.2f} ~ {y.max():.2f}\")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 데이터 누수 방지: 훈련 세트에만 fit, 검증 세트에는 transform만 적용\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
        "X_val   = scaler.transform(X_val).astype(np.float32)\n",
        "\n",
        "# PyTorch 텐서로 변환\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_t   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "y_val_t   = torch.tensor(y_val,   dtype=torch.float32)\n",
        "\n",
        "# 데이터셋과 데이터로더 생성\n",
        "train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "val_ds   = TensorDataset(X_val_t,   y_val_t)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"\\n훈련 데이터: {X_train_t.shape}\")\n",
        "print(f\"검증 데이터: {X_val_t.shape}\")\n",
        "print(f\"특성 개수: {len(feature_names)}\")\n",
        "print(f\"배치 개수 - 훈련: {len(train_loader)}, 검증: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 정의\n",
        "- 선형층 + ReLU + 드롭아웃.\n",
        "- He 초기화(Kaiming)로 학습 안정화."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HousingRegressor(nn.Module):\n",
        "    def __init__(self, input_size=8, hidden_sizes=(128, 64, 32), p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_size\n",
        "        \n",
        "        # 은닉층 구성\n",
        "        for h in hidden_sizes:\n",
        "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(p_drop)]\n",
        "            prev = h\n",
        "        \n",
        "        # 출력층\n",
        "        layers += [nn.Linear(prev, 1)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        \n",
        "        # 가중치 초기화\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def _init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 모델 생성\n",
        "model = HousingRegressor(input_size=X_train_t.shape[1]).to(DEVICE)\n",
        "print(f\"모델 구조:\\n{model}\")\n",
        "\n",
        "# 모델 파라미터 수 계산\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\n총 파라미터 수: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 학습 루프\n",
        "- 손실: MSE\n",
        "- 옵티마이저: Adam + weight decay(간단한 L2)\n",
        "- 스케줄러: `ReduceLROnPlateau`\n",
        "- 얼리 스탑: `patience` 에폭 동안 검증 손실 개선 없으면 중단."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 설정\n",
        "EPOCHS = 200\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "PATIENCE = 20\n",
        "\n",
        "# 손실함수, 옵티마이저, 스케줄러 설정\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "def run_epoch(dataloader, train: bool):\n",
        "    \"\"\"한 에포크 실행\"\"\"\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.set_grad_enabled(train):\n",
        "        for xb, yb in dataloader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "            \n",
        "            if train:\n",
        "                optimizer.zero_grad()\n",
        "            \n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            \n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item() * xb.size(0)\n",
        "            total += xb.size(0)\n",
        "    \n",
        "    return epoch_loss / total\n",
        "\n",
        "print(\"설정 완료!\")\n",
        "print(f\"에포크: {EPOCHS}, 학습률: {LR}, Weight Decay: {WEIGHT_DECAY}, Patience: {PATIENCE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습 실행\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # 훈련\n",
        "    train_loss = run_epoch(train_loader, train=True)\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    # 검증\n",
        "    val_loss = run_epoch(val_loader, train=False)\n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    # 스케줄러 업데이트\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # 얼리 스토핑 체크\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # 최적 모델 저장\n",
        "        torch.save(model.state_dict(), 'best_housing_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    # 10 에포크마다 진행상황 출력\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f'에포크 [{epoch+1}/{EPOCHS}] - '\n",
        "              f'훈련 손실: {train_loss:.6f}, '\n",
        "              f'검증 손실: {val_loss:.6f}, '\n",
        "              f'학습률: {current_lr:.2e}, '\n",
        "              f'Patience: {patience_counter}/{PATIENCE}')\n",
        "    \n",
        "    # 얼리 스토핑\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(f\"\\n얼리 스토핑! 에포크 {epoch+1}에서 훈련 중단\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n훈련 완료! 최적 검증 손실: {best_val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 학습 곡선 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습 곡선 플롯\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='훈련 손실', alpha=0.8)\n",
        "plt.plot(val_losses, label='검증 손실', alpha=0.8)\n",
        "plt.xlabel('에포크')\n",
        "plt.ylabel('MSE 손실')\n",
        "plt.title('학습 곡선')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.log10(train_losses), label='훈련 손실 (log)', alpha=0.8)\n",
        "plt.plot(np.log10(val_losses), label='검증 손실 (log)', alpha=0.8)\n",
        "plt.xlabel('에포크')\n",
        "plt.ylabel('log10(MSE 손실)')\n",
        "plt.title('학습 곡선 (로그 스케일)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"최종 훈련 손실: {train_losses[-1]:.6f}\")\n",
        "print(f\"최종 검증 손실: {val_losses[-1]:.6f}\")\n",
        "print(f\"최적 검증 손실: {best_val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 평가\n",
        "다양한 지표로 모델 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 최적 모델 로드\n",
        "model.load_state_dict(torch.load('best_housing_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# 예측 수행\n",
        "with torch.no_grad():\n",
        "    # 훈련 세트 예측\n",
        "    train_preds = model(X_train_t.to(DEVICE)).cpu().numpy()\n",
        "    # 검증 세트 예측\n",
        "    val_preds = model(X_val_t.to(DEVICE)).cpu().numpy()\n",
        "\n",
        "# 평가 지표 계산\n",
        "def calculate_metrics(y_true, y_pred, dataset_name):\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    print(f\"\\n=== {dataset_name} 세트 평가 ===\")\n",
        "    print(f\"MSE:  {mse:.6f}\")\n",
        "    print(f\"RMSE: {rmse:.6f}\")\n",
        "    print(f\"MAE:  {mae:.6f}\")\n",
        "    print(f\"R²:   {r2:.6f}\")\n",
        "    \n",
        "    return mse, rmse, mae, r2\n",
        "\n",
        "# 훈련 세트 평가\n",
        "train_metrics = calculate_metrics(y_train, train_preds, \"훈련\")\n",
        "\n",
        "# 검증 세트 평가\n",
        "val_metrics = calculate_metrics(y_val, val_preds, \"검증\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 예측 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예측 vs 실제 값 시각화\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# 훈련 세트\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(y_train, train_preds, alpha=0.5, s=1)\n",
        "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
        "plt.xlabel('실제 값')\n",
        "plt.ylabel('예측 값')\n",
        "plt.title(f'훈련 세트 (R² = {train_metrics[3]:.4f})')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 검증 세트\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(y_val, val_preds, alpha=0.5, s=1)\n",
        "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "plt.xlabel('실제 값')\n",
        "plt.ylabel('예측 값')\n",
        "plt.title(f'검증 세트 (R² = {val_metrics[3]:.4f})')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 잔차 플롯 (검증 세트)\n",
        "plt.subplot(1, 3, 3)\n",
        "residuals = y_val - val_preds\n",
        "plt.scatter(val_preds, residuals, alpha=0.5, s=1)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('예측 값')\n",
        "plt.ylabel('잔차 (실제 - 예측)')\n",
        "plt.title('잔차 플롯 (검증 세트)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 특성 중요도 분석 (선택사항)\n",
        "간단한 순열 중요도로 특성의 중요도를 추정해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 순열 중요도 계산 (간단한 버전)\n",
        "def permutation_importance(model, X, y, feature_names, n_repeats=5):\n",
        "    model.eval()\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32).to(DEVICE)\n",
        "    \n",
        "    # 기준 점수 계산\n",
        "    with torch.no_grad():\n",
        "        baseline_preds = model(X_tensor).cpu().numpy()\n",
        "    baseline_score = r2_score(y, baseline_preds)\n",
        "    \n",
        "    importances = []\n",
        "    \n",
        "    for i, feature_name in enumerate(feature_names):\n",
        "        scores = []\n",
        "        \n",
        "        for _ in range(n_repeats):\n",
        "            # 특성 순열\n",
        "            X_perm = X.copy()\n",
        "            np.random.shuffle(X_perm[:, i])\n",
        "            X_perm_tensor = torch.tensor(X_perm, dtype=torch.float32).to(DEVICE)\n",
        "            \n",
        "            # 순열된 특성으로 예측\n",
        "            with torch.no_grad():\n",
        "                perm_preds = model(X_perm_tensor).cpu().numpy()\n",
        "            perm_score = r2_score(y, perm_preds)\n",
        "            \n",
        "            # 중요도 = 기준 점수 - 순열 점수\n",
        "            scores.append(baseline_score - perm_score)\n",
        "        \n",
        "        importances.append(np.mean(scores))\n",
        "    \n",
        "    return np.array(importances)\n",
        "\n",
        "# 검증 세트에서 특성 중요도 계산\n",
        "print(\"특성 중요도 계산 중... (시간이 조금 걸릴 수 있습니다)\")\n",
        "importance_scores = permutation_importance(model, X_val, y_val, feature_names)\n",
        "\n",
        "# 중요도 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "sorted_idx = np.argsort(importance_scores)[::-1]\n",
        "plt.bar(range(len(feature_names)), importance_scores[sorted_idx])\n",
        "plt.xticks(range(len(feature_names)), [feature_names[i] for i in sorted_idx], rotation=45)\n",
        "plt.xlabel('특성')\n",
        "plt.ylabel('순열 중요도')\n",
        "plt.title('특성 중요도 (순열 중요도 기반)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 중요도 출력\n",
        "print(\"\\n특성 중요도 순위:\")\n",
        "for i, idx in enumerate(sorted_idx):\n",
        "    print(f\"{i+1:2d}. {feature_names[idx]:12s}: {importance_scores[idx]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 결과 요약\n",
        "\n",
        "### 모델 성능\n",
        "- **아키텍처**: 8 → 128 → 64 → 32 → 1 (ReLU + Dropout)\n",
        "- **정규화**: Weight Decay + Dropout\n",
        "- **최적화**: Adam + ReduceLROnPlateau\n",
        "- **얼리 스토핑**: 검증 손실 기준\n",
        "\n",
        "### 데이터 누수 방지\n",
        "- StandardScaler는 훈련 세트에만 fit\n",
        "- 검증 세트에는 transform만 적용\n",
        "- 재현성을 위한 시드 고정\n",
        "\n",
        "### 평가 지표\n",
        "- MSE, RMSE, MAE, R² 점수로 다각도 평가\n",
        "- 훈련/검증 성능 비교로 과적합 확인\n",
        "- 잔차 분석으로 모델 편향 확인"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
