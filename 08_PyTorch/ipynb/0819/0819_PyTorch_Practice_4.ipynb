{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM (Large Language Model) 실습 1\n",
    "\n",
    "이 노트북은 Transformers 라이브러리를 사용하여 KoGPT2 모델로 한국어 텍스트 생성을 실습합니다.\n",
    "\n",
    "## 목표\n",
    "- KoGPT2 모델 로드 및 설정\n",
    "- 텍스트 생성 파라미터 이해\n",
    "- GPU/CPU 환경에서의 텍스트 생성 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 로드 함수\n",
    "\n",
    "KoGPT2 모델과 토크나이저를 로드하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name=\"skt/kogpt2-base-v2\"):\n",
    "    \"\"\"모델과 토크나이저를 로드합니다.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 디바이스 설정 함수\n",
    "\n",
    "CUDA가 사용 가능한 경우 GPU를, 그렇지 않으면 CPU를 사용하도록 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_device(model):\n",
    "    \"\"\"디바이스를 설정하고 모델을 해당 디바이스로 이동시킵니다.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(f\"사용 중인 디바이스: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 텍스트 생성 함수\n",
    "\n",
    "입력된 텍스트를 기반으로 새로운 텍스트를 생성하는 함수입니다.\n",
    "\n",
    "### 생성 파라미터 설명:\n",
    "- `max_length`: 생성할 최대 토큰 수\n",
    "- `repetition_penalty`: 반복을 방지하는 페널티 (높을수록 반복 감소)\n",
    "- `do_sample`: 샘플링 사용 여부\n",
    "- `top_k`: top-k 샘플링 (상위 k개 토큰에서만 선택)\n",
    "- `temperature`: 창의성 조절 (높을수록 더 창의적, 낮을수록 더 보수적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(tokenizer, model, device, input_text, max_length=50):\n",
    "    \"\"\"입력 텍스트를 기반으로 새로운 텍스트를 생성합니다.\"\"\"\n",
    "    model.eval()  # 평가 모드로 설정\n",
    "    \n",
    "    # 입력 텍스트를 토큰화하고 디바이스로 이동\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 텍스트 생성\n",
    "    generated_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,  # 최대 생성 길이\n",
    "        pad_token_id=tokenizer.eos_token_id,  # 패딩 토큰 설정\n",
    "        repetition_penalty=2.0,  # 반복 방지\n",
    "        do_sample=True,  # 샘플링 활성화\n",
    "        top_k=50,  # top-k 샘플링\n",
    "        temperature=0.9  # 온도 설정 (창의성 조절)\n",
    "    )\n",
    "    \n",
    "    # 생성된 토큰을 텍스트로 디코딩\n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 실행\n",
    "\n",
    "이제 모든 함수를 사용하여 실제로 텍스트를 생성해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 모델과 토크나이저 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 토크나이저 로드\n",
    "print(\"모델과 토크나이저를 로드하는 중...\")\n",
    "tokenizer, model = load_model()\n",
    "print(\"로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 디바이스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = setup_device(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 텍스트 생성 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텍스트 정의\n",
    "input_text = \"안녕하세요. 오늘 날씨\"\n",
    "\n",
    "# 텍스트 생성\n",
    "print(\"텍스트 생성 중...\")\n",
    "generated_text = generate_text(tokenizer, model, device, input_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- 입력 텍스트 ---\")\n",
    "print(input_text)\n",
    "print(\"\\n--- 생성된 텍스트 ---\")\n",
    "print(generated_text)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 다양한 입력으로 실험하기\n",
    "\n",
    "다양한 입력 텍스트로 실험해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 입력 텍스트 실험\n",
    "test_inputs = [\n",
    "    \"인공지능의 미래는\",\n",
    "    \"오늘 저녁 메뉴로\",\n",
    "    \"코딩을 배우는 것은\",\n",
    "    \"여행을 가고 싶은 곳은\"\n",
    "]\n",
    "\n",
    "for i, input_text in enumerate(test_inputs, 1):\n",
    "    print(f\"\\n--- 실험 {i} ---\")\n",
    "    print(f\"입력: {input_text}\")\n",
    "    generated = generate_text(tokenizer, model, device, input_text, max_length=60)\n",
    "    print(f\"생성: {generated}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 생성 파라미터 조정 실험\n",
    "\n",
    "다양한 파라미터 설정으로 텍스트 생성 결과가 어떻게 달라지는지 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_params(tokenizer, model, device, input_text, \n",
    "                            max_length=50, temperature=0.9, top_k=50, repetition_penalty=2.0):\n",
    "    \"\"\"파라미터를 조정할 수 있는 텍스트 생성 함수\"\"\"\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        do_sample=True,\n",
    "        top_k=top_k,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# 파라미터 실험\n",
    "test_input = \"인공지능 기술은\"\n",
    "\n",
    "print(\"=== 파라미터별 생성 결과 비교 ===\")\n",
    "print(f\"입력 텍스트: {test_input}\\n\")\n",
    "\n",
    "# 낮은 temperature (보수적)\n",
    "result1 = generate_text_with_params(tokenizer, model, device, test_input, \n",
    "                                  temperature=0.3, max_length=60)\n",
    "print(f\"Temperature 0.3 (보수적): {result1}\\n\")\n",
    "\n",
    "# 높은 temperature (창의적)\n",
    "result2 = generate_text_with_params(tokenizer, model, device, test_input, \n",
    "                                  temperature=1.2, max_length=60)\n",
    "print(f\"Temperature 1.2 (창의적): {result2}\\n\")\n",
    "\n",
    "# 다른 top_k 값\n",
    "result3 = generate_text_with_params(tokenizer, model, device, test_input, \n",
    "                                  top_k=10, max_length=60)\n",
    "print(f\"Top_k 10: {result3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이 실습에서는 다음을 학습했습니다:\n",
    "\n",
    "1. **모델 로드**: Transformers 라이브러리를 사용한 KoGPT2 모델 로드\n",
    "2. **디바이스 설정**: GPU/CPU 환경에 따른 적절한 디바이스 설정\n",
    "3. **텍스트 생성**: 다양한 파라미터를 사용한 텍스트 생성\n",
    "4. **파라미터 조정**: temperature, top_k 등의 파라미터가 결과에 미치는 영향\n",
    "\n",
    "### 핵심 개념\n",
    "- **Temperature**: 생성의 창의성 조절 (낮을수록 보수적, 높을수록 창의적)\n",
    "- **Top-k sampling**: 상위 k개 토큰에서만 선택하여 품질 향상\n",
    "- **Repetition penalty**: 반복 방지를 통한 자연스러운 텍스트 생성"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}