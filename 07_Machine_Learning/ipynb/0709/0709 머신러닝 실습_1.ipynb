{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 스케일링(Scaling) 정리\n",
        "\n",
        "## 지도학습 vs 비지도학습\n",
        "\n",
        "### 지도학습\n",
        "- 출력결과를 알고 있을때 사용\n",
        "\n",
        "### 비지도학습 \n",
        "- 결과를 모른다. 라벨링이 없는 학습\n",
        "- 반드시 그렇지는 않지만 대체 뭘 분석해야 할지 모르고 결과도 예측이 안되고 \n",
        "- 지도학습 전단계에 데이터 분석용으로 많이 사용한다. \n",
        "\n",
        "#### 분류 vs 군집\n",
        "- **분류**: 기린하고 병아리 사진을 주면 분류의 경우에는 기린일 확률 0.7 병아리일 확률이 0.3입니다.\n",
        "- **군집**: 대충 2 클래스가 있는 걸로 보여요 클래스1이 될 확률 0.7 클래스2가 될 확률이 0.3입니다. 대충 몇개의 클래스가 존재한다 정도\n",
        "\n",
        "### 스케일링 종류 (4가지)\n",
        "1. StandardScaler\n",
        "2. RobustScaler  \n",
        "3. MinMaxScaler\n",
        "4. Normalizer\n",
        "\n",
        "### 차원축소\n",
        "- 고차원데이터(특성이 아주 많은경우 - 사진, 3차원 => 1차원) 시간도 많이 걸리고 \n",
        "- 사진처럼 정밀하게 그리는 경우와 캐리커쳐(특징만가지고)를 그렸을때 캐리커쳐가 더 빠르다\n",
        "- 때로는 차원축소로 할때 성과가 더 좋은경우도 있다.\n",
        "\n",
        "### 주성분분석 \n",
        "- 분산을 가지고 분산이 큰거로 주성분을 찾아낸다. \n",
        "- 암환자데이터의 경우 특성이 많을 경우 유용하다 \n",
        "\n",
        "### 연관성분석(장바구니분석)\n",
        "- 월마트의 기저귀하고 맥주가 같은 장바구니에 많이 들어갈줄 모르고 분석 \n",
        "- 숫자로 다 바꾸고 -> 벡터로 다 바꾸고         \n",
        "- 숫자로 바꾸기만 하면 연산을 가능하다 \n",
        "\n",
        "### 강화학습 \n",
        "- 게임, 알파고, 채찍과 당근, 파이썬 3.9 책이 전부 절판\n",
        "\n",
        "### 사이킷런에서 \n",
        "- **지도학습**: fit -> predict \n",
        "- **비지도학습**: fit -> transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   feature1  feature2  feature3\n",
            "0       160      3000         3\n",
            "1       165      3200         2\n",
            "2       170      3500         1\n",
            "3       175      4900         4\n",
            "4       180      4800         4\n",
            "5       155      6000         6\n",
            "6       190      2800        12\n",
            "7       172      3300        13\n",
            "8       168      5600        11\n",
            "9       178      4700         6\n"
          ]
        }
      ],
      "source": [
        "# 스케일링을 하기위한 가짜데이터 만들기\n",
        "data = {\n",
        "    \"feature1\":[160,   165,  170,  175, 180,  155,   190, 172, 168, 178],\n",
        "    \"feature2\":[3000, 3200, 3500, 4900, 4800, 6000, 2800, 3300, 5600, 4700],\n",
        "    \"feature3\":[3,     2,     1,   4,   4 ,   6,      12, 13,     11,  6]\n",
        "}\n",
        "\n",
        "import pandas as pd \n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. StandardScaler\n",
        "- 데이터가 정규분포를 따른다고 가정할때 많이 쓰임\n",
        "- 모델특성이 스케일링에 민감할때 \n",
        "- 서포트벡터머신, 로지스틱, 딥러닝일때 유용하다 \n",
        "- 이상치에 민감하다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardScaler 결과:\n",
            "[[-1.17169242 -1.07736727 -0.78165115]\n",
            " [-0.65324445 -0.89476265 -1.02591713]\n",
            " [-0.13479647 -0.62085572 -1.27018312]\n",
            " [ 0.3836515   0.65737664 -0.53738517]\n",
            " [ 0.90209948  0.56607433 -0.53738517]\n",
            " [-1.6901404   1.66170206 -0.0488532 ]\n",
            " [ 1.93899542 -1.2599719   1.41674271]\n",
            " [ 0.07258272 -0.80346034  1.66100869]\n",
            " [-0.34217566  1.29649282  1.17247672]\n",
            " [ 0.69472029  0.47477202 -0.0488532 ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
        "\n",
        "ss = StandardScaler() # 객체 생성 \n",
        "df_scaled = ss.fit_transform(df)  # 학습하고 바로 변경된값 반환 \n",
        "print(\"StandardScaler 결과:\")\n",
        "print(df_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. RobustScaler\n",
        "- 데이터에 이상치가 많으면 StandardScaler 대신 쓸 수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobustScaler 결과:\n",
            "[[-0.95652174 -0.66666667 -0.30769231]\n",
            " [-0.52173913 -0.54545455 -0.46153846]\n",
            " [-0.08695652 -0.36363636 -0.61538462]\n",
            " [ 0.34782609  0.48484848 -0.15384615]\n",
            " [ 0.7826087   0.42424242 -0.15384615]\n",
            " [-1.39130435  1.15151515  0.15384615]\n",
            " [ 1.65217391 -0.78787879  1.07692308]\n",
            " [ 0.08695652 -0.48484848  1.23076923]\n",
            " [-0.26086957  0.90909091  0.92307692]\n",
            " [ 0.60869565  0.36363636  0.15384615]]\n"
          ]
        }
      ],
      "source": [
        "rb = RobustScaler()\n",
        "df_scaled = rb.fit_transform(df)  # 학습하고 바로 변경된 값 반환 \n",
        "print(\"RobustScaler 결과:\")\n",
        "print(df_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. MinMaxScaler\n",
        "- 특성값의 범위가 명확히 0~1 사이에 와야할때 사용 (이미지, 특정신경망)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MinMaxScaler 결과:\n",
            "[[0.14285714 0.0625     0.16666667]\n",
            " [0.28571429 0.125      0.08333333]\n",
            " [0.42857143 0.21875    0.        ]\n",
            " [0.57142857 0.65625    0.25      ]\n",
            " [0.71428571 0.625      0.25      ]\n",
            " [0.         1.         0.41666667]\n",
            " [1.         0.         0.91666667]\n",
            " [0.48571429 0.15625    1.        ]\n",
            " [0.37142857 0.875      0.83333333]\n",
            " [0.65714286 0.59375    0.41666667]]\n"
          ]
        }
      ],
      "source": [
        "mm = MinMaxScaler()\n",
        "df_scaled = mm.fit_transform(df)  # 학습하고 바로 변경된값 반환 \n",
        "print(\"MinMaxScaler 결과:\")\n",
        "print(df_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Normalizer\n",
        "- 주로 텍스트분석에 유용하다\n",
        "- 클러스터링(군집분석)에 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalizer 결과:\n",
            "[[5.32576164e-02 9.98580307e-01 9.98580307e-04]\n",
            " [5.14940820e-02 9.98673105e-01 6.24170690e-04]\n",
            " [4.85142333e-02 9.98822451e-01 2.85377843e-04]\n",
            " [3.56915186e-02 9.99362522e-01 8.15806140e-04]\n",
            " [3.74736476e-02 9.99297269e-01 8.32747724e-04]\n",
            " [2.58247047e-02 9.99665987e-01 9.99665987e-04]\n",
            " [6.77008342e-02 9.97696504e-01 4.27584216e-03]\n",
            " [5.20501565e-02 9.98636723e-01 3.93402345e-03]\n",
            " [2.99864513e-02 9.99548377e-01 1.96339860e-03]\n",
            " [3.78451784e-02 9.99282800e-01 1.27568017e-03]]\n"
          ]
        }
      ],
      "source": [
        "nm = Normalizer()\n",
        "df_scaled = nm.fit_transform(df)  #학습하고 바로 변경된값 반환 \n",
        "print(\"Normalizer 결과:\")\n",
        "print(df_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 결론\n",
        "별짓 다해도 데이터가 많아야 한다!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
