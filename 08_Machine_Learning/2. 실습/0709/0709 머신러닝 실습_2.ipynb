{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 서포트벡터머신 (SVM) 실습\n",
        "\n",
        "## 개요\n",
        "- 대부분의 머신러닝 알고리즘은 평면에 선을 긋는다\n",
        "- 데이터에 따라서는 평면에 선을 못긋는 경우에 수학자들이 차원을 분리시켜서 평면의 다차원공간으로 보내서 차원간에 선을 긋는다\n",
        "- 스케일링의 중요성을 비교해본다\n",
        "\n",
        "## 사용 데이터\n",
        "- 유방암 데이터셋 (Breast Cancer Dataset)\n",
        "- 스케일링 전후 성능 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터셋 키: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            "특성 데이터 shape: (569, 30)\n",
            "타겟 데이터 shape: (569,)\n",
            "특성 이름: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness']...\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# 유방암 데이터셋 로딩 (Bunch타입)\n",
        "cancer = load_breast_cancer()\n",
        "print(\"데이터셋 키:\", cancer.keys())\n",
        "X = cancer.data  # 특성 데이터\n",
        "y = cancer.target  # 타겟 데이터\n",
        "\n",
        "print(f\"특성 데이터 shape: {X.shape}\")\n",
        "print(f\"타겟 데이터 shape: {y.shape}\")\n",
        "print(f\"특성 이름: {cancer.feature_names[:5]}...\")  # 처음 5개만 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 데이터 전처리 - 스케일링\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 데이터의 첫 번째 샘플 (일부):\n",
            "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01]\n",
            "스케일링된 데이터의 첫 번째 샘플 (일부):\n",
            "[ 1.09706398 -2.07333501  1.26993369  0.9843749   1.56846633]\n"
          ]
        }
      ],
      "source": [
        "# 스케일링을 위한 라이브러리 임포트\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler로 데이터 스케일링\n",
        "ss = StandardScaler()  # 객체 생성 \n",
        "X_scaled = ss.fit_transform(X)  # 학습하고 바로 변경된값 반환 \n",
        "\n",
        "print(\"원본 데이터의 첫 번째 샘플 (일부):\")\n",
        "print(X[0][:5])\n",
        "print(\"스케일링된 데이터의 첫 번째 샘플 (일부):\")\n",
        "print(X_scaled[0][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 데이터 분할 및 로지스틱 회귀 모델\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------- 로지스틱 회귀 (원본 데이터) --------------\n",
            "훈련셋 정확도: 0.9460093896713615\n",
            "테스트셋 정확도: 0.9440559440559441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ryan9\\miniconda3\\envs\\sesac_ai\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=100).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# 데이터 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# 로지스틱 회귀 모델 (분류) - 원본 데이터\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "print(\"-------- 로지스틱 회귀 (원본 데이터) --------------\")\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"훈련셋 정확도:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 정확도:\", model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "-------- 로지스틱 회귀 (max_iter 증가) --------------\n",
            "훈련셋 정확도: 0.9647887323943662\n",
            "테스트셋 정확도: 0.958041958041958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ryan9\\miniconda3\\envs\\sesac_ai\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n-------- 로지스틱 회귀 (max_iter 증가) --------------\")\n",
        "# 해결책 1: max_iter 매개변수 늘리기\n",
        "model_iter = LogisticRegression(max_iter=1000)  # 기본값 100에서 1000으로 증가\n",
        "model_iter.fit(X_train, y_train)\n",
        "print(\"훈련셋 정확도:\", model_iter.score(X_train, y_train))\n",
        "print(\"테스트셋 정확도:\", model_iter.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "-------- 로지스틱 회귀 (스케일링된 데이터) --------------\n",
            "훈련셋 정확도: 0.9906103286384976\n",
            "테스트셋 정확도: 0.965034965034965\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n-------- 로지스틱 회귀 (스케일링된 데이터) --------------\")\n",
        "# 해결책 2: 스케일링된 데이터 사용\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, random_state=0)\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "print(\"훈련셋 정확도:\", model_scaled.score(X_train_scaled, y_train))\n",
        "print(\"테스트셋 정확도:\", model_scaled.score(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 서포트벡터머신 (스케일링 없이)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------- 스케일링 안한 서포트벡터머신 ------------\n",
            "훈련셋 정확도: 0.903755868544601\n",
            "테스트셋 정확도: 0.9370629370629371\n"
          ]
        }
      ],
      "source": [
        "# 서포트벡터머신 모델 (분류)\n",
        "from sklearn.svm import SVC\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"-------- 스케일링 안한 서포트벡터머신 ------------\")\n",
        "print(\"훈련셋 정확도:\", svm_model.score(X_train, y_train))\n",
        "print(\"테스트셋 정확도:\", svm_model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 서포트벡터머신 (스케일링 적용)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------- 스케일링 적용 ----------\n",
            "-------- 스케일된 서포트벡터머신 ------------\n",
            "훈련셋 정확도: 0.9906103286384976\n",
            "테스트셋 정확도: 0.965034965034965\n"
          ]
        }
      ],
      "source": [
        "# 스케일링된 데이터로 데이터 분할\n",
        "print(\"-------- 스케일링 적용 ----------\")\n",
        "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y, random_state=1)\n",
        "\n",
        "# 스케일링된 데이터로 SVM 모델 학습\n",
        "svm_model_scaled = SVC()\n",
        "svm_model_scaled.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "print(\"-------- 스케일된 서포트벡터머신 ------------\")\n",
        "print(\"훈련셋 정확도:\", svm_model_scaled.score(X_train_scaled, y_train_scaled))\n",
        "print(\"테스트셋 정확도:\", svm_model_scaled.score(X_test_scaled, y_test_scaled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 결론\n",
        "\n",
        "### 로지스틱 회귀의 수렴 문제 해결\n",
        "- **문제**: ConvergenceWarning - 100번 반복 후에도 수렴하지 못함\n",
        "- **해결책 1**: `max_iter` 매개변수 증가 (100 → 1000)\n",
        "- **해결책 2**: 데이터 스케일링 적용\n",
        "- **권장사항**: 스케일링된 데이터를 사용하는 것이 가장 좋은 방법\n",
        "\n",
        "### 스케일링의 중요성\n",
        "- **로지스틱 회귀**: \n",
        "  - 스케일링에 상대적으로 덜 민감하지만, 수렴 속도에 영향\n",
        "  - 스케일링 적용 시 더 빠른 수렴과 안정적인 학습\n",
        "- **서포트벡터머신**: 스케일링에 매우 민감\n",
        "  - 스케일링 전: 낮은 성능 (90.4% → 93.7%)\n",
        "  - 스케일링 후: 큰 성능 향상 (99.1% → 96.5%)\n",
        "\n",
        "### 서포트벡터머신의 특징\n",
        "- 대부분의 머신러닝 알고리즘은 평면에 선을 긋는다\n",
        "- 데이터에 따라서는 평면에 선을 못긋는 경우가 있다\n",
        "- 이때 수학자들이 차원을 분리시켜서 다차원공간으로 보내서 차원간에 선을 긋는다\n",
        "- **스케일링이 반드시 필요한 알고리즘!**\n",
        "\n",
        "### 실무에서의 권장사항\n",
        "1. **항상 데이터 스케일링을 먼저 적용**\n",
        "2. **로지스틱 회귀**: StandardScaler 사용으로 수렴 속도 개선\n",
        "3. **SVM**: 스케일링 없이는 제대로 작동하지 않음\n",
        "4. **경고 메시지 무시하지 말고 적절한 해결책 적용**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
