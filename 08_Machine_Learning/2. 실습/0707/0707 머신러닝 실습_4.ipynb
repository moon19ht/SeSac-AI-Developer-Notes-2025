{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 회귀 분석\n",
        "\n",
        "## 학습 목표\n",
        "- 선형 회귀(Linear Regression) 이해 및 구현\n",
        "- KNN 회귀(KNeighborsRegressor) 학습\n",
        "- 다중 회귀 분석과 규제(Ridge, Lasso) 기법\n",
        "- 실제 데이터셋(보스톤 주택가격)을 활용한 회귀 분석\n",
        "\n",
        "## 데이터 분석 기본 개념\n",
        "- **사이킷런**: 입력데이터는 2D tensor, 출력은 1D tensor 형태\n",
        "- **회귀 분석**: 연속적인 수치 값을 예측하는 머신러닝 기법\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 단순 선형 회귀 (공부시간 vs 성적)\n",
        "\n",
        "공부시간이라는 **특성이 딱 하나**인 단순한 회귀 분석부터 시작해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (10, 1)\n",
            "y shape: (10,)\n",
            "\n",
            "공부시간(X): [20 19 17 18 12 14 10  9 16  6]\n",
            "성적(y): [100 100  90  90  60  70  40  40  70  30]\n"
          ]
        }
      ],
      "source": [
        "# 1-1. 데이터 준비 (공부시간 vs 성적)\n",
        "import numpy as np \n",
        "\n",
        "# 공부시간 - 특성이 딱 하나 \n",
        "X = [[20], [19], [17], [18], [12], [14], [10], [9], [16], [6]]\n",
        "# 평균값 (성적)\n",
        "y = [100, 100, 90, 90, 60, 70, 40, 40, 70, 30]\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y) \n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"\\n공부시간(X):\", X.flatten())\n",
        "print(\"성적(y):\", y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련셋 크기: (7, 1)\n",
            "테스트셋 크기: (3, 1)\n"
          ]
        }
      ],
      "source": [
        "# 1-2. 데이터 분할\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "\n",
        "print(\"훈련셋 크기:\", X_train.shape)\n",
        "print(\"테스트셋 크기:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 선형 회귀 결과 ===\n",
            "훈련셋 점수: 0.9612227324913892\n",
            "테스트셋 점수: 0.9502758714851357\n",
            "기울기: [5.46268657]\n",
            "절편: -8.567164179104466\n",
            "\n",
            "=== 예측 결과 비교 ===\n",
            "실제값(y_test): [90 30 40]\n",
            "예측값(y_pred): [84.29850746 24.20895522 46.05970149]\n",
            "수동계산(y_pred2): [84.29850746 24.20895522 46.05970149]\n"
          ]
        }
      ],
      "source": [
        "# 1-3. 선형 회귀 모델\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()   # 하이퍼파라미터 없음. 과대든 과소든 할수있는건 데이터셋 늘려주기 밖에 없다.\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== 선형 회귀 결과 ===\")\n",
        "print(\"훈련셋 점수:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 점수:\", model.score(X_test, y_test))\n",
        "print(\"기울기:\", model.coef_) \n",
        "print(\"절편:\", model.intercept_)\n",
        "\n",
        "# 수동 계산으로 검증\n",
        "y_pred2 = X_test * model.coef_ + model.intercept_\n",
        "print(\"\\n=== 예측 결과 비교 ===\")\n",
        "print(\"실제값(y_test):\", y_test)\n",
        "print(\"예측값(y_pred):\", y_pred)\n",
        "print(\"수동계산(y_pred2):\", y_pred2.flatten())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 다중회귀분석의 경우\n",
        "다중회귀분석에서는 가중치가 많습니다. 각 독립변수마다 별도의 가중치를 가져옵니다.\n",
        "\n",
        "**수식**: `w1*x1 + w2*x2 + w3*x3 + ... + wn*xn`\n",
        "\n",
        "**행렬 형태**:\n",
        "```\n",
        "(w1, w2, w3, ..., wn) × (x1, x2, x3, x4, ..., xn)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KNN 회귀 결과 ===\n",
            "훈련셋 점수: 0.8616452991452992\n",
            "테스트셋 점수: 0.5161290322580647\n",
            "실제값(y_test): [90 30 40]\n",
            "예측값(y_pred): [86.66666667 56.66666667 56.66666667]\n"
          ]
        }
      ],
      "source": [
        "# 1-4. KNN 이웃 회귀 알고리즘 \n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== KNN 회귀 결과 ===\")\n",
        "print(\"훈련셋 점수:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 점수:\", model.score(X_test, y_test))\n",
        "print(\"실제값(y_test):\", y_test)\n",
        "print(\"예측값(y_pred):\", y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. mglearn 라이브러리를 활용한 회귀 분석\n",
        "\n",
        "**mglearn**: 사이킷런 책 저자가 차트 그리기를 편하게 하고 가끔 가짜 데이터를 만들어보라고 만든 라이브러리입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mglearn이 설치되지 않아 대체 데이터를 생성합니다.\n",
            "X 처음 10개:\n",
            "[[ 0.49671415]\n",
            " [-0.1382643 ]\n",
            " [ 0.64768854]\n",
            " [ 1.52302986]\n",
            " [-0.23415337]\n",
            " [-0.23413696]\n",
            " [ 1.57921282]\n",
            " [ 0.76743473]\n",
            " [-0.46947439]\n",
            " [ 0.54256004]]\n",
            "\n",
            "y 처음 10개:\n",
            "[ 0.35569328  0.09910321  0.64875964  1.07765554 -0.5303775  -0.39841599\n",
            "  0.94411699  0.53785315 -0.08022289  1.42709947]\n",
            "\n",
            "X shape: (200, 1), y shape: (200,)\n"
          ]
        }
      ],
      "source": [
        "# 2-1. mglearn 데이터셋 생성\n",
        "# mglearn이 설치되지 않은 경우를 대비해 대체 데이터 생성\n",
        "try:\n",
        "    import mglearn\n",
        "    X, y = mglearn.datasets.make_wave(n_samples=200)\n",
        "    print(\"mglearn 라이브러리 사용\")\n",
        "except ImportError:\n",
        "    print(\"mglearn이 설치되지 않아 대체 데이터를 생성합니다.\")\n",
        "    # 대체 데이터 생성\n",
        "    np.random.seed(42)\n",
        "    X = np.random.randn(200, 1)\n",
        "    y = 0.5 * X.flatten() + 0.3 * np.random.randn(200)\n",
        "\n",
        "print(\"X 처음 10개:\")\n",
        "print(X[:10])\n",
        "print(\"\\ny 처음 10개:\")\n",
        "print(y[:10])\n",
        "print(f\"\\nX shape: {X.shape}, y shape: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== mglearn 데이터 - 선형 회귀 결과 ===\n",
            "훈련셋 점수: 0.7263400136424352\n",
            "테스트셋 점수: 0.7731889803646269\n",
            "기울기: [0.53127862]\n",
            "절편: 0.021803415819858035\n",
            "\n",
            "=== 예측 결과 비교 ===\n",
            "실제값(y_test) 처음 5개: [ 0.29877754  0.13147707  1.05445568  0.05283082 -0.33947119]\n",
            "예측값(y_pred) 처음 5개: [ 0.1977966   0.41413492  0.45880394 -0.16027348 -0.09691759]\n",
            "수동계산(y_pred2) 처음 5개: [ 0.1977966   0.41413492  0.45880394 -0.16027348 -0.09691759]\n"
          ]
        }
      ],
      "source": [
        "# 2-2. 데이터 분할 및 모델 학습\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "\n",
        "# 선형 회귀\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== mglearn 데이터 - 선형 회귀 결과 ===\")\n",
        "print(\"훈련셋 점수:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 점수:\", model.score(X_test, y_test))\n",
        "print(\"기울기:\", model.coef_) \n",
        "print(\"절편:\", model.intercept_)\n",
        "\n",
        "# 수동 계산으로 검증\n",
        "y_pred2 = X_test * model.coef_ + model.intercept_\n",
        "print(\"\\n=== 예측 결과 비교 ===\")\n",
        "print(\"실제값(y_test) 처음 5개:\", y_test[:5])\n",
        "print(\"예측값(y_pred) 처음 5개:\", y_pred[:5])\n",
        "print(\"수동계산(y_pred2) 처음 5개:\", y_pred2.flatten()[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== mglearn 데이터 - KNN 회귀 결과 ===\n",
            "훈련셋 점수: 0.8477279775448504\n",
            "테스트셋 점수: 0.6430910461065564\n",
            "실제값(y_test) 처음 5개: [ 0.29877754  0.13147707  1.05445568  0.05283082 -0.33947119]\n",
            "예측값(y_pred) 처음 5개: [ 0.19433492  0.44510106  0.40374249 -0.17776799 -0.38242148]\n"
          ]
        }
      ],
      "source": [
        "# 2-3. KNN 이웃 회귀 알고리즘 \n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== mglearn 데이터 - KNN 회귀 결과 ===\")\n",
        "print(\"훈련셋 점수:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 점수:\", model.score(X_test, y_test))\n",
        "print(\"실제값(y_test) 처음 5개:\", y_test[:5])\n",
        "print(\"예측값(y_pred) 처음 5개:\", y_pred[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 보스톤 주택가격 데이터 - 다중 회귀 분석\n",
        "\n",
        "### 다중회귀분석의 특징\n",
        "- **공분산**: 특성간에 서로 영향을 주고받는 것을 따져보고 필요없는 특성은 제거하는게 맞습니다\n",
        "- **R**: 기본적으로 제거해줍니다\n",
        "- **Python**: 우리가 직접 해야 합니다\n",
        "\n",
        "### 규제(Regularization) 기법\n",
        "- **선형회귀분석**: 다중공선성문제, 여러 특성간에 서로 너무 밀접해서 필요없는 요소들을 고려하지 않습니다\n",
        "- **특성의 개수가 많을 경우**: 처리능력이 떨어집니다\n",
        "- **해결책**: 가중치를 규제하면 과대적합을 막을 수 있습니다\n",
        "\n",
        "### Ridge vs Lasso\n",
        "- **Ridge**: 계수를 완전히 0으로 만들지는 못합니다 (L2 정규화)\n",
        "- **Lasso**: 가중치를 0에 가깝게 하다가 불필요한 요소가 있으면 아예 0으로 만들기도 합니다 (L1 정규화)\n",
        "- **alpha**: 하이퍼파라미터. 0으로 놓으면 규제를 안하겠다는 뜻(LinearRegression과 동일), 키우면 규제가 높아집니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "온라인 데이터 로드 성공\n",
            "데이터 형태: (1012, 11)\n",
            "\n",
            "처음 10행:\n",
            "          0      1      2    3      4      5     6       7    8      9     10\n",
            "0    0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3\n",
            "1  396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
            "2    0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8\n",
            "3  396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
            "4    0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8\n",
            "5  392.83000   4.03  34.70  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
            "6    0.03237   0.00   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7\n",
            "7  394.63000   2.94  33.40  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
            "8    0.06905   0.00   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7\n",
            "9  396.90000   5.33  36.20  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n"
          ]
        }
      ],
      "source": [
        "# 3-1. 보스톤 주택가격 데이터 로드\n",
        "import pandas as pd\n",
        "\n",
        "url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "\n",
        "# 분리문자가 공백이 아니고 \\s+, skiprows = 22줄 건너뛰기, 제목줄이 없다.\n",
        "try:\n",
        "    df = pd.read_csv(url, sep=r\"\\s+\", skiprows=22, header=None)\n",
        "    print(\"온라인 데이터 로드 성공\")\n",
        "    print(\"데이터 형태:\", df.shape)\n",
        "    print(\"\\n처음 10행:\")\n",
        "    print(df.head(10))\n",
        "except Exception as e:\n",
        "    print(f\"온라인 데이터 로드 실패: {e}\")\n",
        "    print(\"대체 데이터를 생성합니다...\")\n",
        "    \n",
        "    # 대체 데이터 생성 (보스톤 데이터셋과 유사한 형태)\n",
        "    np.random.seed(42)\n",
        "    n_samples = 506\n",
        "    n_features = 13\n",
        "    df = pd.DataFrame(np.random.randn(n_samples, n_features))\n",
        "    print(\"대체 데이터 생성 완료\")\n",
        "    print(\"데이터 형태:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 보스톤 데이터 처리 방식 적용\n",
            "X shape: (506, 13)\n",
            "y shape: (506,)\n",
            "\n",
            "X 처음 10개:\n",
            "[[6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01 6.5750e+00\n",
            "  6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01 3.9690e+02\n",
            "  4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
            "  7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
            "  9.1400e+00]\n",
            " [2.7290e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 7.1850e+00\n",
            "  6.1100e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9283e+02\n",
            "  4.0300e+00]\n",
            " [3.2370e-02 0.0000e+00 2.1800e+00 0.0000e+00 4.5800e-01 6.9980e+00\n",
            "  4.5800e+01 6.0622e+00 3.0000e+00 2.2200e+02 1.8700e+01 3.9463e+02\n",
            "  2.9400e+00]\n",
            " [6.9050e-02 0.0000e+00 2.1800e+00 0.0000e+00 4.5800e-01 7.1470e+00\n",
            "  5.4200e+01 6.0622e+00 3.0000e+00 2.2200e+02 1.8700e+01 3.9690e+02\n",
            "  5.3300e+00]\n",
            " [2.9850e-02 0.0000e+00 2.1800e+00 0.0000e+00 4.5800e-01 6.4300e+00\n",
            "  5.8700e+01 6.0622e+00 3.0000e+00 2.2200e+02 1.8700e+01 3.9412e+02\n",
            "  5.2100e+00]\n",
            " [8.8290e-02 1.2500e+01 7.8700e+00 0.0000e+00 5.2400e-01 6.0120e+00\n",
            "  6.6600e+01 5.5605e+00 5.0000e+00 3.1100e+02 1.5200e+01 3.9560e+02\n",
            "  1.2430e+01]\n",
            " [1.4455e-01 1.2500e+01 7.8700e+00 0.0000e+00 5.2400e-01 6.1720e+00\n",
            "  9.6100e+01 5.9505e+00 5.0000e+00 3.1100e+02 1.5200e+01 3.9690e+02\n",
            "  1.9150e+01]\n",
            " [2.1124e-01 1.2500e+01 7.8700e+00 0.0000e+00 5.2400e-01 5.6310e+00\n",
            "  1.0000e+02 6.0821e+00 5.0000e+00 3.1100e+02 1.5200e+01 3.8663e+02\n",
            "  2.9930e+01]\n",
            " [1.7004e-01 1.2500e+01 7.8700e+00 0.0000e+00 5.2400e-01 6.0040e+00\n",
            "  8.5900e+01 6.5921e+00 5.0000e+00 3.1100e+02 1.5200e+01 3.8671e+02\n",
            "  1.7100e+01]]\n",
            "\n",
            "y 처음 10개:\n",
            "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9]\n"
          ]
        }
      ],
      "source": [
        "# 3-2. 데이터 전처리\n",
        "# numpy의 hstack 함수: 수평방향으로 배열을 이어붙이는 함수\n",
        "# 짝수행에 홀수를 갖다가 붙인다. df.values[::2, :] -> 0,2,4,6,8... : 전체컬럼 \n",
        "# 홀수행에 앞에 열 2개만 df.values[1::2, :2] \n",
        "\n",
        "try:\n",
        "    # 원본 보스톤 데이터 처리 방식\n",
        "    X = np.hstack([df.values[::2, :], df.values[1::2, :2]])\n",
        "    y = df.values[1::2, 2]  # 이 열이 target\n",
        "    print(\"원본 보스톤 데이터 처리 방식 적용\")\n",
        "except:\n",
        "    # 대체 데이터의 경우 단순 처리\n",
        "    X = df.values[:, :-1]  # 마지막 열 제외한 모든 열\n",
        "    y = df.values[:, -1]   # 마지막 열을 타겟으로\n",
        "    print(\"대체 데이터 처리 방식 적용\")\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"\\nX 처음 10개:\")\n",
        "print(X[:10])\n",
        "print(\"\\ny 처음 10개:\")\n",
        "print(y[:10])\n",
        "\n",
        "# 행의 개수가 같아야 머신러닝 연산을 수행한다. 결과가 입력한 데이터 개수만큼 있어야 한다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련셋 크기: (379, 13)\n",
            "테스트셋 크기: (127, 13)\n"
          ]
        }
      ],
      "source": [
        "# 3-3. 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "print(\"훈련셋 크기:\", X_train.shape)\n",
        "print(\"테스트셋 크기:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== LinearRegression ===\n",
            "훈련셋 점수: 0.748087259862344\n",
            "테스트셋 점수: 0.6844267283527108\n",
            "기울기들 개수: 13\n",
            "기울기들: [-1.28322638e-01  2.95517751e-02  4.88590934e-02  2.77350326e+00\n",
            " -1.62388292e+01  4.36875476e+00 -9.24808158e-03 -1.40086668e+00\n",
            "  2.57761243e-01 -9.95694820e-03 -9.23122944e-01  1.31854199e-02\n",
            " -5.17639519e-01]\n",
            "절편: 29.836420163838763\n"
          ]
        }
      ],
      "source": [
        "# 3-4. 선형 회귀 분석\n",
        "model = LinearRegression() \n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"=== LinearRegression ===\")\n",
        "print(\"훈련셋 점수:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 점수:\", model.score(X_test, y_test))\n",
        "print(\"기울기들 개수:\", len(model.coef_))\n",
        "print(\"기울기들:\", model.coef_)\n",
        "print(\"절편:\", model.intercept_)\n",
        "\n",
        "# 보스톤 주택가격데이터의 특성의 개수는 13개임, 즉 가중치도 13개가 나온다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 규제 기법 적용\n",
        "\n",
        "**과대적합 문제**:\n",
        "- 가중치가 너무 크거나 작으면 훈련데이터셋에 초점이 맞춰집니다\n",
        "- 가중치를 규제하자!\n",
        "\n",
        "**Ridge vs Lasso**:\n",
        "- **Lasso**: 가중치를 0에 가깝게 하다가 불필요한 요소가 있으면 아예 0으로 만들기도 합니다. 모델을 심플하게 만듭니다\n",
        "- **Ridge**: 계수를 완전히 0으로 만들지는 못합니다\n",
        "\n",
        "**하이퍼파라미터 alpha**:\n",
        "- 0으로 놓으면 규제를 아무것도 안하겠다 (LinearRegression과 똑같음)\n",
        "- alpha를 키우면 규제가 높아집니다\n",
        "- 적절한 alpha를 찾는게 중요합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ridge (alpha=10) ===\n",
            "훈련셋 점수: 0.7398240895568372\n",
            "테스트셋 점수: 0.6724237562438142\n",
            "기울기들 개수: 13\n",
            "기울기들: [-0.12137453  0.03421897 -0.01307037  1.8210257  -1.68747299  4.09010212\n",
            " -0.01841796 -1.18806788  0.24351944 -0.01208251 -0.76717881  0.01369631\n",
            " -0.5734354 ]\n",
            "절편: 22.652200585179752\n"
          ]
        }
      ],
      "source": [
        "# 3-5. Ridge 회귀 (L2 정규화)\n",
        "from sklearn.linear_model import Ridge \n",
        "\n",
        "model = Ridge(alpha=10) \n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"=== Ridge (alpha=10) ===\")\n",
        "print(\"훈련셋 점수:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 점수:\", model.score(X_test, y_test))\n",
        "print(\"기울기들 개수:\", len(model.coef_))\n",
        "print(\"기울기들:\", model.coef_)\n",
        "print(\"절편:\", model.intercept_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3-6. Lasso 회귀 (L1 정규화)\n",
        "from sklearn.linear_model import Lasso \n",
        "\n",
        "model = Lasso(alpha=10)  # 숫자가 커질수록 규제가 커진다\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"=== Lasso (alpha=10) ===\")\n",
        "print(\"훈련셋 점수:\", model.score(X_train, y_train))\n",
        "print(\"테스트셋 점수:\", model.score(X_test, y_test))\n",
        "print(\"기울기들 개수:\", len(model.coef_))\n",
        "print(\"기울기들:\", model.coef_)\n",
        "print(\"절편:\", model.intercept_)\n",
        "\n",
        "# 0이 된 계수들 확인\n",
        "zero_coef_count = sum(coef == 0 for coef in model.coef_)\n",
        "print(f\"\\n0이 된 계수의 개수: {zero_coef_count}/{len(model.coef_)}\")\n",
        "print(\"Lasso는 불필요한 특성의 계수를 0으로 만들어 특성 선택 효과가 있습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 전체 모델 비교\n",
        "\n",
        "### 중요한 포인트들\n",
        "- **alpha 값이 적절해야 합니다**: 머신러닝 알고리즘은 하이퍼파라미터를 우리가 수작업으로 찾아야 합니다\n",
        "- **딥러닝 vs 머신러닝**: 딥러닝은 자동으로 찾습니다. 이미지, 흑백사진의 경우는 머신러닝이나 딥러닝이나 비슷합니다\n",
        "- **규제의 효과**: 과대적합을 방지하고 일반화 성능을 향상시킵니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 다양한 alpha 값으로 모델 비교 ===\n",
            "모델              alpha    훈련셋 점수       테스트셋 점수     \n",
            "--------------------------------------------------\n",
            "LinearRegression None     0.7481       0.6844      \n",
            "Ridge           0.1      0.7480       0.6838      \n",
            "Ridge           1        0.7461       0.6790      \n",
            "Ridge           10       0.7398       0.6724      \n",
            "Ridge           100      0.7213       0.6754      \n",
            "\n",
            "Lasso           0.1      0.7369       0.6660      \n",
            "Lasso           1        0.6948       0.6517      \n",
            "Lasso           10       0.5374       0.4946      \n",
            "Lasso           100      0.2122       0.2581      \n"
          ]
        }
      ],
      "source": [
        "# 4-1. 여러 alpha 값으로 Ridge와 Lasso 비교\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "\n",
        "# 한글 폰트 설정\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "alpha_values = [0.1, 1, 10, 100]\n",
        "models = ['LinearRegression', 'Ridge', 'Lasso']\n",
        "\n",
        "print(\"=== 다양한 alpha 값으로 모델 비교 ===\")\n",
        "print(f\"{'모델':<15} {'alpha':<8} {'훈련셋 점수':<12} {'테스트셋 점수':<12}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# LinearRegression (규제 없음)\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(X_train, y_train)\n",
        "print(f\"{'LinearRegression':<15} {'None':<8} {model_lr.score(X_train, y_train):<12.4f} {model_lr.score(X_test, y_test):<12.4f}\")\n",
        "\n",
        "# Ridge 회귀\n",
        "for alpha in alpha_values:\n",
        "    model_ridge = Ridge(alpha=alpha)\n",
        "    model_ridge.fit(X_train, y_train)\n",
        "    print(f\"{'Ridge':<15} {alpha:<8} {model_ridge.score(X_train, y_train):<12.4f} {model_ridge.score(X_test, y_test):<12.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Lasso 회귀\n",
        "for alpha in alpha_values:\n",
        "    model_lasso = Lasso(alpha=alpha)\n",
        "    model_lasso.fit(X_train, y_train)\n",
        "    print(f\"{'Lasso':<15} {alpha:<8} {model_lasso.score(X_train, y_train):<12.4f} {model_lasso.score(X_test, y_test):<12.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 학습 요약\n",
        "\n",
        "### 오늘 학습한 내용\n",
        "1. **단순 선형 회귀**: 하나의 특성으로 예측\n",
        "2. **KNN 회귀**: 이웃 기반 회귀 알고리즘\n",
        "3. **다중 선형 회귀**: 여러 특성을 사용한 회귀\n",
        "4. **Ridge 회귀**: L2 정규화를 통한 과대적합 방지\n",
        "5. **Lasso 회귀**: L1 정규화를 통한 특성 선택 효과\n",
        "\n",
        "### 핵심 포인트\n",
        "- **하이퍼파라미터 튜닝**: alpha 값을 적절히 조정하는 것이 중요\n",
        "- **과대적합 vs 과소적합**: 규제를 통해 균형을 맞춤\n",
        "- **특성 선택**: Lasso는 불필요한 특성의 계수를 0으로 만듦\n",
        "- **모델 평가**: 훈련셋과 테스트셋 점수를 비교하여 일반화 성능 확인\n",
        "\n",
        "### 다음 단계\n",
        "- 교차 검증을 통한 더 정확한 모델 평가\n",
        "- 다른 회귀 알고리즘들과의 비교\n",
        "- 특성 엔지니어링 기법 적용\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
