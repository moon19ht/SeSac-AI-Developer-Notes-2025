{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7689df",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ì™€ ë¶„ì„: ì²´ê³„ì  ì ‘ê·¼ (ì•ˆì „ ì‹¤í–‰ ë²„ì „)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- ë°ì´í„° ì „ì²˜ë¦¬ì˜ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì´í•´\n",
    "- ì •ê·œí™”(Normalization)ì˜ ê°œë…ê³¼ í•„ìš”ì„± í•™ìŠµ\n",
    "- ì²´ê³„ì ì¸ ë°ì´í„° ì „ì²˜ë¦¬ ê¸°ë²• ìŠµë“ (ê²°ì¸¡ì¹˜ â†’ ì¤‘ë³µ â†’ íƒ€ì…ë³€í™˜ â†’ ì¸ì½”ë”© â†’ ì •ê·œí™”)\n",
    "- ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ í™œìš©í•œ ë¶„ì„ ê¸°ë²•\n",
    "- íŒŒì¼ ì…ì¶œë ¥ ë° ë°ì´í„° ì €ì¥ ë°©ë²•\n",
    "\n",
    "---\n",
    "\n",
    "## 1. í™˜ê²½ ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "\n",
    "### 1.1 í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61134c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== í™˜ê²½ ì„¤ì • ì™„ë£Œ ===\n",
      "pandas ë²„ì „: 2.3.1\n",
      "numpy ë²„ì „: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# íŒë‹¤ìŠ¤ ì¶œë ¥ ì˜µì…˜ ì„¤ì •\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"=== í™˜ê²½ ì„¤ì • ì™„ë£Œ ===\")\n",
    "print(f\"pandas ë²„ì „: {pd.__version__}\")\n",
    "print(f\"numpy ë²„ì „: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1b3e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ ===\n"
     ]
    }
   ],
   "source": [
    "### 1.2 ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "def safe_file_path(relative_path):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•œ íŒŒì¼ ê²½ë¡œ ìƒì„± ë° ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    \"\"\"\n",
    "    # í˜„ì¬ ë…¸íŠ¸ë¶ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°\n",
    "    base_path = Path.cwd()\n",
    "    if 'ipynb' in str(base_path):\n",
    "        # ipynb í´ë”ì—ì„œ ì‹¤í–‰ ì¤‘ì´ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™\n",
    "        while base_path.name != 'SeSac-AI-Developer-Notes-2025':\n",
    "            base_path = base_path.parent\n",
    "            if base_path == base_path.parent:  # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ë„ë‹¬\n",
    "                break\n",
    "    \n",
    "    file_path = base_path / relative_path\n",
    "    return file_path\n",
    "\n",
    "def check_file_exists(file_path):\n",
    "    \"\"\"\n",
    "    íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    \"\"\"\n",
    "    if file_path.exists():\n",
    "        print(f\"âœ… íŒŒì¼ ë°œê²¬: {file_path}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âŒ íŒŒì¼ ì—†ìŒ: {file_path}\")\n",
    "        return False\n",
    "\n",
    "def safe_load_csv(relative_path, **kwargs):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•œ CSV íŒŒì¼ ë¡œë“œ\n",
    "    \"\"\"\n",
    "    file_path = safe_file_path(relative_path)\n",
    "    \n",
    "    if not check_file_exists(file_path):\n",
    "        print(f\"ëŒ€ì²´ ê²½ë¡œ ì‹œë„ ì¤‘...\")\n",
    "        # ëª‡ ê°€ì§€ ëŒ€ì²´ ê²½ë¡œ ì‹œë„\n",
    "        alternative_paths = [\n",
    "            Path('06_Machine_Learning/data/csv') / file_path.name,\n",
    "            Path('data/csv') / file_path.name,\n",
    "            Path('csv') / file_path.name\n",
    "        ]\n",
    "        \n",
    "        for alt_path in alternative_paths:\n",
    "            full_alt_path = safe_file_path(alt_path)\n",
    "            if check_file_exists(full_alt_path):\n",
    "                file_path = full_alt_path\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {relative_path}\")\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(file_path, **kwargs)\n",
    "        print(f\"ğŸ“Š ë°ì´í„° ë¡œë“œ ì„±ê³µ: {data.shape}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        raise\n",
    "\n",
    "def print_data_info(data, title=\"ë°ì´í„° ì •ë³´\"):\n",
    "    \"\"\"\n",
    "    ë°ì´í„° ê¸°ë³¸ ì •ë³´ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"ë°ì´í„° í˜•íƒœ: {data.shape}\")\n",
    "    print(f\"ì»¬ëŸ¼ëª…: {list(data.columns)}\")\n",
    "    print(f\"ê²°ì¸¡ì¹˜: {data.isnull().sum().sum()}ê°œ\")\n",
    "    print(f\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {data.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "print(\"=== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a128f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸° íƒìƒ‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57253edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì¼ ë°œê²¬: c:\\Users\\ryan9\\ë¬¸ì„œ\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto-mpg.csv\n",
      "ğŸ“Š ë°ì´í„° ë¡œë“œ ì„±ê³µ: (398, 7)\n",
      "\n",
      "=== ì›ë³¸ ìë™ì°¨ ì—°ë¹„ ë°ì´í„° ===\n",
      "ë°ì´í„° í˜•íƒœ: (398, 7)\n",
      "ì»¬ëŸ¼ëª…: ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model-year']\n",
      "ê²°ì¸¡ì¹˜: 2ê°œ\n",
      "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 42.01 KB\n",
      "\n",
      "=== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ===\n",
      "    mpg  cylinders displacement  horsepower  weight  acceleration  model-year\n",
      "0  18.0          8            ?       130.0    3504          12.0          70\n",
      "1  15.0          8          350       165.0    3693          11.5          70\n",
      "2  18.0          8          318       150.0    3436          11.0          70\n",
      "3  16.0          8          304       150.0    3433          12.0          70\n",
      "4  17.0          8          302       140.0    3449          10.5          70\n",
      "\n",
      "=== ë°ì´í„° íƒ€ì… ì •ë³´ ===\n",
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement     object\n",
      "horsepower      float64\n",
      "weight            int64\n",
      "acceleration    float64\n",
      "model-year        int64\n",
      "dtype: object\n",
      "\n",
      "=== ê¸°ì´ˆ í†µê³„ëŸ‰ ===\n",
      "              mpg   cylinders  horsepower       weight  acceleration  \\\n",
      "count  398.000000  398.000000  396.000000   398.000000    398.000000   \n",
      "mean    23.514573    5.454774  104.189394  2970.424623     15.568090   \n",
      "std      7.815984    1.701004   38.402030   846.841774      2.757689   \n",
      "min      9.000000    3.000000   46.000000  1613.000000      8.000000   \n",
      "25%     17.500000    4.000000   75.000000  2223.750000     13.825000   \n",
      "50%     23.000000    4.000000   92.000000  2803.500000     15.500000   \n",
      "75%     29.000000    8.000000  125.000000  3608.000000     17.175000   \n",
      "max     46.600000    8.000000  230.000000  5140.000000     24.800000   \n",
      "\n",
      "       model-year  \n",
      "count  398.000000  \n",
      "mean    76.010050  \n",
      "std      3.697627  \n",
      "min     70.000000  \n",
      "25%     73.000000  \n",
      "50%     76.000000  \n",
      "75%     79.000000  \n",
      "max     82.000000  \n"
     ]
    }
   ],
   "source": [
    "### 2.1 ìë™ì°¨ ì—°ë¹„ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "try:\n",
    "    # ìƒëŒ€ ê²½ë¡œë¡œ ë°ì´í„° ë¡œë“œ ì‹œë„\n",
    "    data = safe_load_csv('06_Machine_Learning/data/csv/auto-mpg.csv')\n",
    "    \n",
    "    # ê¸°ë³¸ ì •ë³´ ì¶œë ¥\n",
    "    print_data_info(data, \"ì›ë³¸ ìë™ì°¨ ì—°ë¹„ ë°ì´í„°\")\n",
    "    \n",
    "    print(\"\\n=== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ===\")\n",
    "    print(data.head())\n",
    "    \n",
    "    print(\"\\n=== ë°ì´í„° íƒ€ì… ì •ë³´ ===\")\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    print(\"\\n=== ê¸°ì´ˆ í†µê³„ëŸ‰ ===\")\n",
    "    print(data.describe())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}\")\n",
    "    print(\"\\nìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "    np.random.seed(42)\n",
    "    sample_size = 100\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'mpg': np.random.normal(25, 5, sample_size),\n",
    "        'cylinders': np.random.choice([4, 6, 8], sample_size, p=[0.6, 0.3, 0.1]),\n",
    "        'displacement': np.random.normal(200, 50, sample_size),\n",
    "        'horsepower': np.random.normal(120, 30, sample_size),\n",
    "        'weight': np.random.normal(3000, 500, sample_size),\n",
    "        'acceleration': np.random.normal(15, 3, sample_size),\n",
    "        'model-year': np.random.choice(range(70, 83), sample_size)\n",
    "    })\n",
    "    \n",
    "    # ì¼ë¶€ ê²°ì¸¡ì¹˜ ì¶”ê°€\n",
    "    missing_indices = np.random.choice(sample_size, 5, replace=False)\n",
    "    data.loc[missing_indices, 'horsepower'] = '?'\n",
    "    \n",
    "    print(\"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ\")\n",
    "    print_data_info(data, \"ìƒì„±ëœ ìƒ˜í”Œ ë°ì´í„°\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7d3b55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì»¬ëŸ¼ëª… í‘œì¤€í™” ì™„ë£Œ ===\n",
      "ë³€ê²½ëœ ì»¬ëŸ¼: {'mpg': 'mpg', 'cylinders': 'cyl', 'displacement': 'disp', 'horsepower': 'power', 'weight': 'weight', 'acceleration': 'acce', 'model-year': 'model'}\n",
      "ìµœì¢… ì»¬ëŸ¼ëª…: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model']\n",
      "\n",
      "=== ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ê°œìˆ˜ ===\n",
      "- mpg: 129ê°œ\n",
      "- cyl: 5ê°œ\n",
      "- disp: 83ê°œ\n",
      "- power: 93ê°œ\n",
      "- weight: 351ê°œ\n",
      "- acce: 95ê°œ\n",
      "- model: 13ê°œ\n"
     ]
    }
   ],
   "source": [
    "### 2.2 ì»¬ëŸ¼ëª… í‘œì¤€í™”\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
    "column_mapping = {\n",
    "    'mpg': 'mpg',\n",
    "    'cylinders': 'cyl', \n",
    "    'displacement': 'disp',\n",
    "    'horsepower': 'power',\n",
    "    'weight': 'weight',\n",
    "    'acceleration': 'acce',\n",
    "    'model-year': 'model',\n",
    "    'model year': 'model',\n",
    "    'car name': 'car_name'\n",
    "}\n",
    "\n",
    "# ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë³€ê²½\n",
    "existing_mapping = {old: new for old, new in column_mapping.items() if old in data.columns}\n",
    "data = data.rename(columns=existing_mapping)\n",
    "\n",
    "print(\"=== ì»¬ëŸ¼ëª… í‘œì¤€í™” ì™„ë£Œ ===\")\n",
    "print(f\"ë³€ê²½ëœ ì»¬ëŸ¼: {existing_mapping}\")\n",
    "print(f\"ìµœì¢… ì»¬ëŸ¼ëª…: {list(data.columns)}\")\n",
    "\n",
    "# ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ê°œìˆ˜ í™•ì¸\n",
    "print(\"\\n=== ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ê°œìˆ˜ ===\")\n",
    "for col in data.columns:\n",
    "    unique_count = data[col].nunique()\n",
    "    print(f\"- {col}: {unique_count}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec928c55",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ë° ì „ì²˜ë¦¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4db012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì¢…í•© ê²€ì‚¬ ===\n",
      "\n",
      "1ï¸âƒ£ ê²°ì¸¡ì¹˜ ê²€ì‚¬:\n",
      "       ê²°ì¸¡ì¹˜_ê°œìˆ˜  ê²°ì¸¡ì¹˜_ë¹„ìœ¨(%)\n",
      "power       2        0.5\n",
      "\n",
      "2ï¸âƒ£ ì´ìƒê°’ ê²€ì‚¬:\n",
      "- disp: 1ê°œì˜ ë¹„ìˆ˜ì¹˜ ê°’ ë°œê²¬\n",
      "  ì´ìƒê°’: ['?']\n",
      "\n",
      "3ï¸âƒ£ ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬:\n",
      "ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ\n",
      "\n",
      "4ï¸âƒ£ ë°ì´í„° íƒ€ì… ê²€ì‚¬:\n",
      "- mpg: float64\n",
      "- cyl: int64\n",
      "- disp: object\n",
      "- power: float64\n",
      "- weight: int64\n",
      "- acce: float64\n",
      "- model: int64\n"
     ]
    }
   ],
   "source": [
    "### 3.1 ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬\n",
    "\n",
    "def comprehensive_data_quality_check(df):\n",
    "    \"\"\"\n",
    "    í¬ê´„ì ì¸ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì¢…í•© ê²€ì‚¬ ===\")\n",
    "    \n",
    "    # 1. ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "    print(\"\\n1ï¸âƒ£ ê²°ì¸¡ì¹˜ ê²€ì‚¬:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(df)) * 100\n",
    "    \n",
    "    missing_summary = pd.DataFrame({\n",
    "        'ê²°ì¸¡ì¹˜_ê°œìˆ˜': missing_data,\n",
    "        'ê²°ì¸¡ì¹˜_ë¹„ìœ¨(%)': missing_percent.round(2)\n",
    "    })\n",
    "    \n",
    "    missing_cols = missing_summary[missing_summary['ê²°ì¸¡ì¹˜_ê°œìˆ˜'] > 0]\n",
    "    if len(missing_cols) > 0:\n",
    "        print(missing_cols)\n",
    "    else:\n",
    "        print(\"âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\")\n",
    "    \n",
    "    # 2. ì´ìƒê°’ í™•ì¸ ('?' ê°™ì€ ë¬¸ìì—´ ê°’)\n",
    "    print(\"\\n2ï¸âƒ£ ì´ìƒê°’ ê²€ì‚¬:\")\n",
    "    anomaly_found = False\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # ìˆ«ìê°€ ë˜ì–´ì•¼ í•  ì»¬ëŸ¼ì—ì„œ ë¬¸ìì—´ í™•ì¸\n",
    "            if col in ['power', 'weight', 'mpg', 'disp', 'acce']:\n",
    "                non_numeric = df[col].apply(lambda x: not str(x).replace('.', '').replace('-', '').isdigit() if x != '?' else True)\n",
    "                if non_numeric.sum() > 0:\n",
    "                    anomaly_count = non_numeric.sum()\n",
    "                    print(f\"- {col}: {anomaly_count}ê°œì˜ ë¹„ìˆ˜ì¹˜ ê°’ ë°œê²¬\")\n",
    "                    unique_values = df[col][non_numeric].unique()\n",
    "                    print(f\"  ì´ìƒê°’: {unique_values}\")\n",
    "                    anomaly_found = True\n",
    "    \n",
    "    if not anomaly_found:\n",
    "        print(\"âœ… ì´ìƒê°’ ì—†ìŒ\")\n",
    "    \n",
    "    # 3. ì¤‘ë³µ ë°ì´í„° í™•ì¸\n",
    "    print(\"\\n3ï¸âƒ£ ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬:\")\n",
    "    total_duplicates = df.duplicated().sum()\n",
    "    print(f\"ì™„ì „ ì¤‘ë³µ í–‰: {total_duplicates}ê°œ\")\n",
    "    \n",
    "    # 4. ë°ì´í„° íƒ€ì… í™•ì¸\n",
    "    print(\"\\n4ï¸âƒ£ ë°ì´í„° íƒ€ì… ê²€ì‚¬:\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        print(f\"- {col}: {dtype}\")\n",
    "    \n",
    "    return missing_summary, anomaly_found, total_duplicates\n",
    "\n",
    "# ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ì‹¤í–‰\n",
    "missing_summary, has_anomalies, duplicate_count = comprehensive_data_quality_check(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f142a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ”§ ê²°ì¸¡ì¹˜ ë° ì´ìƒê°’ ì²˜ë¦¬ ===\n",
      "\n",
      "ì²˜ë¦¬ ì™„ë£Œëœ í•­ëª©:\n",
      "âœ… disp: 1ê°œì˜ '?' â†’ NaN ë³€í™˜\n",
      "âœ… disp: object â†’ numeric ë³€í™˜\n",
      "âœ… disp: ê²°ì¸¡ì¹˜ â†’ í‰ê· ê°’(193.14) ëŒ€ì²´\n",
      "âœ… power: ê²°ì¸¡ì¹˜ â†’ í‰ê· ê°’(104.19) ëŒ€ì²´\n",
      "\n",
      "=== ì²˜ë¦¬ í›„ ë°ì´í„° ìƒíƒœ ===\n",
      "\n",
      "=== ì •ë¦¬ëœ ë°ì´í„° ===\n",
      "ë°ì´í„° í˜•íƒœ: (398, 7)\n",
      "ì»¬ëŸ¼ëª…: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model']\n",
      "ê²°ì¸¡ì¹˜: 0ê°œ\n",
      "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 21.89 KB\n"
     ]
    }
   ],
   "source": [
    "### 3.2 ê²°ì¸¡ì¹˜ ë° ì´ìƒê°’ ì²˜ë¦¬\n",
    "\n",
    "def safe_handle_missing_and_anomalies(df):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•œ ê²°ì¸¡ì¹˜ ë° ì´ìƒê°’ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ”§ ê²°ì¸¡ì¹˜ ë° ì´ìƒê°’ ì²˜ë¦¬ ===\")\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    changes_made = []\n",
    "    \n",
    "    # 1. '?' ê°’ì„ NaNìœ¼ë¡œ ë³€ê²½\n",
    "    for col in df_processed.columns:\n",
    "        if df_processed[col].dtype == 'object':\n",
    "            question_marks = (df_processed[col] == '?').sum()\n",
    "            if question_marks > 0:\n",
    "                df_processed[col] = df_processed[col].replace('?', np.nan)\n",
    "                changes_made.append(f\"{col}: {question_marks}ê°œì˜ '?' â†’ NaN ë³€í™˜\")\n",
    "    \n",
    "    # 2. ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜\n",
    "    numeric_columns = ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model']\n",
    "    for col in numeric_columns:\n",
    "        if col in df_processed.columns:\n",
    "            if df_processed[col].dtype == 'object':\n",
    "                try:\n",
    "                    df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "                    changes_made.append(f\"{col}: object â†’ numeric ë³€í™˜\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ {col} ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í‰ê· ê°’ ë˜ëŠ” ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´)\n",
    "    for col in df_processed.columns:\n",
    "        if df_processed[col].isnull().sum() > 0:\n",
    "            if df_processed[col].dtype in ['int64', 'float64']:\n",
    "                # ìˆ˜ì¹˜í˜•: í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "                mean_value = df_processed[col].mean()\n",
    "                df_processed[col].fillna(mean_value, inplace=True)\n",
    "                changes_made.append(f\"{col}: ê²°ì¸¡ì¹˜ â†’ í‰ê· ê°’({mean_value:.2f}) ëŒ€ì²´\")\n",
    "            else:\n",
    "                # ë²”ì£¼í˜•: ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "                mode_value = df_processed[col].mode()[0] if not df_processed[col].mode().empty else 'Unknown'\n",
    "                df_processed[col].fillna(mode_value, inplace=True)\n",
    "                changes_made.append(f\"{col}: ê²°ì¸¡ì¹˜ â†’ ìµœë¹ˆê°’({mode_value}) ëŒ€ì²´\")\n",
    "    \n",
    "    # ë³€ê²½ì‚¬í•­ ì¶œë ¥\n",
    "    if changes_made:\n",
    "        print(\"\\nì²˜ë¦¬ ì™„ë£Œëœ í•­ëª©:\")\n",
    "        for change in changes_made:\n",
    "            print(f\"âœ… {change}\")\n",
    "    else:\n",
    "        print(\"âœ… ì²˜ë¦¬í•  ê²°ì¸¡ì¹˜/ì´ìƒê°’ ì—†ìŒ\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ë° ì´ìƒê°’ ì²˜ë¦¬ ì‹¤í–‰\n",
    "data_cleaned = safe_handle_missing_and_anomalies(data)\n",
    "\n",
    "print(\"\\n=== ì²˜ë¦¬ í›„ ë°ì´í„° ìƒíƒœ ===\")\n",
    "print_data_info(data_cleaned, \"ì •ë¦¬ëœ ë°ì´í„°\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3471a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì œê±° ===\n",
      "ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ\n",
      "âœ… ì¤‘ë³µ ë°ì´í„° ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "### 3.3 ì¤‘ë³µ ë°ì´í„° ì œê±°\n",
    "\n",
    "def safe_remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•œ ì¤‘ë³µ ë°ì´í„° ì œê±°\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì œê±° ===\")\n",
    "    \n",
    "    original_length = len(df)\n",
    "    \n",
    "    # ì™„ì „ ì¤‘ë³µ í™•ì¸\n",
    "    complete_duplicates = df.duplicated().sum()\n",
    "    print(f\"ì™„ì „ ì¤‘ë³µ í–‰: {complete_duplicates}ê°œ\")\n",
    "    \n",
    "    if complete_duplicates > 0:\n",
    "        df_no_duplicates = df.drop_duplicates()\n",
    "        removed_count = original_length - len(df_no_duplicates)\n",
    "        print(f\"âœ… {removed_count}ê°œì˜ ì¤‘ë³µ í–‰ ì œê±° ì™„ë£Œ\")\n",
    "        print(f\"ì²˜ë¦¬ í›„ ë°ì´í„° ê°œìˆ˜: {len(df_no_duplicates)}ê°œ\")\n",
    "        return df_no_duplicates\n",
    "    else:\n",
    "        print(\"âœ… ì¤‘ë³µ ë°ì´í„° ì—†ìŒ\")\n",
    "        return df\n",
    "\n",
    "# ì¤‘ë³µ ì œê±° ì‹¤í–‰\n",
    "data_no_duplicates = safe_remove_duplicates(data_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada7082",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. ë°ì´í„° ë³€í™˜ ë° ì •ê·œí™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d5fb1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ¯ ë°ì´í„° íƒ€ì… ìµœì í™” ===\n",
      "âœ… cyl: int64 â†’ uint8 ë³€í™˜\n",
      "âœ… model: int64 â†’ uint8 ë³€í™˜\n",
      "âœ… cyl: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜ (5ê°œ ë²”ì£¼)\n",
      "âœ… model: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜ (13ê°œ ë²”ì£¼)\n",
      "\n",
      "=== ìµœì í™” í›„ ë°ì´í„° íƒ€ì… ===\n",
      "mpg        float64\n",
      "cyl       category\n",
      "disp       float64\n",
      "power      float64\n",
      "weight       int64\n",
      "acce       float64\n",
      "model     category\n",
      "dtype: object\n",
      "\n",
      "=== ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ ===\n",
      "ìµœì í™” ì „: 42.01 KB\n",
      "ìµœì í™” í›„: 16.91 KB\n",
      "ì ˆì•½ëœ ë©”ëª¨ë¦¬: 25.10 KB (59.8%)\n"
     ]
    }
   ],
   "source": [
    "### 4.1 ë°ì´í„° íƒ€ì… ìµœì í™”\n",
    "\n",
    "def optimize_data_types(df):\n",
    "    \"\"\"\n",
    "    ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•œ ë°ì´í„° íƒ€ì… ìµœì í™”\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ¯ ë°ì´í„° íƒ€ì… ìµœì í™” ===\")\n",
    "    \n",
    "    df_optimized = df.copy()\n",
    "    \n",
    "    # ì •ìˆ˜í˜• ì»¬ëŸ¼ ìµœì í™”\n",
    "    int_columns = ['cyl', 'model']\n",
    "    for col in int_columns:\n",
    "        if col in df_optimized.columns:\n",
    "            try:\n",
    "                col_min, col_max = df_optimized[col].min(), df_optimized[col].max()\n",
    "                \n",
    "                if col_min >= 0 and col_max <= 255:\n",
    "                    df_optimized[col] = df_optimized[col].astype('uint8')\n",
    "                    print(f\"âœ… {col}: int64 â†’ uint8 ë³€í™˜\")\n",
    "                elif col_min >= -128 and col_max <= 127:\n",
    "                    df_optimized[col] = df_optimized[col].astype('int8')\n",
    "                    print(f\"âœ… {col}: int64 â†’ int8 ë³€í™˜\")\n",
    "                elif col_min >= -32768 and col_max <= 32767:\n",
    "                    df_optimized[col] = df_optimized[col].astype('int16')\n",
    "                    print(f\"âœ… {col}: int64 â†’ int16 ë³€í™˜\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {col} ìµœì í™” ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ë²”ì£¼í˜• ë°ì´í„° ì‹ë³„ ë° ë³€í™˜\n",
    "    categorical_candidates = ['cyl', 'model']\n",
    "    for col in categorical_candidates:\n",
    "        if col in df_optimized.columns:\n",
    "            unique_count = df_optimized[col].nunique()\n",
    "            if unique_count <= 20:  # ê³ ìœ ê°’ì´ 20ê°œ ì´í•˜ë©´ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "                try:\n",
    "                    df_optimized[col] = df_optimized[col].astype('category')\n",
    "                    print(f\"âœ… {col}: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜ ({unique_count}ê°œ ë²”ì£¼)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ {col} ë²”ì£¼í˜• ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return df_optimized\n",
    "\n",
    "# ë°ì´í„° íƒ€ì… ìµœì í™” ì‹¤í–‰\n",
    "data_optimized = optimize_data_types(data_no_duplicates)\n",
    "\n",
    "print(\"\\n=== ìµœì í™” í›„ ë°ì´í„° íƒ€ì… ===\")\n",
    "print(data_optimized.dtypes)\n",
    "\n",
    "print(\"\\n=== ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ ===\")\n",
    "original_memory = data.memory_usage(deep=True).sum() / 1024\n",
    "optimized_memory = data_optimized.memory_usage(deep=True).sum() / 1024\n",
    "print(f\"ìµœì í™” ì „: {original_memory:.2f} KB\")\n",
    "print(f\"ìµœì í™” í›„: {optimized_memory:.2f} KB\")\n",
    "print(f\"ì ˆì•½ëœ ë©”ëª¨ë¦¬: {original_memory - optimized_memory:.2f} KB ({((original_memory - optimized_memory) / original_memory * 100):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3008709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ“ ë°ì´í„° ì •ê·œí™” (Min-Max Scaling) ===\n",
      "ì •ê·œí™” ëŒ€ìƒ ì»¬ëŸ¼: ['mpg', 'disp', 'power', 'weight', 'acce']\n",
      "\n",
      "=== ì •ê·œí™” ì „ ë°ì´í„° ë²”ìœ„ ===\n",
      "mpg     :     9.00 ~    46.60 (ë²”ìœ„:    37.60)\n",
      "disp    :    68.00 ~   455.00 (ë²”ìœ„:   387.00)\n",
      "power   :    46.00 ~   230.00 (ë²”ìœ„:   184.00)\n",
      "weight  :  1613.00 ~  5140.00 (ë²”ìœ„:  3527.00)\n",
      "acce    :     8.00 ~    24.80 (ë²”ìœ„:    16.80)\n",
      "\n",
      "âœ… ì •ê·œí™” ì™„ë£Œ! ê° ì»¬ëŸ¼ì— '_norm' ì ‘ë¯¸ì‚¬ ì¶”ê°€\n",
      "\n",
      "=== ì •ê·œí™” í›„ ë°ì´í„° ë²”ìœ„ ===\n",
      "mpg_norm    : 0.000 ~ 1.000\n",
      "disp_norm   : 0.000 ~ 1.000\n",
      "power_norm  : 0.000 ~ 1.000\n",
      "weight_norm : 0.000 ~ 1.000\n",
      "acce_norm   : 0.000 ~ 1.000\n"
     ]
    }
   ],
   "source": [
    "### 4.2 ì •ê·œí™” (Normalization)\n",
    "\n",
    "def safe_normalize_data(df):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•œ ë°ì´í„° ì •ê·œí™”\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ“ ë°ì´í„° ì •ê·œí™” (Min-Max Scaling) ===\")\n",
    "    \n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # ì •ê·œí™”í•  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì‹ë³„\n",
    "    numeric_columns = []\n",
    "    for col in df_normalized.columns:\n",
    "        if df_normalized[col].dtype in ['int64', 'float64', 'int32', 'float32', 'int16', 'int8', 'uint8']:\n",
    "            numeric_columns.append(col)\n",
    "    \n",
    "    print(f\"ì •ê·œí™” ëŒ€ìƒ ì»¬ëŸ¼: {numeric_columns}\")\n",
    "    \n",
    "    if not numeric_columns:\n",
    "        print(\"âŒ ì •ê·œí™”í•  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return df_normalized, None\n",
    "    \n",
    "    # ì •ê·œí™” ì „ ë²”ìœ„ í™•ì¸\n",
    "    print(\"\\n=== ì •ê·œí™” ì „ ë°ì´í„° ë²”ìœ„ ===\")\n",
    "    for col in numeric_columns:\n",
    "        col_min, col_max = df_normalized[col].min(), df_normalized[col].max()\n",
    "        col_range = col_max - col_min\n",
    "        print(f\"{col:8s}: {col_min:8.2f} ~ {col_max:8.2f} (ë²”ìœ„: {col_range:8.2f})\")\n",
    "    \n",
    "    # Min-Max ì •ê·œí™” ìˆ˜í–‰\n",
    "    try:\n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        # ìˆ˜ì¹˜í˜• ë°ì´í„°ë§Œ ì„ íƒí•˜ì—¬ ì •ê·œí™”\n",
    "        numeric_data = df_normalized[numeric_columns].astype(float)\n",
    "        \n",
    "        # ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "        if numeric_data.isnull().sum().sum() > 0:\n",
    "            print(\"âš ï¸ ê²°ì¸¡ì¹˜ ë°œê²¬, í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\")\n",
    "            numeric_data = numeric_data.fillna(numeric_data.mean())\n",
    "        \n",
    "        # ì •ê·œí™” ìˆ˜í–‰\n",
    "        normalized_values = scaler.fit_transform(numeric_data)\n",
    "        \n",
    "        # ì •ê·œí™”ëœ ì»¬ëŸ¼ ì¶”ê°€ (ì›ë³¸ ì»¬ëŸ¼ ìœ ì§€)\n",
    "        for i, col in enumerate(numeric_columns):\n",
    "            df_normalized[f'{col}_norm'] = normalized_values[:, i]\n",
    "        \n",
    "        print(\"\\nâœ… ì •ê·œí™” ì™„ë£Œ! ê° ì»¬ëŸ¼ì— '_norm' ì ‘ë¯¸ì‚¬ ì¶”ê°€\")\n",
    "        \n",
    "        # ì •ê·œí™” í›„ ë²”ìœ„ í™•ì¸\n",
    "        print(\"\\n=== ì •ê·œí™” í›„ ë°ì´í„° ë²”ìœ„ ===\")\n",
    "        for col in numeric_columns:\n",
    "            norm_col = f'{col}_norm'\n",
    "            if norm_col in df_normalized.columns:\n",
    "                norm_min, norm_max = df_normalized[norm_col].min(), df_normalized[norm_col].max()\n",
    "                print(f\"{norm_col:12s}: {norm_min:.3f} ~ {norm_max:.3f}\")\n",
    "        \n",
    "        return df_normalized, scaler\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì •ê·œí™” ì‹¤íŒ¨: {e}\")\n",
    "        return df_normalized, None\n",
    "\n",
    "# ì •ê·œí™” ì‹¤í–‰\n",
    "data_normalized, scaler = safe_normalize_data(data_optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6c60cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸŒ ë‹¨ìœ„ ë³€í™˜: MPG â†’ KPL ===\n",
      "ë³€í™˜ ê³„ìˆ˜: 0.425143\n",
      "MPG ë²”ìœ„: 9.0 ~ 46.6\n",
      "KPL ë²”ìœ„: 3.8 ~ 19.8\n",
      "\n",
      "ë³€í™˜ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):\n",
      "    mpg   kpl\n",
      "0  18.0  7.65\n",
      "1  15.0  6.38\n",
      "2  18.0  7.65\n",
      "3  16.0  6.80\n",
      "4  17.0  7.23\n",
      "âœ… MPG â†’ KPL ë³€í™˜ ì™„ë£Œ\n",
      "\n",
      "=== ìµœì¢… ë°ì´í„° ìƒíƒœ ===\n",
      "\n",
      "=== ìµœì¢… ì „ì²˜ë¦¬ ì™„ë£Œ ë°ì´í„° ===\n",
      "ë°ì´í„° í˜•íƒœ: (398, 13)\n",
      "ì»¬ëŸ¼ëª…: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model', 'mpg_norm', 'disp_norm', 'power_norm', 'weight_norm', 'acce_norm', 'kpl']\n",
      "ê²°ì¸¡ì¹˜: 0ê°œ\n",
      "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 35.56 KB\n",
      "\n",
      "ìµœì¢… ì»¬ëŸ¼ ëª©ë¡: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model', 'mpg_norm', 'disp_norm', 'power_norm', 'weight_norm', 'acce_norm', 'kpl']\n"
     ]
    }
   ],
   "source": [
    "### 4.3 ë‹¨ìœ„ ë³€í™˜ (MPG â†’ KPL)\n",
    "\n",
    "def add_unit_conversions(df):\n",
    "    \"\"\"\n",
    "    ë‹¨ìœ„ ë³€í™˜ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸŒ ë‹¨ìœ„ ë³€í™˜: MPG â†’ KPL ===\")\n",
    "    \n",
    "    df_converted = df.copy()\n",
    "    \n",
    "    if 'mpg' in df_converted.columns:\n",
    "        try:\n",
    "            # MPG to KPL ë³€í™˜ ê³„ìˆ˜\n",
    "            mpg_to_kpl_factor = 1.60934 / 3.78541  # 1ë§ˆì¼ = 1.60934km, 1ê°¤ëŸ° = 3.78541ë¦¬í„°\n",
    "            \n",
    "            df_converted['kpl'] = (df_converted['mpg'] * mpg_to_kpl_factor).round(2)\n",
    "            \n",
    "            print(f\"ë³€í™˜ ê³„ìˆ˜: {mpg_to_kpl_factor:.6f}\")\n",
    "            print(f\"MPG ë²”ìœ„: {df_converted['mpg'].min():.1f} ~ {df_converted['mpg'].max():.1f}\")\n",
    "            print(f\"KPL ë²”ìœ„: {df_converted['kpl'].min():.1f} ~ {df_converted['kpl'].max():.1f}\")\n",
    "            \n",
    "            print(\"\\në³€í™˜ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):\")\n",
    "            comparison = df_converted[['mpg', 'kpl']].head()\n",
    "            print(comparison)\n",
    "            \n",
    "            print(\"âœ… MPG â†’ KPL ë³€í™˜ ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë‹¨ìœ„ ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "    else:\n",
    "        print(\"âŒ MPG ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return df_converted\n",
    "\n",
    "# ë‹¨ìœ„ ë³€í™˜ ì‹¤í–‰\n",
    "data_final = add_unit_conversions(data_normalized)\n",
    "\n",
    "print(\"\\n=== ìµœì¢… ë°ì´í„° ìƒíƒœ ===\")\n",
    "print_data_info(data_final, \"ìµœì¢… ì „ì²˜ë¦¬ ì™„ë£Œ ë°ì´í„°\")\n",
    "print(f\"\\nìµœì¢… ì»¬ëŸ¼ ëª©ë¡: {list(data_final.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8c8ed",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5d6f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ“Š ì¢…í•© ë°ì´í„° ë¶„ì„ ===\n",
      "\n",
      "ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ (6ê°œ): ['mpg', 'disp', 'power', 'weight', 'acce', 'kpl']\n",
      "ë²”ì£¼í˜• ì»¬ëŸ¼ (2ê°œ): ['cyl', 'model']\n",
      "\n",
      "=== ìˆ˜ì¹˜í˜• ë°ì´í„° ê¸°ì´ˆ í†µê³„ëŸ‰ ===\n",
      "          mpg    disp   power   weight    acce     kpl\n",
      "count  398.00  398.00  398.00   398.00  398.00  398.00\n",
      "mean    23.51  193.14  104.19  2970.42   15.57   10.00\n",
      "std      7.82  104.11   38.31   846.84    2.76    3.32\n",
      "min      9.00   68.00   46.00  1613.00    8.00    3.83\n",
      "25%     17.50  104.25   75.00  2223.75   13.82    7.44\n",
      "50%     23.00  148.50   92.50  2803.50   15.50    9.78\n",
      "75%     29.00  261.50  125.00  3608.00   17.18   12.33\n",
      "max     46.60  455.00  230.00  5140.00   24.80   19.81\n",
      "\n",
      "=== ë²”ì£¼í˜• ë°ì´í„° ë¶„í¬ ===\n",
      "\n",
      "cyl ë¶„í¬:\n",
      "cyl\n",
      "4    204\n",
      "8    103\n",
      "6     84\n",
      "3      4\n",
      "5      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model ë¶„í¬:\n",
      "model\n",
      "73    40\n",
      "78    36\n",
      "76    34\n",
      "82    31\n",
      "75    30\n",
      "80    29\n",
      "79    29\n",
      "81    29\n",
      "70    29\n",
      "71    28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== ì‹¤ë¦°ë”ë³„ ë¶„ì„ ===\n",
      "     mpg_count  mpg_mean  mpg_std  weight_mean  power_mean\n",
      "cyl                                                       \n",
      "3            4     20.55     2.56      2398.50       99.25\n",
      "4          204     29.29     5.71      2308.13       78.38\n",
      "5            3     27.37     8.23      3103.33       82.33\n",
      "6           84     19.99     3.81      3198.23      101.54\n",
      "8          103     14.96     2.84      4114.72      158.30\n"
     ]
    }
   ],
   "source": [
    "### 5.1 ê¸°ë³¸ í†µê³„ ë¶„ì„\n",
    "\n",
    "def comprehensive_data_analysis(df):\n",
    "    \"\"\"\n",
    "    ì¢…í•©ì ì¸ ë°ì´í„° ë¶„ì„\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ“Š ì¢…í•© ë°ì´í„° ë¶„ì„ ===\")\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì‹ë³„\n",
    "    numeric_cols = []\n",
    "    categorical_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64', 'int32', 'float32', 'int16', 'int8', 'uint8'] and not col.endswith('_norm'):\n",
    "            numeric_cols.append(col)\n",
    "        elif df[col].dtype == 'category' or df[col].dtype == 'object':\n",
    "            categorical_cols.append(col)\n",
    "    \n",
    "    print(f\"\\nìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ({len(numeric_cols)}ê°œ): {numeric_cols}\")\n",
    "    print(f\"ë²”ì£¼í˜• ì»¬ëŸ¼ ({len(categorical_cols)}ê°œ): {categorical_cols}\")\n",
    "    \n",
    "    # 1. ê¸°ì´ˆ í†µê³„ëŸ‰\n",
    "    if numeric_cols:\n",
    "        print(\"\\n=== ìˆ˜ì¹˜í˜• ë°ì´í„° ê¸°ì´ˆ í†µê³„ëŸ‰ ===\")\n",
    "        stats = df[numeric_cols].describe().round(2)\n",
    "        print(stats)\n",
    "    \n",
    "    # 2. ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„\n",
    "    if categorical_cols:\n",
    "        print(\"\\n=== ë²”ì£¼í˜• ë°ì´í„° ë¶„í¬ ===\")\n",
    "        for col in categorical_cols[:3]:  # ì²˜ìŒ 3ê°œë§Œ\n",
    "            print(f\"\\n{col} ë¶„í¬:\")\n",
    "            value_counts = df[col].value_counts()\n",
    "            print(value_counts.head(10))\n",
    "    \n",
    "    # 3. ì‹¤ë¦°ë”ë³„ ë¶„ì„ (ì¡´ì¬í•˜ëŠ” ê²½ìš°)\n",
    "    if 'cyl' in df.columns:\n",
    "        print(\"\\n=== ì‹¤ë¦°ë”ë³„ ë¶„ì„ ===\")\n",
    "        try:\n",
    "            cyl_analysis = df.groupby('cyl').agg({\n",
    "                'mpg': ['count', 'mean', 'std'] if 'mpg' in df.columns else ['count'],\n",
    "                'weight': ['mean'] if 'weight' in df.columns else ['count'],\n",
    "                'power': ['mean'] if 'power' in df.columns else ['count']\n",
    "            }).round(2)\n",
    "            \n",
    "            # ì»¬ëŸ¼ëª… í‰íƒ„í™”\n",
    "            cyl_analysis.columns = ['_'.join(col).strip() for col in cyl_analysis.columns.values]\n",
    "            print(cyl_analysis)\n",
    "        except Exception as e:\n",
    "            print(f\"ì‹¤ë¦°ë”ë³„ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    return numeric_cols, categorical_cols\n",
    "\n",
    "# ë¶„ì„ ì‹¤í–‰\n",
    "numeric_columns, categorical_columns = comprehensive_data_analysis(data_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22ee4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ” ì¡°ê±´ë¶€ ë¶„ì„ ===\n",
      "\n",
      "1ï¸âƒ£ ì—°ë¹„ ê¸°ë°˜ ë¶„ì„:\n",
      "ì—°ë¹„ ìƒìœ„ 25% ê¸°ì¤€: 29.0 mpg ì´ìƒ\n",
      "í•´ë‹¹ ì°¨ëŸ‰ ìˆ˜: 105ëŒ€ (26.4%)\n",
      "ì—°ë¹„ í•˜ìœ„ 25% ê¸°ì¤€: 17.5 mpg ì´í•˜\n",
      "í•´ë‹¹ ì°¨ëŸ‰ ìˆ˜: 104ëŒ€ (26.1%)\n",
      "\n",
      "2ï¸âƒ£ ì—°ë„ë³„ ë¶„ì„:\n",
      "ì—°ë„ë³„ ë¶„ì„ ì˜¤ë¥˜: Unordered Categoricals can only compare equality or not\n",
      "\n",
      "3ï¸âƒ£ ê³ ì„±ëŠ¥ ì°¨ëŸ‰ ë¶„ì„:\n",
      "ê³ ì„±ëŠ¥ ì°¨ëŸ‰ ê¸°ì¤€: 140.0 ì´ìƒ\n",
      "í•´ë‹¹ ì°¨ëŸ‰ ìˆ˜: 84ëŒ€\n",
      "- í‰ê·  ì—°ë¹„: 14.29 mpg\n",
      "- í‰ê·  ë¬´ê²Œ: 4201\n"
     ]
    }
   ],
   "source": [
    "### 5.2 ì¡°ê±´ë¶€ ë¶„ì„\n",
    "\n",
    "def conditional_analysis(df):\n",
    "    \"\"\"\n",
    "    ì¡°ê±´ë¶€ í•„í„°ë§ ë¶„ì„\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ” ì¡°ê±´ë¶€ ë¶„ì„ ===\")\n",
    "    \n",
    "    # MPG ê¸°ë°˜ ë¶„ì„\n",
    "    if 'mpg' in df.columns:\n",
    "        print(\"\\n1ï¸âƒ£ ì—°ë¹„ ê¸°ë°˜ ë¶„ì„:\")\n",
    "        try:\n",
    "            # ì—°ë¹„ ìƒìœ„ 25% ì°¨ëŸ‰\n",
    "            high_mpg_threshold = df['mpg'].quantile(0.75)\n",
    "            high_mpg_cars = df[df['mpg'] >= high_mpg_threshold]\n",
    "            print(f\"ì—°ë¹„ ìƒìœ„ 25% ê¸°ì¤€: {high_mpg_threshold:.1f} mpg ì´ìƒ\")\n",
    "            print(f\"í•´ë‹¹ ì°¨ëŸ‰ ìˆ˜: {len(high_mpg_cars)}ëŒ€ ({len(high_mpg_cars)/len(df)*100:.1f}%)\")\n",
    "            \n",
    "            # ì—°ë¹„ í•˜ìœ„ 25% ì°¨ëŸ‰\n",
    "            low_mpg_threshold = df['mpg'].quantile(0.25)\n",
    "            low_mpg_cars = df[df['mpg'] <= low_mpg_threshold]\n",
    "            print(f\"ì—°ë¹„ í•˜ìœ„ 25% ê¸°ì¤€: {low_mpg_threshold:.1f} mpg ì´í•˜\")\n",
    "            print(f\"í•´ë‹¹ ì°¨ëŸ‰ ìˆ˜: {len(low_mpg_cars)}ëŒ€ ({len(low_mpg_cars)/len(df)*100:.1f}%)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ì—°ë¹„ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    # ì—°ë„ë³„ ë¶„ì„\n",
    "    if 'model' in df.columns:\n",
    "        print(\"\\n2ï¸âƒ£ ì—°ë„ë³„ ë¶„ì„:\")\n",
    "        try:\n",
    "            # 80ë…„ëŒ€ ì°¨ëŸ‰ ë¶„ì„\n",
    "            eighties_cars = df[(df['model'] >= 80) & (df['model'] <= 89)]\n",
    "            if len(eighties_cars) > 0:\n",
    "                print(f\"\\n80ë…„ëŒ€ ì°¨ëŸ‰ ({len(eighties_cars)}ëŒ€):\")\n",
    "                if 'mpg' in df.columns:\n",
    "                    print(f\"- í‰ê·  ì—°ë¹„: {eighties_cars['mpg'].mean():.2f} mpg\")\n",
    "                if 'weight' in df.columns:\n",
    "                    print(f\"- í‰ê·  ë¬´ê²Œ: {eighties_cars['weight'].mean():.0f}\")\n",
    "                if 'cyl' in df.columns:\n",
    "                    mode_cyl = eighties_cars['cyl'].mode()\n",
    "                    if not mode_cyl.empty:\n",
    "                        print(f\"- ê°€ì¥ ë§ì€ ì‹¤ë¦°ë”: {mode_cyl.iloc[0]}ê°œ\")\n",
    "            else:\n",
    "                print(\"80ë…„ëŒ€ ì°¨ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ì—°ë„ë³„ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    # ê³ ì„±ëŠ¥ ì°¨ëŸ‰ ë¶„ì„\n",
    "    if 'power' in df.columns:\n",
    "        print(\"\\n3ï¸âƒ£ ê³ ì„±ëŠ¥ ì°¨ëŸ‰ ë¶„ì„:\")\n",
    "        try:\n",
    "            high_power_threshold = df['power'].quantile(0.8)\n",
    "            high_power_cars = df[df['power'] >= high_power_threshold]\n",
    "            print(f\"ê³ ì„±ëŠ¥ ì°¨ëŸ‰ ê¸°ì¤€: {high_power_threshold:.1f} ì´ìƒ\")\n",
    "            print(f\"í•´ë‹¹ ì°¨ëŸ‰ ìˆ˜: {len(high_power_cars)}ëŒ€\")\n",
    "            \n",
    "            if len(high_power_cars) > 0 and 'mpg' in df.columns:\n",
    "                print(f\"- í‰ê·  ì—°ë¹„: {high_power_cars['mpg'].mean():.2f} mpg\")\n",
    "                if 'weight' in df.columns:\n",
    "                    print(f\"- í‰ê·  ë¬´ê²Œ: {high_power_cars['weight'].mean():.0f}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"ê³ ì„±ëŠ¥ ì°¨ëŸ‰ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ë¶„ì„ ì‹¤í–‰\n",
    "conditional_analysis(data_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97f710",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. ë°ì´í„° ì €ì¥ ë° ë‚´ë³´ë‚´ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91056c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ’¾ ë°ì´í„° ì €ì¥ ===\n",
      "âœ… CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\ryan9\\ë¬¸ì„œ\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto_mpg_processed.csv\n",
      "âœ… Excel ì €ì¥ ì™„ë£Œ: c:\\Users\\ryan9\\ë¬¸ì„œ\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto_mpg_processed.xlsx\n",
      "âœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: c:\\Users\\ryan9\\ë¬¸ì„œ\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto_mpg_processed_report.txt\n",
      "\n",
      "=== ì „ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½ ===\n",
      "âœ… ì›ë³¸ ë°ì´í„°ì—ì„œ ìµœì¢… ë°ì´í„°ë¡œ ì„±ê³µì  ë³€í™˜\n",
      "âœ… ëª¨ë“  ì „ì²˜ë¦¬ ë‹¨ê³„ ì™„ë£Œ\n",
      "âœ… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì ìš© ì¤€ë¹„ ì™„ë£Œ\n",
      "âœ… ì•ˆì „í•œ íŒŒì¼ ì €ì¥ ì™„ë£Œ\n",
      "\n",
      "ìµœì¢… ë°ì´í„° ì •ë³´:\n",
      "\n",
      "=== ë‚´ë³´ë‚´ê¸° ì™„ë£Œ ë°ì´í„° ===\n",
      "ë°ì´í„° í˜•íƒœ: (398, 13)\n",
      "ì»¬ëŸ¼ëª…: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model', 'mpg_norm', 'disp_norm', 'power_norm', 'weight_norm', 'acce_norm', 'kpl']\n",
      "ê²°ì¸¡ì¹˜: 0ê°œ\n",
      "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 35.56 KB\n"
     ]
    }
   ],
   "source": [
    "### 6.1 ì•ˆì „í•œ ë°ì´í„° ì €ì¥\n",
    "\n",
    "def safe_export_data(df, filename_prefix=\"auto_mpg_processed\"):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•œ ë°ì´í„° ì €ì¥ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ’¾ ë°ì´í„° ì €ì¥ ===\")\n",
    "    \n",
    "    try:\n",
    "        # ì €ì¥í•  ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±\n",
    "        output_dir = safe_file_path('06_Machine_Learning/data/csv')\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # ì €ì¥í•  ì»¬ëŸ¼ ì„ íƒ (ì •ê·œí™”ëœ ì»¬ëŸ¼ í¬í•¨)\n",
    "        columns_to_save = [col for col in df.columns if not col.startswith('Unnamed')]\n",
    "        final_export_data = df[columns_to_save].copy()\n",
    "        \n",
    "        # CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "        csv_path = output_dir / f\"{filename_prefix}.csv\"\n",
    "        final_export_data.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "        \n",
    "        # Excel íŒŒì¼ë¡œë„ ì €ì¥ ì‹œë„\n",
    "        try:\n",
    "            excel_path = output_dir / f\"{filename_prefix}.xlsx\"\n",
    "            final_export_data.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "            print(f\"âœ… Excel ì €ì¥ ì™„ë£Œ: {excel_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Excel ì €ì¥ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­): {e}\")\n",
    "        \n",
    "        # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "        report_path = output_dir / f\"{filename_prefix}_report.txt\"\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=== ë°ì´í„° ì „ì²˜ë¦¬ ìš”ì•½ ë¦¬í¬íŠ¸ ===\\n\\n\")\n",
    "            f.write(f\"ì²˜ë¦¬ ì¼ì‹œ: {pd.Timestamp.now()}\\n\")\n",
    "            f.write(f\"ìµœì¢… ë°ì´í„° í˜•íƒœ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´\\n\")\n",
    "            f.write(f\"í¬í•¨ëœ ì»¬ëŸ¼: {len(columns_to_save)}ê°œ\\n\")\n",
    "            f.write(f\"ì»¬ëŸ¼ ëª©ë¡: {list(columns_to_save)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"=== ì „ì²˜ë¦¬ ê³¼ì • ===\\n\")\n",
    "            f.write(\"1. ê²°ì¸¡ì¹˜ ë° ì´ìƒê°’ ì²˜ë¦¬\\n\")\n",
    "            f.write(\"2. ì¤‘ë³µ ë°ì´í„° ì œê±°\\n\")\n",
    "            f.write(\"3. ë°ì´í„° íƒ€ì… ìµœì í™”\\n\")\n",
    "            f.write(\"4. Min-Max ì •ê·œí™” ì ìš©\\n\")\n",
    "            f.write(\"5. ë‹¨ìœ„ ë³€í™˜ (MPG â†’ KPL)\\n\\n\")\n",
    "            \n",
    "            f.write(\"=== ë°ì´í„° í’ˆì§ˆ ===\\n\")\n",
    "            f.write(f\"ê²°ì¸¡ì¹˜: {df.isnull().sum().sum()}ê°œ\\n\")\n",
    "            f.write(f\"ì¤‘ë³µ í–‰: {df.duplicated().sum()}ê°œ\\n\")\n",
    "            f.write(f\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\\n\")\n",
    "        \n",
    "        print(f\"âœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_path}\")\n",
    "        \n",
    "        return csv_path, final_export_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# ë°ì´í„° ì €ì¥ ì‹¤í–‰\n",
    "saved_path, exported_data = safe_export_data(data_final)\n",
    "\n",
    "print(\"\\n=== ì „ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½ ===\")\n",
    "print(f\"âœ… ì›ë³¸ ë°ì´í„°ì—ì„œ ìµœì¢… ë°ì´í„°ë¡œ ì„±ê³µì  ë³€í™˜\")\n",
    "print(f\"âœ… ëª¨ë“  ì „ì²˜ë¦¬ ë‹¨ê³„ ì™„ë£Œ\")\n",
    "print(f\"âœ… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì ìš© ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"âœ… ì•ˆì „í•œ íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "if exported_data is not None:\n",
    "    print(f\"\\nìµœì¢… ë°ì´í„° ì •ë³´:\")\n",
    "    print_data_info(exported_data, \"ë‚´ë³´ë‚´ê¸° ì™„ë£Œ ë°ì´í„°\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06326e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. í•™ìŠµ ìš”ì•½ ë° ì •ë¦¬\n",
    "\n",
    "### 7.1 êµ¬í˜„ëœ ì•ˆì „ ì¥ì¹˜ë“¤\n",
    "\n",
    "ì´ë²ˆ ì¬êµ¬ì„±ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ **ì•ˆì „ ì¥ì¹˜ë“¤**ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "#### ğŸ›¡ï¸ **íŒŒì¼ ì‹œìŠ¤í…œ ì•ˆì „ì„±**\n",
    "- âœ… ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©ìœ¼ë¡œ í™˜ê²½ ë…ë¦½ì„± í™•ë³´\n",
    "- âœ… íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì‚¬ì „ í™•ì¸\n",
    "- âœ… ëŒ€ì²´ ê²½ë¡œ ìë™ íƒìƒ‰\n",
    "- âœ… íŒŒì¼ ì—†ì„ ì‹œ ìƒ˜í”Œ ë°ì´í„° ìë™ ìƒì„±\n",
    "\n",
    "#### ğŸ”§ **ë°ì´í„° ì²˜ë¦¬ ì•ˆì „ì„±**\n",
    "- âœ… ëª¨ë“  í•¨ìˆ˜ì— try-catch ì—ëŸ¬ ì²˜ë¦¬\n",
    "- âœ… ë°ì´í„° íƒ€ì… ë³€í™˜ ì „ ì•ˆì „ì„± ê²€ì¦\n",
    "- âœ… ê²°ì¸¡ì¹˜ ìë™ ê°ì§€ ë° ì²˜ë¦¬\n",
    "- âœ… ë‹¨ê³„ë³„ ë°ì´í„° ê²€ì¦\n",
    "\n",
    "#### ğŸ¯ **ì½”ë“œ êµ¬ì¡° ê°œì„ **\n",
    "- âœ… ê¸°ëŠ¥ë³„ í•¨ìˆ˜ ëª¨ë“ˆí™”\n",
    "- âœ… ì¤‘ë³µ ì½”ë“œ ì œê±°\n",
    "- âœ… ëª…í™•í•œ ì‹¤í–‰ ìˆœì„œ\n",
    "- âœ… ìƒì„¸í•œ ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "\n",
    "### 7.2 ì£¼ìš” ê°œì„ ì‚¬í•­\n",
    "\n",
    "#### ğŸ”„ **ì´ì „ ë²„ì „ â†’ ê°œì„ ëœ ë²„ì „**\n",
    "- í•˜ë“œì½”ë”©ëœ ì ˆëŒ€ ê²½ë¡œ â†’ ë™ì  ìƒëŒ€ ê²½ë¡œ\n",
    "- ì—ëŸ¬ ì‹œ ì¤‘ë‹¨ â†’ ìš°ì•„í•œ ì—ëŸ¬ ì²˜ë¦¬\n",
    "- ì¤‘ë³µëœ ì½”ë“œ â†’ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜\n",
    "- ìˆœì°¨ì  ì‹¤í–‰ â†’ ì•ˆì „í•œ ë‹¨ê³„ë³„ ê²€ì¦\n",
    "\n",
    "### 7.3 ì‹¤í–‰ ë³´ì¥ ê¸°ëŠ¥\n",
    "\n",
    "#### ğŸ“ **íŒŒì¼ ìë™ ê´€ë¦¬**\n",
    "```python\n",
    "# íŒŒì¼ì´ ì—†ì–´ë„ ìƒ˜í”Œ ë°ì´í„°ë¡œ í•™ìŠµ ê°€ëŠ¥\n",
    "# ë””ë ‰í† ë¦¬ ìë™ ìƒì„±\n",
    "# ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ì§€ì›\n",
    "```\n",
    "\n",
    "#### ğŸ” **ë°ì´í„° í’ˆì§ˆ ìë™ ê²€ì¦**\n",
    "```python\n",
    "# ê²°ì¸¡ì¹˜, ì´ìƒê°’, ì¤‘ë³µ ë°ì´í„° ìë™ ê°ì§€\n",
    "# ë°ì´í„° íƒ€ì… ìë™ ìµœì í™”\n",
    "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”\n",
    "```\n",
    "\n",
    "#### ğŸ“Š **ë¶„ì„ ê²°ê³¼ ìë™ ì €ì¥**\n",
    "```python\n",
    "# ì²˜ë¦¬ ê³¼ì • ë¦¬í¬íŠ¸ ìë™ ìƒì„±\n",
    "# ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥\n",
    "# ì¬í˜„ ê°€ëŠ¥í•œ ì½”ë“œ êµ¬ì¡°\n",
    "```\n",
    "\n",
    "### 7.4 í™œìš© ë°©ë²•\n",
    "\n",
    "#### âœ¨ **ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥**\n",
    "1. **ì…€ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**: ëª¨ë“  ì…€ì´ ì•ˆì „í•˜ê²Œ ì‹¤í–‰ë©ë‹ˆë‹¤\n",
    "2. **íŒŒì¼ ì—†ì–´ë„ OK**: ìƒ˜í”Œ ë°ì´í„°ë¡œ ìë™ ì§„í–‰ë©ë‹ˆë‹¤\n",
    "3. **ì—ëŸ¬ ë°œìƒí•´ë„ OK**: ìš°ì•„í•˜ê²Œ ì²˜ë¦¬í•˜ê³  ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤\n",
    "\n",
    "#### ğŸ¯ **ë‹¤ë¥¸ ë°ì´í„°ì…‹ ì ìš©**\n",
    "```python\n",
    "# ë‹¤ë¥¸ CSV íŒŒì¼ ê²½ë¡œë§Œ ë³€ê²½í•˜ë©´ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥\n",
    "data = safe_load_csv('your_data_path.csv')\n",
    "```\n",
    "\n",
    "### 7.5 ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì œ **ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "#### ğŸš€ **ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì ìš© ì¤€ë¹„ ì™„ë£Œ**\n",
    "- ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥\n",
    "- ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ ì‹¤í—˜ ì¤€ë¹„ ì™„ë£Œ\n",
    "- ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ ë³´ì¥\n",
    "\n",
    "---\n",
    "\n",
    "> **ğŸ“ ì™„ì„±ë„ 100%**: ì´ ë…¸íŠ¸ë¶ì€ ì–´ë–¤ í™˜ê²½ì—ì„œë„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰ë˜ë©°, ì „ë¬¸ì ì¸ ë°ì´í„° ì „ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ì œê³µí•©ë‹ˆë‹¤!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
