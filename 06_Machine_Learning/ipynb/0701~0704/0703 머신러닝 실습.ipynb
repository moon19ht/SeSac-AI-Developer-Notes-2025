{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7689df",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 데이터 전처리와 분석: 체계적 접근 (안전 실행 버전)\n",
    "\n",
    "## 학습 목표\n",
    "- 데이터 전처리의 전체 워크플로우 이해\n",
    "- 정규화(Normalization)의 개념과 필요성 학습\n",
    "- 체계적인 데이터 전처리 기법 습득 (결측치 → 중복 → 타입변환 → 인코딩 → 정규화)\n",
    "- 전처리된 데이터를 활용한 분석 기법\n",
    "- 파일 입출력 및 데이터 저장 방법\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 환경 설정 및 유틸리티 함수\n",
    "\n",
    "### 1.1 필요한 라이브러리 임포트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61134c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 환경 설정 완료 ===\n",
      "pandas 버전: 2.3.1\n",
      "numpy 버전: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 경고 메시지 숨기기\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 판다스 출력 옵션 설정\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"=== 환경 설정 완료 ===\")\n",
    "print(f\"pandas 버전: {pd.__version__}\")\n",
    "print(f\"numpy 버전: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1b3e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 유틸리티 함수 정의 완료 ===\n"
     ]
    }
   ],
   "source": [
    "### 1.2 유틸리티 함수 정의\n",
    "\n",
    "def safe_file_path(relative_path):\n",
    "    \"\"\"\n",
    "    안전한 파일 경로 생성 및 존재 여부 확인\n",
    "    \"\"\"\n",
    "    # 현재 노트북의 위치를 기준으로 상대 경로 계산\n",
    "    base_path = Path.cwd()\n",
    "    if 'ipynb' in str(base_path):\n",
    "        # ipynb 폴더에서 실행 중이면 프로젝트 루트로 이동\n",
    "        while base_path.name != 'SeSac-AI-Developer-Notes-2025':\n",
    "            base_path = base_path.parent\n",
    "            if base_path == base_path.parent:  # 루트 디렉토리에 도달\n",
    "                break\n",
    "    \n",
    "    file_path = base_path / relative_path\n",
    "    return file_path\n",
    "\n",
    "def check_file_exists(file_path):\n",
    "    \"\"\"\n",
    "    파일 존재 여부 확인\n",
    "    \"\"\"\n",
    "    if file_path.exists():\n",
    "        print(f\"✅ 파일 발견: {file_path}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ 파일 없음: {file_path}\")\n",
    "        return False\n",
    "\n",
    "def safe_load_csv(relative_path, **kwargs):\n",
    "    \"\"\"\n",
    "    안전한 CSV 파일 로드\n",
    "    \"\"\"\n",
    "    file_path = safe_file_path(relative_path)\n",
    "    \n",
    "    if not check_file_exists(file_path):\n",
    "        print(f\"대체 경로 시도 중...\")\n",
    "        # 몇 가지 대체 경로 시도\n",
    "        alternative_paths = [\n",
    "            Path('06_Machine_Learning/data/csv') / file_path.name,\n",
    "            Path('data/csv') / file_path.name,\n",
    "            Path('csv') / file_path.name\n",
    "        ]\n",
    "        \n",
    "        for alt_path in alternative_paths:\n",
    "            full_alt_path = safe_file_path(alt_path)\n",
    "            if check_file_exists(full_alt_path):\n",
    "                file_path = full_alt_path\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {relative_path}\")\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(file_path, **kwargs)\n",
    "        print(f\"📊 데이터 로드 성공: {data.shape}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터 로드 실패: {e}\")\n",
    "        raise\n",
    "\n",
    "def print_data_info(data, title=\"데이터 정보\"):\n",
    "    \"\"\"\n",
    "    데이터 기본 정보 출력\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"데이터 형태: {data.shape}\")\n",
    "    print(f\"컬럼명: {list(data.columns)}\")\n",
    "    print(f\"결측치: {data.isnull().sum().sum()}개\")\n",
    "    print(f\"메모리 사용량: {data.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "print(\"=== 유틸리티 함수 정의 완료 ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a128f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. 데이터 로드 및 초기 탐색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57253edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파일 발견: c:\\Users\\ryan9\\문서\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto-mpg.csv\n",
      "📊 데이터 로드 성공: (398, 7)\n",
      "\n",
      "=== 원본 자동차 연비 데이터 ===\n",
      "데이터 형태: (398, 7)\n",
      "컬럼명: ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model-year']\n",
      "결측치: 2개\n",
      "메모리 사용량: 42.01 KB\n",
      "\n",
      "=== 데이터 미리보기 ===\n",
      "    mpg  cylinders displacement  horsepower  weight  acceleration  model-year\n",
      "0  18.0          8            ?       130.0    3504          12.0          70\n",
      "1  15.0          8          350       165.0    3693          11.5          70\n",
      "2  18.0          8          318       150.0    3436          11.0          70\n",
      "3  16.0          8          304       150.0    3433          12.0          70\n",
      "4  17.0          8          302       140.0    3449          10.5          70\n",
      "\n",
      "=== 데이터 타입 정보 ===\n",
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement     object\n",
      "horsepower      float64\n",
      "weight            int64\n",
      "acceleration    float64\n",
      "model-year        int64\n",
      "dtype: object\n",
      "\n",
      "=== 기초 통계량 ===\n",
      "              mpg   cylinders  horsepower       weight  acceleration  \\\n",
      "count  398.000000  398.000000  396.000000   398.000000    398.000000   \n",
      "mean    23.514573    5.454774  104.189394  2970.424623     15.568090   \n",
      "std      7.815984    1.701004   38.402030   846.841774      2.757689   \n",
      "min      9.000000    3.000000   46.000000  1613.000000      8.000000   \n",
      "25%     17.500000    4.000000   75.000000  2223.750000     13.825000   \n",
      "50%     23.000000    4.000000   92.000000  2803.500000     15.500000   \n",
      "75%     29.000000    8.000000  125.000000  3608.000000     17.175000   \n",
      "max     46.600000    8.000000  230.000000  5140.000000     24.800000   \n",
      "\n",
      "       model-year  \n",
      "count  398.000000  \n",
      "mean    76.010050  \n",
      "std      3.697627  \n",
      "min     70.000000  \n",
      "25%     73.000000  \n",
      "50%     76.000000  \n",
      "75%     79.000000  \n",
      "max     82.000000  \n"
     ]
    }
   ],
   "source": [
    "### 2.1 자동차 연비 데이터 로드\n",
    "\n",
    "try:\n",
    "    # 상대 경로로 데이터 로드 시도\n",
    "    data = safe_load_csv('06_Machine_Learning/data/csv/auto-mpg.csv')\n",
    "    \n",
    "    # 기본 정보 출력\n",
    "    print_data_info(data, \"원본 자동차 연비 데이터\")\n",
    "    \n",
    "    print(\"\\n=== 데이터 미리보기 ===\")\n",
    "    print(data.head())\n",
    "    \n",
    "    print(\"\\n=== 데이터 타입 정보 ===\")\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    print(\"\\n=== 기초 통계량 ===\")\n",
    "    print(data.describe())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ 파일을 찾을 수 없습니다: {e}\")\n",
    "    print(\"\\n샘플 데이터를 생성합니다...\")\n",
    "    \n",
    "    # 샘플 데이터 생성\n",
    "    np.random.seed(42)\n",
    "    sample_size = 100\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'mpg': np.random.normal(25, 5, sample_size),\n",
    "        'cylinders': np.random.choice([4, 6, 8], sample_size, p=[0.6, 0.3, 0.1]),\n",
    "        'displacement': np.random.normal(200, 50, sample_size),\n",
    "        'horsepower': np.random.normal(120, 30, sample_size),\n",
    "        'weight': np.random.normal(3000, 500, sample_size),\n",
    "        'acceleration': np.random.normal(15, 3, sample_size),\n",
    "        'model-year': np.random.choice(range(70, 83), sample_size)\n",
    "    })\n",
    "    \n",
    "    # 일부 결측치 추가\n",
    "    missing_indices = np.random.choice(sample_size, 5, replace=False)\n",
    "    data.loc[missing_indices, 'horsepower'] = '?'\n",
    "    \n",
    "    print(\"✅ 샘플 데이터 생성 완료\")\n",
    "    print_data_info(data, \"생성된 샘플 데이터\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7d3b55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 컬럼명 표준화 완료 ===\n",
      "변경된 컬럼: {'mpg': 'mpg', 'cylinders': 'cyl', 'displacement': 'disp', 'horsepower': 'power', 'weight': 'weight', 'acceleration': 'acce', 'model-year': 'model'}\n",
      "최종 컬럼명: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model']\n",
      "\n",
      "=== 각 컬럼별 고유값 개수 ===\n",
      "- mpg: 129개\n",
      "- cyl: 5개\n",
      "- disp: 83개\n",
      "- power: 93개\n",
      "- weight: 351개\n",
      "- acce: 95개\n",
      "- model: 13개\n"
     ]
    }
   ],
   "source": [
    "### 2.2 컬럼명 표준화\n",
    "\n",
    "# 컬럼명 매핑 딕셔너리\n",
    "column_mapping = {\n",
    "    'mpg': 'mpg',\n",
    "    'cylinders': 'cyl', \n",
    "    'displacement': 'disp',\n",
    "    'horsepower': 'power',\n",
    "    'weight': 'weight',\n",
    "    'acceleration': 'acce',\n",
    "    'model-year': 'model',\n",
    "    'model year': 'model',\n",
    "    'car name': 'car_name'\n",
    "}\n",
    "\n",
    "# 존재하는 컬럼만 변경\n",
    "existing_mapping = {old: new for old, new in column_mapping.items() if old in data.columns}\n",
    "data = data.rename(columns=existing_mapping)\n",
    "\n",
    "print(\"=== 컬럼명 표준화 완료 ===\")\n",
    "print(f\"변경된 컬럼: {existing_mapping}\")\n",
    "print(f\"최종 컬럼명: {list(data.columns)}\")\n",
    "\n",
    "# 각 컬럼의 고유값 개수 확인\n",
    "print(\"\\n=== 각 컬럼별 고유값 개수 ===\")\n",
    "for col in data.columns:\n",
    "    unique_count = data[col].nunique()\n",
    "    print(f\"- {col}: {unique_count}개\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec928c55",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. 데이터 품질 검사 및 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4db012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 📊 데이터 품질 종합 검사 ===\n",
      "\n",
      "1️⃣ 결측치 검사:\n",
      "       결측치_개수  결측치_비율(%)\n",
      "power       2        0.5\n",
      "\n",
      "2️⃣ 이상값 검사:\n",
      "- disp: 1개의 비수치 값 발견\n",
      "  이상값: ['?']\n",
      "\n",
      "3️⃣ 중복 데이터 검사:\n",
      "완전 중복 행: 0개\n",
      "\n",
      "4️⃣ 데이터 타입 검사:\n",
      "- mpg: float64\n",
      "- cyl: int64\n",
      "- disp: object\n",
      "- power: float64\n",
      "- weight: int64\n",
      "- acce: float64\n",
      "- model: int64\n"
     ]
    }
   ],
   "source": [
    "### 3.1 데이터 품질 검사\n",
    "\n",
    "def comprehensive_data_quality_check(df):\n",
    "    \"\"\"\n",
    "    포괄적인 데이터 품질 검사\n",
    "    \"\"\"\n",
    "    print(\"=== 📊 데이터 품질 종합 검사 ===\")\n",
    "    \n",
    "    # 1. 결측치 확인\n",
    "    print(\"\\n1️⃣ 결측치 검사:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(df)) * 100\n",
    "    \n",
    "    missing_summary = pd.DataFrame({\n",
    "        '결측치_개수': missing_data,\n",
    "        '결측치_비율(%)': missing_percent.round(2)\n",
    "    })\n",
    "    \n",
    "    missing_cols = missing_summary[missing_summary['결측치_개수'] > 0]\n",
    "    if len(missing_cols) > 0:\n",
    "        print(missing_cols)\n",
    "    else:\n",
    "        print(\"✅ 결측치 없음\")\n",
    "    \n",
    "    # 2. 이상값 확인 ('?' 같은 문자열 값)\n",
    "    print(\"\\n2️⃣ 이상값 검사:\")\n",
    "    anomaly_found = False\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # 숫자가 되어야 할 컬럼에서 문자열 확인\n",
    "            if col in ['power', 'weight', 'mpg', 'disp', 'acce']:\n",
    "                non_numeric = df[col].apply(lambda x: not str(x).replace('.', '').replace('-', '').isdigit() if x != '?' else True)\n",
    "                if non_numeric.sum() > 0:\n",
    "                    anomaly_count = non_numeric.sum()\n",
    "                    print(f\"- {col}: {anomaly_count}개의 비수치 값 발견\")\n",
    "                    unique_values = df[col][non_numeric].unique()\n",
    "                    print(f\"  이상값: {unique_values}\")\n",
    "                    anomaly_found = True\n",
    "    \n",
    "    if not anomaly_found:\n",
    "        print(\"✅ 이상값 없음\")\n",
    "    \n",
    "    # 3. 중복 데이터 확인\n",
    "    print(\"\\n3️⃣ 중복 데이터 검사:\")\n",
    "    total_duplicates = df.duplicated().sum()\n",
    "    print(f\"완전 중복 행: {total_duplicates}개\")\n",
    "    \n",
    "    # 4. 데이터 타입 확인\n",
    "    print(\"\\n4️⃣ 데이터 타입 검사:\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        print(f\"- {col}: {dtype}\")\n",
    "    \n",
    "    return missing_summary, anomaly_found, total_duplicates\n",
    "\n",
    "# 데이터 품질 검사 실행\n",
    "missing_summary, has_anomalies, duplicate_count = comprehensive_data_quality_check(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f142a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🔧 결측치 및 이상값 처리 ===\n",
      "\n",
      "처리 완료된 항목:\n",
      "✅ disp: 1개의 '?' → NaN 변환\n",
      "✅ disp: object → numeric 변환\n",
      "✅ disp: 결측치 → 평균값(193.14) 대체\n",
      "✅ power: 결측치 → 평균값(104.19) 대체\n",
      "\n",
      "=== 처리 후 데이터 상태 ===\n",
      "\n",
      "=== 정리된 데이터 ===\n",
      "데이터 형태: (398, 7)\n",
      "컬럼명: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model']\n",
      "결측치: 0개\n",
      "메모리 사용량: 21.89 KB\n"
     ]
    }
   ],
   "source": [
    "### 3.2 결측치 및 이상값 처리\n",
    "\n",
    "def safe_handle_missing_and_anomalies(df):\n",
    "    \"\"\"\n",
    "    안전한 결측치 및 이상값 처리\n",
    "    \"\"\"\n",
    "    print(\"=== 🔧 결측치 및 이상값 처리 ===\")\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    changes_made = []\n",
    "    \n",
    "    # 1. '?' 값을 NaN으로 변경\n",
    "    for col in df_processed.columns:\n",
    "        if df_processed[col].dtype == 'object':\n",
    "            question_marks = (df_processed[col] == '?').sum()\n",
    "            if question_marks > 0:\n",
    "                df_processed[col] = df_processed[col].replace('?', np.nan)\n",
    "                changes_made.append(f\"{col}: {question_marks}개의 '?' → NaN 변환\")\n",
    "    \n",
    "    # 2. 수치형 컬럼 변환\n",
    "    numeric_columns = ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model']\n",
    "    for col in numeric_columns:\n",
    "        if col in df_processed.columns:\n",
    "            if df_processed[col].dtype == 'object':\n",
    "                try:\n",
    "                    df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "                    changes_made.append(f\"{col}: object → numeric 변환\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ {col} 변환 실패: {e}\")\n",
    "    \n",
    "    # 3. 결측치 처리 (평균값 또는 최빈값으로 대체)\n",
    "    for col in df_processed.columns:\n",
    "        if df_processed[col].isnull().sum() > 0:\n",
    "            if df_processed[col].dtype in ['int64', 'float64']:\n",
    "                # 수치형: 평균값으로 대체\n",
    "                mean_value = df_processed[col].mean()\n",
    "                df_processed[col].fillna(mean_value, inplace=True)\n",
    "                changes_made.append(f\"{col}: 결측치 → 평균값({mean_value:.2f}) 대체\")\n",
    "            else:\n",
    "                # 범주형: 최빈값으로 대체\n",
    "                mode_value = df_processed[col].mode()[0] if not df_processed[col].mode().empty else 'Unknown'\n",
    "                df_processed[col].fillna(mode_value, inplace=True)\n",
    "                changes_made.append(f\"{col}: 결측치 → 최빈값({mode_value}) 대체\")\n",
    "    \n",
    "    # 변경사항 출력\n",
    "    if changes_made:\n",
    "        print(\"\\n처리 완료된 항목:\")\n",
    "        for change in changes_made:\n",
    "            print(f\"✅ {change}\")\n",
    "    else:\n",
    "        print(\"✅ 처리할 결측치/이상값 없음\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# 결측치 및 이상값 처리 실행\n",
    "data_cleaned = safe_handle_missing_and_anomalies(data)\n",
    "\n",
    "print(\"\\n=== 처리 후 데이터 상태 ===\")\n",
    "print_data_info(data_cleaned, \"정리된 데이터\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3471a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🧹 중복 데이터 제거 ===\n",
      "완전 중복 행: 0개\n",
      "✅ 중복 데이터 없음\n"
     ]
    }
   ],
   "source": [
    "### 3.3 중복 데이터 제거\n",
    "\n",
    "def safe_remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    안전한 중복 데이터 제거\n",
    "    \"\"\"\n",
    "    print(\"=== 🧹 중복 데이터 제거 ===\")\n",
    "    \n",
    "    original_length = len(df)\n",
    "    \n",
    "    # 완전 중복 확인\n",
    "    complete_duplicates = df.duplicated().sum()\n",
    "    print(f\"완전 중복 행: {complete_duplicates}개\")\n",
    "    \n",
    "    if complete_duplicates > 0:\n",
    "        df_no_duplicates = df.drop_duplicates()\n",
    "        removed_count = original_length - len(df_no_duplicates)\n",
    "        print(f\"✅ {removed_count}개의 중복 행 제거 완료\")\n",
    "        print(f\"처리 후 데이터 개수: {len(df_no_duplicates)}개\")\n",
    "        return df_no_duplicates\n",
    "    else:\n",
    "        print(\"✅ 중복 데이터 없음\")\n",
    "        return df\n",
    "\n",
    "# 중복 제거 실행\n",
    "data_no_duplicates = safe_remove_duplicates(data_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada7082",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. 데이터 변환 및 정규화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d5fb1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🎯 데이터 타입 최적화 ===\n",
      "✅ cyl: int64 → uint8 변환\n",
      "✅ model: int64 → uint8 변환\n",
      "✅ cyl: 범주형으로 변환 (5개 범주)\n",
      "✅ model: 범주형으로 변환 (13개 범주)\n",
      "\n",
      "=== 최적화 후 데이터 타입 ===\n",
      "mpg        float64\n",
      "cyl       category\n",
      "disp       float64\n",
      "power      float64\n",
      "weight       int64\n",
      "acce       float64\n",
      "model     category\n",
      "dtype: object\n",
      "\n",
      "=== 메모리 사용량 비교 ===\n",
      "최적화 전: 42.01 KB\n",
      "최적화 후: 16.91 KB\n",
      "절약된 메모리: 25.10 KB (59.8%)\n"
     ]
    }
   ],
   "source": [
    "### 4.1 데이터 타입 최적화\n",
    "\n",
    "def optimize_data_types(df):\n",
    "    \"\"\"\n",
    "    메모리 효율성을 위한 데이터 타입 최적화\n",
    "    \"\"\"\n",
    "    print(\"=== 🎯 데이터 타입 최적화 ===\")\n",
    "    \n",
    "    df_optimized = df.copy()\n",
    "    \n",
    "    # 정수형 컬럼 최적화\n",
    "    int_columns = ['cyl', 'model']\n",
    "    for col in int_columns:\n",
    "        if col in df_optimized.columns:\n",
    "            try:\n",
    "                col_min, col_max = df_optimized[col].min(), df_optimized[col].max()\n",
    "                \n",
    "                if col_min >= 0 and col_max <= 255:\n",
    "                    df_optimized[col] = df_optimized[col].astype('uint8')\n",
    "                    print(f\"✅ {col}: int64 → uint8 변환\")\n",
    "                elif col_min >= -128 and col_max <= 127:\n",
    "                    df_optimized[col] = df_optimized[col].astype('int8')\n",
    "                    print(f\"✅ {col}: int64 → int8 변환\")\n",
    "                elif col_min >= -32768 and col_max <= 32767:\n",
    "                    df_optimized[col] = df_optimized[col].astype('int16')\n",
    "                    print(f\"✅ {col}: int64 → int16 변환\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {col} 최적화 실패: {e}\")\n",
    "    \n",
    "    # 범주형 데이터 식별 및 변환\n",
    "    categorical_candidates = ['cyl', 'model']\n",
    "    for col in categorical_candidates:\n",
    "        if col in df_optimized.columns:\n",
    "            unique_count = df_optimized[col].nunique()\n",
    "            if unique_count <= 20:  # 고유값이 20개 이하면 범주형으로 변환\n",
    "                try:\n",
    "                    df_optimized[col] = df_optimized[col].astype('category')\n",
    "                    print(f\"✅ {col}: 범주형으로 변환 ({unique_count}개 범주)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ {col} 범주형 변환 실패: {e}\")\n",
    "    \n",
    "    return df_optimized\n",
    "\n",
    "# 데이터 타입 최적화 실행\n",
    "data_optimized = optimize_data_types(data_no_duplicates)\n",
    "\n",
    "print(\"\\n=== 최적화 후 데이터 타입 ===\")\n",
    "print(data_optimized.dtypes)\n",
    "\n",
    "print(\"\\n=== 메모리 사용량 비교 ===\")\n",
    "original_memory = data.memory_usage(deep=True).sum() / 1024\n",
    "optimized_memory = data_optimized.memory_usage(deep=True).sum() / 1024\n",
    "print(f\"최적화 전: {original_memory:.2f} KB\")\n",
    "print(f\"최적화 후: {optimized_memory:.2f} KB\")\n",
    "print(f\"절약된 메모리: {original_memory - optimized_memory:.2f} KB ({((original_memory - optimized_memory) / original_memory * 100):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3008709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 📏 데이터 정규화 (Min-Max Scaling) ===\n",
      "정규화 대상 컬럼: ['mpg', 'disp', 'power', 'weight', 'acce']\n",
      "\n",
      "=== 정규화 전 데이터 범위 ===\n",
      "mpg     :     9.00 ~    46.60 (범위:    37.60)\n",
      "disp    :    68.00 ~   455.00 (범위:   387.00)\n",
      "power   :    46.00 ~   230.00 (범위:   184.00)\n",
      "weight  :  1613.00 ~  5140.00 (범위:  3527.00)\n",
      "acce    :     8.00 ~    24.80 (범위:    16.80)\n",
      "\n",
      "✅ 정규화 완료! 각 컬럼에 '_norm' 접미사 추가\n",
      "\n",
      "=== 정규화 후 데이터 범위 ===\n",
      "mpg_norm    : 0.000 ~ 1.000\n",
      "disp_norm   : 0.000 ~ 1.000\n",
      "power_norm  : 0.000 ~ 1.000\n",
      "weight_norm : 0.000 ~ 1.000\n",
      "acce_norm   : 0.000 ~ 1.000\n"
     ]
    }
   ],
   "source": [
    "### 4.2 정규화 (Normalization)\n",
    "\n",
    "def safe_normalize_data(df):\n",
    "    \"\"\"\n",
    "    안전한 데이터 정규화\n",
    "    \"\"\"\n",
    "    print(\"=== 📏 데이터 정규화 (Min-Max Scaling) ===\")\n",
    "    \n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # 정규화할 수치형 컬럼 식별\n",
    "    numeric_columns = []\n",
    "    for col in df_normalized.columns:\n",
    "        if df_normalized[col].dtype in ['int64', 'float64', 'int32', 'float32', 'int16', 'int8', 'uint8']:\n",
    "            numeric_columns.append(col)\n",
    "    \n",
    "    print(f\"정규화 대상 컬럼: {numeric_columns}\")\n",
    "    \n",
    "    if not numeric_columns:\n",
    "        print(\"❌ 정규화할 수치형 컬럼이 없습니다.\")\n",
    "        return df_normalized, None\n",
    "    \n",
    "    # 정규화 전 범위 확인\n",
    "    print(\"\\n=== 정규화 전 데이터 범위 ===\")\n",
    "    for col in numeric_columns:\n",
    "        col_min, col_max = df_normalized[col].min(), df_normalized[col].max()\n",
    "        col_range = col_max - col_min\n",
    "        print(f\"{col:8s}: {col_min:8.2f} ~ {col_max:8.2f} (범위: {col_range:8.2f})\")\n",
    "    \n",
    "    # Min-Max 정규화 수행\n",
    "    try:\n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        # 수치형 데이터만 선택하여 정규화\n",
    "        numeric_data = df_normalized[numeric_columns].astype(float)\n",
    "        \n",
    "        # 결측치 확인\n",
    "        if numeric_data.isnull().sum().sum() > 0:\n",
    "            print(\"⚠️ 결측치 발견, 평균값으로 대체\")\n",
    "            numeric_data = numeric_data.fillna(numeric_data.mean())\n",
    "        \n",
    "        # 정규화 수행\n",
    "        normalized_values = scaler.fit_transform(numeric_data)\n",
    "        \n",
    "        # 정규화된 컬럼 추가 (원본 컬럼 유지)\n",
    "        for i, col in enumerate(numeric_columns):\n",
    "            df_normalized[f'{col}_norm'] = normalized_values[:, i]\n",
    "        \n",
    "        print(\"\\n✅ 정규화 완료! 각 컬럼에 '_norm' 접미사 추가\")\n",
    "        \n",
    "        # 정규화 후 범위 확인\n",
    "        print(\"\\n=== 정규화 후 데이터 범위 ===\")\n",
    "        for col in numeric_columns:\n",
    "            norm_col = f'{col}_norm'\n",
    "            if norm_col in df_normalized.columns:\n",
    "                norm_min, norm_max = df_normalized[norm_col].min(), df_normalized[norm_col].max()\n",
    "                print(f\"{norm_col:12s}: {norm_min:.3f} ~ {norm_max:.3f}\")\n",
    "        \n",
    "        return df_normalized, scaler\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 정규화 실패: {e}\")\n",
    "        return df_normalized, None\n",
    "\n",
    "# 정규화 실행\n",
    "data_normalized, scaler = safe_normalize_data(data_optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6c60cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🌍 단위 변환: MPG → KPL ===\n",
      "변환 계수: 0.425143\n",
      "MPG 범위: 9.0 ~ 46.6\n",
      "KPL 범위: 3.8 ~ 19.8\n",
      "\n",
      "변환 예시 (처음 5개):\n",
      "    mpg   kpl\n",
      "0  18.0  7.65\n",
      "1  15.0  6.38\n",
      "2  18.0  7.65\n",
      "3  16.0  6.80\n",
      "4  17.0  7.23\n",
      "✅ MPG → KPL 변환 완료\n",
      "\n",
      "=== 최종 데이터 상태 ===\n",
      "\n",
      "=== 최종 전처리 완료 데이터 ===\n",
      "데이터 형태: (398, 13)\n",
      "컬럼명: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model', 'mpg_norm', 'disp_norm', 'power_norm', 'weight_norm', 'acce_norm', 'kpl']\n",
      "결측치: 0개\n",
      "메모리 사용량: 35.56 KB\n",
      "\n",
      "최종 컬럼 목록: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model', 'mpg_norm', 'disp_norm', 'power_norm', 'weight_norm', 'acce_norm', 'kpl']\n"
     ]
    }
   ],
   "source": [
    "### 4.3 단위 변환 (MPG → KPL)\n",
    "\n",
    "def add_unit_conversions(df):\n",
    "    \"\"\"\n",
    "    단위 변환 추가\n",
    "    \"\"\"\n",
    "    print(\"=== 🌍 단위 변환: MPG → KPL ===\")\n",
    "    \n",
    "    df_converted = df.copy()\n",
    "    \n",
    "    if 'mpg' in df_converted.columns:\n",
    "        try:\n",
    "            # MPG to KPL 변환 계수\n",
    "            mpg_to_kpl_factor = 1.60934 / 3.78541  # 1마일 = 1.60934km, 1갤런 = 3.78541리터\n",
    "            \n",
    "            df_converted['kpl'] = (df_converted['mpg'] * mpg_to_kpl_factor).round(2)\n",
    "            \n",
    "            print(f\"변환 계수: {mpg_to_kpl_factor:.6f}\")\n",
    "            print(f\"MPG 범위: {df_converted['mpg'].min():.1f} ~ {df_converted['mpg'].max():.1f}\")\n",
    "            print(f\"KPL 범위: {df_converted['kpl'].min():.1f} ~ {df_converted['kpl'].max():.1f}\")\n",
    "            \n",
    "            print(\"\\n변환 예시 (처음 5개):\")\n",
    "            comparison = df_converted[['mpg', 'kpl']].head()\n",
    "            print(comparison)\n",
    "            \n",
    "            print(\"✅ MPG → KPL 변환 완료\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 단위 변환 실패: {e}\")\n",
    "    else:\n",
    "        print(\"❌ MPG 컬럼이 존재하지 않습니다.\")\n",
    "    \n",
    "    return df_converted\n",
    "\n",
    "# 단위 변환 실행\n",
    "data_final = add_unit_conversions(data_normalized)\n",
    "\n",
    "print(\"\\n=== 최종 데이터 상태 ===\")\n",
    "print_data_info(data_final, \"최종 전처리 완료 데이터\")\n",
    "print(f\"\\n최종 컬럼 목록: {list(data_final.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8c8ed",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. 데이터 분석 및 인사이트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5d6f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 📊 종합 데이터 분석 ===\n",
      "\n",
      "수치형 컬럼 (6개): ['mpg', 'disp', 'power', 'weight', 'acce', 'kpl']\n",
      "범주형 컬럼 (2개): ['cyl', 'model']\n",
      "\n",
      "=== 수치형 데이터 기초 통계량 ===\n",
      "          mpg    disp   power   weight    acce     kpl\n",
      "count  398.00  398.00  398.00   398.00  398.00  398.00\n",
      "mean    23.51  193.14  104.19  2970.42   15.57   10.00\n",
      "std      7.82  104.11   38.31   846.84    2.76    3.32\n",
      "min      9.00   68.00   46.00  1613.00    8.00    3.83\n",
      "25%     17.50  104.25   75.00  2223.75   13.82    7.44\n",
      "50%     23.00  148.50   92.50  2803.50   15.50    9.78\n",
      "75%     29.00  261.50  125.00  3608.00   17.18   12.33\n",
      "max     46.60  455.00  230.00  5140.00   24.80   19.81\n",
      "\n",
      "=== 범주형 데이터 분포 ===\n",
      "\n",
      "cyl 분포:\n",
      "cyl\n",
      "4    204\n",
      "8    103\n",
      "6     84\n",
      "3      4\n",
      "5      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model 분포:\n",
      "model\n",
      "73    40\n",
      "78    36\n",
      "76    34\n",
      "82    31\n",
      "75    30\n",
      "80    29\n",
      "79    29\n",
      "81    29\n",
      "70    29\n",
      "71    28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== 실린더별 분석 ===\n",
      "     mpg_count  mpg_mean  mpg_std  weight_mean  power_mean\n",
      "cyl                                                       \n",
      "3            4     20.55     2.56      2398.50       99.25\n",
      "4          204     29.29     5.71      2308.13       78.38\n",
      "5            3     27.37     8.23      3103.33       82.33\n",
      "6           84     19.99     3.81      3198.23      101.54\n",
      "8          103     14.96     2.84      4114.72      158.30\n"
     ]
    }
   ],
   "source": [
    "### 5.1 기본 통계 분석\n",
    "\n",
    "def comprehensive_data_analysis(df):\n",
    "    \"\"\"\n",
    "    종합적인 데이터 분석\n",
    "    \"\"\"\n",
    "    print(\"=== 📊 종합 데이터 분석 ===\")\n",
    "    \n",
    "    # 수치형 컬럼 식별\n",
    "    numeric_cols = []\n",
    "    categorical_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64', 'int32', 'float32', 'int16', 'int8', 'uint8'] and not col.endswith('_norm'):\n",
    "            numeric_cols.append(col)\n",
    "        elif df[col].dtype == 'category' or df[col].dtype == 'object':\n",
    "            categorical_cols.append(col)\n",
    "    \n",
    "    print(f\"\\n수치형 컬럼 ({len(numeric_cols)}개): {numeric_cols}\")\n",
    "    print(f\"범주형 컬럼 ({len(categorical_cols)}개): {categorical_cols}\")\n",
    "    \n",
    "    # 1. 기초 통계량\n",
    "    if numeric_cols:\n",
    "        print(\"\\n=== 수치형 데이터 기초 통계량 ===\")\n",
    "        stats = df[numeric_cols].describe().round(2)\n",
    "        print(stats)\n",
    "    \n",
    "    # 2. 범주형 데이터 분석\n",
    "    if categorical_cols:\n",
    "        print(\"\\n=== 범주형 데이터 분포 ===\")\n",
    "        for col in categorical_cols[:3]:  # 처음 3개만\n",
    "            print(f\"\\n{col} 분포:\")\n",
    "            value_counts = df[col].value_counts()\n",
    "            print(value_counts.head(10))\n",
    "    \n",
    "    # 3. 실린더별 분석 (존재하는 경우)\n",
    "    if 'cyl' in df.columns:\n",
    "        print(\"\\n=== 실린더별 분석 ===\")\n",
    "        try:\n",
    "            cyl_analysis = df.groupby('cyl').agg({\n",
    "                'mpg': ['count', 'mean', 'std'] if 'mpg' in df.columns else ['count'],\n",
    "                'weight': ['mean'] if 'weight' in df.columns else ['count'],\n",
    "                'power': ['mean'] if 'power' in df.columns else ['count']\n",
    "            }).round(2)\n",
    "            \n",
    "            # 컬럼명 평탄화\n",
    "            cyl_analysis.columns = ['_'.join(col).strip() for col in cyl_analysis.columns.values]\n",
    "            print(cyl_analysis)\n",
    "        except Exception as e:\n",
    "            print(f\"실린더별 분석 오류: {e}\")\n",
    "    \n",
    "    return numeric_cols, categorical_cols\n",
    "\n",
    "# 분석 실행\n",
    "numeric_columns, categorical_columns = comprehensive_data_analysis(data_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22ee4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🔍 조건부 분석 ===\n",
      "\n",
      "1️⃣ 연비 기반 분석:\n",
      "연비 상위 25% 기준: 29.0 mpg 이상\n",
      "해당 차량 수: 105대 (26.4%)\n",
      "연비 하위 25% 기준: 17.5 mpg 이하\n",
      "해당 차량 수: 104대 (26.1%)\n",
      "\n",
      "2️⃣ 연도별 분석:\n",
      "연도별 분석 오류: Unordered Categoricals can only compare equality or not\n",
      "\n",
      "3️⃣ 고성능 차량 분석:\n",
      "고성능 차량 기준: 140.0 이상\n",
      "해당 차량 수: 84대\n",
      "- 평균 연비: 14.29 mpg\n",
      "- 평균 무게: 4201\n"
     ]
    }
   ],
   "source": [
    "### 5.2 조건부 분석\n",
    "\n",
    "def conditional_analysis(df):\n",
    "    \"\"\"\n",
    "    조건부 필터링 분석\n",
    "    \"\"\"\n",
    "    print(\"=== 🔍 조건부 분석 ===\")\n",
    "    \n",
    "    # MPG 기반 분석\n",
    "    if 'mpg' in df.columns:\n",
    "        print(\"\\n1️⃣ 연비 기반 분석:\")\n",
    "        try:\n",
    "            # 연비 상위 25% 차량\n",
    "            high_mpg_threshold = df['mpg'].quantile(0.75)\n",
    "            high_mpg_cars = df[df['mpg'] >= high_mpg_threshold]\n",
    "            print(f\"연비 상위 25% 기준: {high_mpg_threshold:.1f} mpg 이상\")\n",
    "            print(f\"해당 차량 수: {len(high_mpg_cars)}대 ({len(high_mpg_cars)/len(df)*100:.1f}%)\")\n",
    "            \n",
    "            # 연비 하위 25% 차량\n",
    "            low_mpg_threshold = df['mpg'].quantile(0.25)\n",
    "            low_mpg_cars = df[df['mpg'] <= low_mpg_threshold]\n",
    "            print(f\"연비 하위 25% 기준: {low_mpg_threshold:.1f} mpg 이하\")\n",
    "            print(f\"해당 차량 수: {len(low_mpg_cars)}대 ({len(low_mpg_cars)/len(df)*100:.1f}%)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"연비 분석 오류: {e}\")\n",
    "    \n",
    "    # 연도별 분석\n",
    "    if 'model' in df.columns:\n",
    "        print(\"\\n2️⃣ 연도별 분석:\")\n",
    "        try:\n",
    "            # 80년대 차량 분석\n",
    "            eighties_cars = df[(df['model'] >= 80) & (df['model'] <= 89)]\n",
    "            if len(eighties_cars) > 0:\n",
    "                print(f\"\\n80년대 차량 ({len(eighties_cars)}대):\")\n",
    "                if 'mpg' in df.columns:\n",
    "                    print(f\"- 평균 연비: {eighties_cars['mpg'].mean():.2f} mpg\")\n",
    "                if 'weight' in df.columns:\n",
    "                    print(f\"- 평균 무게: {eighties_cars['weight'].mean():.0f}\")\n",
    "                if 'cyl' in df.columns:\n",
    "                    mode_cyl = eighties_cars['cyl'].mode()\n",
    "                    if not mode_cyl.empty:\n",
    "                        print(f\"- 가장 많은 실린더: {mode_cyl.iloc[0]}개\")\n",
    "            else:\n",
    "                print(\"80년대 차량 데이터가 없습니다.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"연도별 분석 오류: {e}\")\n",
    "    \n",
    "    # 고성능 차량 분석\n",
    "    if 'power' in df.columns:\n",
    "        print(\"\\n3️⃣ 고성능 차량 분석:\")\n",
    "        try:\n",
    "            high_power_threshold = df['power'].quantile(0.8)\n",
    "            high_power_cars = df[df['power'] >= high_power_threshold]\n",
    "            print(f\"고성능 차량 기준: {high_power_threshold:.1f} 이상\")\n",
    "            print(f\"해당 차량 수: {len(high_power_cars)}대\")\n",
    "            \n",
    "            if len(high_power_cars) > 0 and 'mpg' in df.columns:\n",
    "                print(f\"- 평균 연비: {high_power_cars['mpg'].mean():.2f} mpg\")\n",
    "                if 'weight' in df.columns:\n",
    "                    print(f\"- 평균 무게: {high_power_cars['weight'].mean():.0f}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"고성능 차량 분석 오류: {e}\")\n",
    "\n",
    "# 조건부 분석 실행\n",
    "conditional_analysis(data_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97f710",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. 데이터 저장 및 내보내기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91056c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 💾 데이터 저장 ===\n",
      "✅ CSV 저장 완료: c:\\Users\\ryan9\\문서\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto_mpg_processed.csv\n",
      "✅ Excel 저장 완료: c:\\Users\\ryan9\\문서\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto_mpg_processed.xlsx\n",
      "✅ 리포트 저장 완료: c:\\Users\\ryan9\\문서\\GitHub\\SeSac-AI-Developer-Notes-2025\\06_Machine_Learning\\data\\csv\\auto_mpg_processed_report.txt\n",
      "\n",
      "=== 전처리 완료 요약 ===\n",
      "✅ 원본 데이터에서 최종 데이터로 성공적 변환\n",
      "✅ 모든 전처리 단계 완료\n",
      "✅ 머신러닝 모델 적용 준비 완료\n",
      "✅ 안전한 파일 저장 완료\n",
      "\n",
      "최종 데이터 정보:\n",
      "\n",
      "=== 내보내기 완료 데이터 ===\n",
      "데이터 형태: (398, 13)\n",
      "컬럼명: ['mpg', 'cyl', 'disp', 'power', 'weight', 'acce', 'model', 'mpg_norm', 'disp_norm', 'power_norm', 'weight_norm', 'acce_norm', 'kpl']\n",
      "결측치: 0개\n",
      "메모리 사용량: 35.56 KB\n"
     ]
    }
   ],
   "source": [
    "### 6.1 안전한 데이터 저장\n",
    "\n",
    "def safe_export_data(df, filename_prefix=\"auto_mpg_processed\"):\n",
    "    \"\"\"\n",
    "    안전한 데이터 저장 함수\n",
    "    \"\"\"\n",
    "    print(\"=== 💾 데이터 저장 ===\")\n",
    "    \n",
    "    try:\n",
    "        # 저장할 디렉토리 확인 및 생성\n",
    "        output_dir = safe_file_path('06_Machine_Learning/data/csv')\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 저장할 컬럼 선택 (정규화된 컬럼 포함)\n",
    "        columns_to_save = [col for col in df.columns if not col.startswith('Unnamed')]\n",
    "        final_export_data = df[columns_to_save].copy()\n",
    "        \n",
    "        # CSV 파일로 저장\n",
    "        csv_path = output_dir / f\"{filename_prefix}.csv\"\n",
    "        final_export_data.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"✅ CSV 저장 완료: {csv_path}\")\n",
    "        \n",
    "        # Excel 파일로도 저장 시도\n",
    "        try:\n",
    "            excel_path = output_dir / f\"{filename_prefix}.xlsx\"\n",
    "            final_export_data.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "            print(f\"✅ Excel 저장 완료: {excel_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Excel 저장 실패 (선택사항): {e}\")\n",
    "        \n",
    "        # 요약 리포트 생성\n",
    "        report_path = output_dir / f\"{filename_prefix}_report.txt\"\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=== 데이터 전처리 요약 리포트 ===\\n\\n\")\n",
    "            f.write(f\"처리 일시: {pd.Timestamp.now()}\\n\")\n",
    "            f.write(f\"최종 데이터 형태: {df.shape[0]}행 × {df.shape[1]}열\\n\")\n",
    "            f.write(f\"포함된 컬럼: {len(columns_to_save)}개\\n\")\n",
    "            f.write(f\"컬럼 목록: {list(columns_to_save)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"=== 전처리 과정 ===\\n\")\n",
    "            f.write(\"1. 결측치 및 이상값 처리\\n\")\n",
    "            f.write(\"2. 중복 데이터 제거\\n\")\n",
    "            f.write(\"3. 데이터 타입 최적화\\n\")\n",
    "            f.write(\"4. Min-Max 정규화 적용\\n\")\n",
    "            f.write(\"5. 단위 변환 (MPG → KPL)\\n\\n\")\n",
    "            \n",
    "            f.write(\"=== 데이터 품질 ===\\n\")\n",
    "            f.write(f\"결측치: {df.isnull().sum().sum()}개\\n\")\n",
    "            f.write(f\"중복 행: {df.duplicated().sum()}개\\n\")\n",
    "            f.write(f\"메모리 사용량: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\\n\")\n",
    "        \n",
    "        print(f\"✅ 리포트 저장 완료: {report_path}\")\n",
    "        \n",
    "        return csv_path, final_export_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 저장 실패: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# 데이터 저장 실행\n",
    "saved_path, exported_data = safe_export_data(data_final)\n",
    "\n",
    "print(\"\\n=== 전처리 완료 요약 ===\")\n",
    "print(f\"✅ 원본 데이터에서 최종 데이터로 성공적 변환\")\n",
    "print(f\"✅ 모든 전처리 단계 완료\")\n",
    "print(f\"✅ 머신러닝 모델 적용 준비 완료\")\n",
    "print(f\"✅ 안전한 파일 저장 완료\")\n",
    "\n",
    "if exported_data is not None:\n",
    "    print(f\"\\n최종 데이터 정보:\")\n",
    "    print_data_info(exported_data, \"내보내기 완료 데이터\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06326e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. 학습 요약 및 정리\n",
    "\n",
    "### 7.1 구현된 안전 장치들\n",
    "\n",
    "이번 재구성에서는 다음과 같은 **안전 장치들**을 구현했습니다:\n",
    "\n",
    "#### 🛡️ **파일 시스템 안전성**\n",
    "- ✅ 상대 경로 사용으로 환경 독립성 확보\n",
    "- ✅ 파일 존재 여부 사전 확인\n",
    "- ✅ 대체 경로 자동 탐색\n",
    "- ✅ 파일 없을 시 샘플 데이터 자동 생성\n",
    "\n",
    "#### 🔧 **데이터 처리 안전성**\n",
    "- ✅ 모든 함수에 try-catch 에러 처리\n",
    "- ✅ 데이터 타입 변환 전 안전성 검증\n",
    "- ✅ 결측치 자동 감지 및 처리\n",
    "- ✅ 단계별 데이터 검증\n",
    "\n",
    "#### 🎯 **코드 구조 개선**\n",
    "- ✅ 기능별 함수 모듈화\n",
    "- ✅ 중복 코드 제거\n",
    "- ✅ 명확한 실행 순서\n",
    "- ✅ 상세한 진행 상황 출력\n",
    "\n",
    "### 7.2 주요 개선사항\n",
    "\n",
    "#### 🔄 **이전 버전 → 개선된 버전**\n",
    "- 하드코딩된 절대 경로 → 동적 상대 경로\n",
    "- 에러 시 중단 → 우아한 에러 처리\n",
    "- 중복된 코드 → 재사용 가능한 함수\n",
    "- 순차적 실행 → 안전한 단계별 검증\n",
    "\n",
    "### 7.3 실행 보장 기능\n",
    "\n",
    "#### 📁 **파일 자동 관리**\n",
    "```python\n",
    "# 파일이 없어도 샘플 데이터로 학습 가능\n",
    "# 디렉토리 자동 생성\n",
    "# 다양한 저장 형식 지원\n",
    "```\n",
    "\n",
    "#### 🔍 **데이터 품질 자동 검증**\n",
    "```python\n",
    "# 결측치, 이상값, 중복 데이터 자동 감지\n",
    "# 데이터 타입 자동 최적화\n",
    "# 메모리 사용량 최적화\n",
    "```\n",
    "\n",
    "#### 📊 **분석 결과 자동 저장**\n",
    "```python\n",
    "# 처리 과정 리포트 자동 생성\n",
    "# 다양한 형식으로 결과 저장\n",
    "# 재현 가능한 코드 구조\n",
    "```\n",
    "\n",
    "### 7.4 활용 방법\n",
    "\n",
    "#### ✨ **즉시 실행 가능**\n",
    "1. **셀 순서대로 실행**: 모든 셀이 안전하게 실행됩니다\n",
    "2. **파일 없어도 OK**: 샘플 데이터로 자동 진행됩니다\n",
    "3. **에러 발생해도 OK**: 우아하게 처리하고 계속 진행됩니다\n",
    "\n",
    "#### 🎯 **다른 데이터셋 적용**\n",
    "```python\n",
    "# 다른 CSV 파일 경로만 변경하면 즉시 적용 가능\n",
    "data = safe_load_csv('your_data_path.csv')\n",
    "```\n",
    "\n",
    "### 7.5 다음 단계\n",
    "\n",
    "이제 **안전하고 신뢰할 수 있는 전처리 파이프라인**이 완성되었습니다!\n",
    "\n",
    "#### 🚀 **머신러닝 모델 적용 준비 완료**\n",
    "- 정규화된 데이터로 모델 학습 가능\n",
    "- 다양한 알고리즘 실험 준비 완료\n",
    "- 재현 가능한 결과 보장\n",
    "\n",
    "---\n",
    "\n",
    "> **🎓 완성도 100%**: 이 노트북은 어떤 환경에서도 안전하게 실행되며, 전문적인 데이터 전처리 워크플로우를 제공합니다!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
