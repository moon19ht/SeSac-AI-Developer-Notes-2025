{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 당뇨병 데이터를 이용한 회귀분석 모델 비교\n",
        "\n",
        "당뇨병과 관련된 요소들이 있고, 1년 후 값들을 예측하는 문제입니다.\n",
        "- 알고리즘: KNN 이웃, 의사결정트리, 랜덤포레스트 등은 분류뿐만 아니라 회귀도 지원\n",
        "- Ridge, Lasso 정규화 회귀도 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 import\n",
        "from sklearn.datasets import load_diabetes  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# xgboost는 별도 설치 필요: conda install xgboost\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"XGBoost가 설치되지 않았습니다. 'conda install xgboost'로 설치하세요.\")\n",
        "    XGBOOST_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 키들: dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n",
            "타겟 데이터 처음 10개: [151.  75. 141. 206. 135.  97. 138.  63. 110. 310.]\n",
            "특성 데이터 처음 10개: [[ 0.03807591  0.05068012  0.06169621  0.02187239 -0.0442235  -0.03482076\n",
            "  -0.04340085 -0.00259226  0.01990749 -0.01764613]\n",
            " [-0.00188202 -0.04464164 -0.05147406 -0.02632753 -0.00844872 -0.01916334\n",
            "   0.07441156 -0.03949338 -0.06833155 -0.09220405]\n",
            " [ 0.08529891  0.05068012  0.04445121 -0.00567042 -0.04559945 -0.03419447\n",
            "  -0.03235593 -0.00259226  0.00286131 -0.02593034]\n",
            " [-0.08906294 -0.04464164 -0.01159501 -0.03665608  0.01219057  0.02499059\n",
            "  -0.03603757  0.03430886  0.02268774 -0.00936191]\n",
            " [ 0.00538306 -0.04464164 -0.03638469  0.02187239  0.00393485  0.01559614\n",
            "   0.00814208 -0.00259226 -0.03198764 -0.04664087]\n",
            " [-0.09269548 -0.04464164 -0.04069594 -0.01944183 -0.06899065 -0.07928784\n",
            "   0.04127682 -0.0763945  -0.04117617 -0.09634616]\n",
            " [-0.04547248  0.05068012 -0.04716281 -0.01599898 -0.04009564 -0.02480001\n",
            "   0.00077881 -0.03949338 -0.06291688 -0.03835666]\n",
            " [ 0.06350368  0.05068012 -0.00189471  0.06662945  0.09061988  0.10891438\n",
            "   0.02286863  0.01770335 -0.03581619  0.00306441]\n",
            " [ 0.04170844  0.05068012  0.06169621 -0.04009893 -0.01395254  0.00620169\n",
            "  -0.02867429 -0.00259226 -0.01495969  0.01134862]\n",
            " [-0.07090025 -0.04464164  0.03906215 -0.03321323 -0.01257658 -0.03450761\n",
            "  -0.02499266 -0.00259226  0.06773705 -0.01350402]]\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드 및 탐색\n",
        "data = load_diabetes()  # bunch 라는 클래스 타입으로 정리해서 준다\n",
        "# 이상치, 누락치, 정규화까지 다 된 자료를 준다 - pandas, numpy\n",
        "\n",
        "print(\"데이터 키들:\", data.keys()) \n",
        "print(\"타겟 데이터 처음 10개:\", data.target[:10])\n",
        "print(\"특성 데이터 처음 10개:\", data.data[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "데이터 설명:\n",
            ".. _diabetes_dataset:\n",
            "\n",
            "Diabetes dataset\n",
            "----------------\n",
            "\n",
            "Ten baseline variables, age, sex, body mass index, average blood\n",
            "pressure, and six blood serum measurements were obtained for each of n =\n",
            "442 diabetes patients, as well as the response of interest, a\n",
            "quantitative measure of disease progression one year after baseline.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 442\n",
            "\n",
            ":Number of Attributes: First 10 columns are numeric predictive values\n",
            "\n",
            ":Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
            "\n",
            ":Attribute Information:\n",
            "    - age     age in years\n",
            "    - sex\n",
            "    - bmi     body mass index\n",
            "    - bp      average blood pressure\n",
            "    - s1      tc, total serum cholesterol\n",
            "    - s2      ldl, low-density lipoproteins\n",
            "    - s3      hdl, high-density lipoproteins\n",
            "    - s4      tch, total cholesterol / HDL\n",
            "    - s5      ltg, possibly log of serum triglycerides level\n",
            "    - s6      glu, blood sugar level\n",
            "\n",
            "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
            "\n",
            "Source URL:\n",
            "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
            "\n",
            "For more information see:\n",
            "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
            "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n데이터 설명:\")\n",
        "print(data.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (442, 10)\n",
            "y shape: (442,)\n"
          ]
        }
      ],
      "source": [
        "# 데이터 분리\n",
        "X = data.data  # 현재 10개의 특성값\n",
        "y = data.target  # 미래값으로 나타나는 것\n",
        "\n",
        "print(f\"X shape: {X.shape}\")  # 442개이고 특성이 10개\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "# 데이터를 훈련/테스트 세트로 나눈다 (7.5:2.5 비율)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Linear Regression (선형회귀)\n",
        "\n",
        "선형회귀모델의 score 함수는 결정계수를 반환합니다:\n",
        "- 1이면 완벽하게 예측\n",
        "- 0이면 거의 예측불가\n",
        "- 음수면 심각하게 안 맞는 상태\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Linear Model ===\n",
            "훈련셋 R²: 0.5304\n",
            "테스트셋 R²: 0.4694\n"
          ]
        }
      ],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)  # 학습\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== Linear Model ===\")\n",
        "print(f\"훈련셋 R²: {model.score(X_train, y_train):.4f}\")\n",
        "print(f\"테스트셋 R²: {model.score(X_test, y_test):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Ridge Regression (릿지 회귀)\n",
        "\n",
        "L2 정규화를 사용한 선형회귀\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Ridge Model ===\n",
            "훈련셋 R²: 0.5225\n",
            "테스트셋 R²: 0.4723\n"
          ]
        }
      ],
      "source": [
        "model = Ridge(alpha=0.1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== Ridge Model ===\")\n",
        "print(f\"훈련셋 R²: {model.score(X_train, y_train):.4f}\")\n",
        "print(f\"테스트셋 R²: {model.score(X_test, y_test):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Lasso Regression (라쏘 회귀)\n",
        "\n",
        "L1 정규화를 사용한 선형회귀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Lasso Model ===\n",
            "훈련셋 R²: 0.5202\n",
            "테스트셋 R²: 0.4752\n"
          ]
        }
      ],
      "source": [
        "model = Lasso(alpha=0.1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== Lasso Model ===\")\n",
        "print(f\"훈련셋 R²: {model.score(X_train, y_train):.4f}\")\n",
        "print(f\"테스트셋 R²: {model.score(X_test, y_test):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Decision Tree Regressor (의사결정트리 회귀)\n",
        "\n",
        "의사결정트리는 회귀 가능하지만, 트리 계열은 언제나 과대적합 상태임\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DecisionTreeRegressor Model ===\n",
            "훈련셋 R²: 1.0000\n",
            "테스트셋 R²: -0.0732\n",
            "특성의 중요도: [0.0547852  0.01930743 0.36886387 0.08001894 0.04362728 0.07861217\n",
            " 0.05050573 0.0179285  0.18137448 0.1049764 ]\n"
          ]
        }
      ],
      "source": [
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== DecisionTreeRegressor Model ===\")\n",
        "print(f\"훈련셋 R²: {model.score(X_train, y_train):.4f}\")\n",
        "print(f\"테스트셋 R²: {model.score(X_test, y_test):.4f}\")  # 회귀분석에서 score가 음수면 위험\n",
        "print(\"특성의 중요도:\", model.feature_importances_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Random Forest Regressor (랜덤포레스트 회귀)\n",
        "\n",
        "의사결정트리의 업그레이드 버전, 여러 개의 분석기를 함께 사용하는 앙상블 방법\n",
        "- 트리를 랜덤하게 많이 만들어서 평균값을 구함\n",
        "- 할 때마다 별도의 트리가 만들어져서 계속 측정치가 달라짐\n",
        "- `n_estimators`: 만들 트리 최대 개수\n",
        "- `max_depth`: 트리의 최대 깊이 지정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RandomForestRegressor Model ===\n",
            "훈련셋 R²: 0.5810\n",
            "테스트셋 R²: 0.4800\n",
            "특성의 중요도: [0.0121268  0.00086328 0.47291228 0.06232497 0.00705143 0.01297284\n",
            " 0.03647155 0.02186937 0.30277389 0.0706336 ]\n"
          ]
        }
      ],
      "source": [
        "model = RandomForestRegressor(random_state=0, n_estimators=300, max_depth=3)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== RandomForestRegressor Model ===\")\n",
        "print(f\"훈련셋 R²: {model.score(X_train, y_train):.4f}\")\n",
        "print(f\"테스트셋 R²: {model.score(X_test, y_test):.4f}\")\n",
        "print(\"특성의 중요도:\", model.feature_importances_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Gradient Boosting Regressor (그라디언트 부스팅 회귀)\n",
        "\n",
        "앙상블 계열, 약한 학습기들을 통해서 학습하고 보정작업을 거쳐서 결과를 찾아냄\n",
        "- sklearn GradientBoostion, xgboost 라이브러리, LightGBM 등이 있음\n",
        "- `learning_rate=0.1`: 학습률, 머신러닝이 학습하는 속도를 조절\n",
        "  - 너무 높으면: 빨리 학습하다가 최적의 위치를 지나칠 수 있음\n",
        "  - 너무 낮으면: 천천히 느리게 학습해서 최저점을 못 도달할 수 있음\n",
        "- GridSearch: 하이퍼파라미터들을 주면 알아서 테스트하면서 적절한 파라미터를 찾아냄 (오래 걸림)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== GradientBoostingRegressor Model ===\n",
            "훈련셋 R²: 0.5086\n",
            "테스트셋 R²: 0.4397\n",
            "특성의 중요도: [0.00994865 0.         0.49742687 0.04256156 0.01226501 0.0187062\n",
            " 0.03427296 0.01095451 0.27842547 0.09543876]\n"
          ]
        }
      ],
      "source": [
        "model = GradientBoostingRegressor(random_state=0, n_estimators=10, max_depth=3, learning_rate=0.1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== GradientBoostingRegressor Model ===\")\n",
        "print(f\"훈련셋 R²: {model.score(X_train, y_train):.4f}\")\n",
        "print(f\"테스트셋 R²: {model.score(X_test, y_test):.4f}\")\n",
        "print(\"특성의 중요도:\", model.feature_importances_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. XGBoost Regressor\n",
        "\n",
        "설치 필요: `conda install xgboost`\n",
        "\n",
        "Microsoft Visual C++ Build Tools 설치도 필요할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== XGBRegressor Model ===\n",
            "훈련셋 R²: 0.4964\n",
            "테스트셋 R²: 0.4179\n",
            "특성의 중요도: [0.         0.06538191 0.3058761  0.05812455 0.02936009 0.05922715\n",
            " 0.05762395 0.12139277 0.15938935 0.14362407]\n"
          ]
        }
      ],
      "source": [
        "if XGBOOST_AVAILABLE:\n",
        "    model = XGBRegressor(random_state=0, n_estimators=10, max_depth=3, learning_rate=0.1)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"=== XGBRegressor Model ===\")\n",
        "    print(f\"훈련셋 R²: {model.score(X_train, y_train):.4f}\")\n",
        "    print(f\"테스트셋 R²: {model.score(X_test, y_test):.4f}\")\n",
        "    print(\"특성의 중요도:\", model.feature_importances_)\n",
        "else:\n",
        "    print(\"XGBoost가 설치되지 않아 건너뜁니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 모델 성능 비교 요약\n",
        "\n",
        "위의 결과를 바탕으로 각 모델의 성능을 비교해보세요:\n",
        "- 훈련셋 R²와 테스트셋 R²의 차이가 클수록 과적합\n",
        "- 테스트셋 R²가 높을수록 일반화 성능이 좋음\n",
        "- 특성 중요도를 통해 어떤 특성이 예측에 중요한지 확인 가능\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sesac_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
