# 머신러닝 완전 처리 가이드
## 기초 통계부터 모델 평가까지

---

## 📊 1. 기초통계학 개념

### 1.1 기초통계의 목적
> **현재 상황을 정리하고 집단의 성격을 통계량으로 파악**

### 1.2 주요 통계량

#### 📈 평균 (Mean)
- **정의**: 모든 요소의 합 ÷ 전체 데이터 개수
- **활용 예시**: 연평균 동해안 바다 온도
- **한계**: 평균만으로는 전체 상황 파악이 어려움

#### 📏 분산 (Variance)
- **정의**: 오차의 제곱의 합
- **목적**: 데이터의 흩어짐 정도 측정
- **공식 차이**:
  - **표준분산 (R언어)**: `(기댓값 - 평균값)² 합 ÷ (n-1)`
  - **Scikit-learn**: `(기댓값 - 평균값)² 합 ÷ n`

#### 📐 표준편차 (Standard Deviation)
- **정의**: 분산의 제곱근
- **의미**: 데이터의 흩어짐 정도
- **시각화**: Boxplot에서 박스 크기로 표현

#### 💡 실전 예시
```
학생 A: 모의고사 평균 60, 표준편차 20 → 40~80점 범위 (불안정)
학생 B: 모의고사 평균 70, 표준편차 5  → 65~75점 범위 (안정)
```

#### 🎯 중간값 (Median)
- **정의**: 데이터를 정렬했을 때 중간에 위치한 값
- **계산법**:
  - 홀수 개: 정중앙 값
  - 짝수 개: 중앙 2개 값의 평균
- **활용**: 이상치가 있을 때 평균보다 더 신뢰할 수 있는 대표값

---

## 📋 2. 데이터 유형 분류

### 2.1 범주형 데이터 (Categorical Data)
- **특징**: 값이 불연속적, 카테고리 형태
- **예시**: 연비등급 (1, 2, 3, 4)
- **분석 방법**: 
  - 발생빈도수 (Frequency)
  - 분할표 (Cross-tabulation)
  - 히스토그램으로 구간별 분포 확인

### 2.2 연속형 데이터 (Continuous Data)
- **특징**: 연속된 숫자 값
- **예시**: 실제 연비 값, 키, 몸무게
- **분석 방법**: 평균, 표준편차, 중간값

---

## 🔬 3. 통계적 검정

### 3.1 차이검정의 목적
> **두 그룹 간에 의미있는 차이가 있는지 객관적으로 확인**

### 3.2 검정 방법

#### 📊 범주형 데이터: 카이제곱검정 (Chi-square Test)
```
예시: 형주씨 vs 준오씨 도서 보유 현황
         형주    준오
문학     100     120
추리     400     380
자연주의  50      0
신비주의  10      15
```

#### 📈 연속형 데이터: T-test
- **활용**: 신약 효과 검증 등
- **방법**: 한 그룹은 신약, 다른 그룹은 위약(플라시보)

### 3.3 통계적 유의성
- **유의수준**: 0.05 미만이어야 "차이가 있다"고 판단
- **가설 설정**:
  - **귀무가설**: 현재 상태 (예: 한국 남자 평균키 173cm)
  - **대립가설**: 현재 가설을 폐기할 가설 (173cm보다 크거나 작다)

---

## 🤖 4. 머신러닝 유형

### 4.1 추론통계
> **기초통계를 바탕으로 한 예측**

### 4.2 머신러닝 분류

#### 🎯 지도학습 (Supervised Learning)
- **조건**: 라벨(타겟)이 있는 데이터
- **유형**:
  - **회귀**: 연속된 값 예측 (키, 집값, 성적)
  - **분류**: 범주 예측
    - 이진분류: 둘 중 하나 선택
    - 다중분류: 여러 개 중 하나 선택

#### 🔍 비지도학습 (Unsupervised Learning)
- **조건**: 라벨이 없는 데이터
- **목적**: 지도학습 전단계 특성공학
- **작업**: 새로운 특성 생성, 차원 축소, 연관성 발견, 스케일링

#### 🎮 강화학습 (Reinforcement Learning)
- **예시**: 알파고, 게임 AI
- **방법**: 당근과 채찍 방식
- **주의사항**: Python 3.9 이하에서만 지원, 별도 가상환경 필요

---

## 🛠️ 5. 데이터 전처리 단계

### 5.1 기본 데이터 분석
```python
# 시각화 도구
- boxplot: 이상치 확인
- 산포도(히트맵): 상관관계
- 히스토그램: 분포 확인 (분류용)
- 분할표: 범주형 데이터 분석
- 상관계수: 변수 간 관계
```

### 5.2 결측치 처리
#### 처리 방법 선택
1. **열/행 제거**: 결측치가 너무 많은 경우
2. **대체값 사용**:
   - **연속형 데이터**: 평균 또는 중간값
   - **범주형 데이터**: 최빈값

### 5.3 이상치 제거
#### IQR 방식 (권장)
- **시각화**: Boxplot으로 확인
- **기준**: Q1 - 1.5×IQR 미만, Q3 + 1.5×IQR 초과
- **주의**: 함수를 직접 구현해야 함

### 5.4 중복값 제거
```python
df.drop_duplicates()
```

### 5.5 잘못된 데이터 처리
```python
# 확인 방법
df['column'].value_counts()
df['column'].unique()

# 처리 방법
- 값 교체
- 해당 행 삭제
```

---

## 🏷️ 6. 데이터 인코딩

### 6.1 라벨 인코딩 (Label Encoding)
#### 적용 상황
- **범위**: 3~4개 미만의 범주
- **예시**: 성별 (male=0, female=1)

#### 도구
```python
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder
```

### 6.2 원핫 인코딩 (One-Hot Encoding)
#### 적용 상황
- **범위**: 범주가 많은 경우
- **이유**: 라벨 인코딩 시 가중치 왜곡 방지

#### 예시
```python
# 직업 데이터 원핫 인코딩
     직업_회사원  직업_주부  직업_학생  직업_공무원  직업_기타
회사원    1        0        0        0       0
주부      0        1        0        0       0
학생      0        0        1        0       0
```

---

## ⚖️ 7. 스케일링

### 7.1 스케일링의 필요성
```python
# 선형 회귀 모델
y = w1×x1 + w2×x2 + w3×x3 + ... + wn×xn + b
```

- **문제**: 값의 범위 차이가 클 때 큰 값 기준으로 가중치 결정
- **영향받는 알고리즘**: 
  - Support Vector Machine (SVM)
  - 딥러닝 모델

### 7.2 스케일링 방법
- **정규화 (Normalization)**: 0~1 범위로 변환
- **표준화 (Standardization)**: 평균 0, 표준편차 1로 변환

---

## 🎯 8. 모델 학습 및 최적화

### 8.1 모델 선택
- 여러 모델로 학습 및 비교
- GridSearchCV를 통한 하이퍼파라미터 최적화

### 8.2 교차검증
- 모델의 일반화 성능 확인
- 과적합 방지

---

## 📏 9. 평가지표

### 9.1 회귀 평가지표

#### MAE (Mean Absolute Error)
- **공식**: `|기댓값 - 실제값|의 합 ÷ 개수`
- **특징**: 이상치에 덜 민감

#### MSE (Mean Squared Error)
- **공식**: `(기댓값 - 실제값)²의 합 ÷ 개수`
- **특징**: 이상치에 민감, 딥러닝 손실함수로 활용

#### RMSE (Root Mean Squared Error)
- **공식**: `√MSE`
- **장점**: 원래 단위로 해석 가능

#### R² (결정계수)
- **범위**: -∞ ~ 1
- **해석**:
  - 1에 가까울수록: 예측 뛰어남
  - 0에 가까울수록: 예측력 부족
  - 음수: 심각한 문제

#### MAPE (Mean Absolute Percentage Error)
- **특징**: 퍼센트로 표현되어 해석 용이

### 9.2 분류 평가지표

#### ⚠️ 불균형 데이터의 문제점
```
예시: 암환자 데이터
- 양성: 3%
- 음성: 97%

→ 모든 예측을 "음성"으로 해도 97% 정확도!
```

#### 🔍 오차행렬 (Confusion Matrix)
```
           예측 양성    예측 음성
실제 양성     TP         FN
실제 음성     FP         TN
```

- **TP (True Positive)**: 실제 양성을 양성으로 예측
- **FP (False Positive)**: 실제 음성을 양성으로 예측
- **TN (True Negative)**: 실제 음성을 음성으로 예측
- **FN (False Negative)**: 실제 양성을 음성으로 예측

#### 📊 주요 지표

##### 1️⃣ 정확도 (Accuracy)
```python
정확도 = (TP + TN) / (TP + FP + TN + FN)
```
- **한계**: 불균형 데이터에서 신뢰도 떨어짐

##### 2️⃣ 정밀도 (Precision)
```python
정밀도 = TP / (TP + FP)
```
- **의미**: 양성으로 예측한 것 중 실제 양성 비율
- **중요한 경우**: 스팸 메일 분류 (정상 메일을 스팸으로 분류하면 안 됨)

##### 3️⃣ 재현율 (Recall) / 민감도 (Sensitivity)
```python
재현율 = TP / (TP + FN)
```
- **의미**: 실제 양성 중 양성으로 예측한 비율
- **중요한 경우**: 암 진단 (양성을 음성으로 판단하면 치명적)

##### 4️⃣ F1-Score
```python
F1-Score = 2 × (정밀도 × 재현율) / (정밀도 + 재현율)
```
- **의미**: 정밀도와 재현율의 조화평균
- **활용**: 두 지표 모두 중요한 경우

---

## 🎯 10. 실무 적용 팁

### 10.1 프로젝트 단계별 체크리스트
1. ✅ **데이터 탐색**: 기초통계, 시각화
2. ✅ **전처리**: 결측치, 이상치, 중복값 처리
3. ✅ **특성공학**: 인코딩, 스케일링
4. ✅ **모델링**: 다양한 알고리즘 시도
5. ✅ **평가**: 적절한 평가지표 선택
6. ✅ **최적화**: 하이퍼파라미터 튜닝

### 10.2 평가지표 선택 가이드

| 상황 | 권장 지표 | 이유 |
|------|-----------|------|
| 균형 데이터 분류 | Accuracy | 직관적이고 신뢰할 수 있음 |
| 불균형 데이터 | F1-Score, AUC | 정밀도와 재현율 균형 |
| 의료 진단 | Recall | 놓치면 안 되는 케이스 |
| 스팸 분류 | Precision | 잘못 분류하면 문제 |
| 회귀 예측 | RMSE, R² | 해석하기 쉽고 표준적 |

---

## 📚 참고사항

### 주의사항
- **불균형 데이터**: 반드시 적절한 평가지표 사용
- **이상치**: 도메인 지식과 함께 신중하게 처리
- **과적합**: 교차검증으로 반드시 확인
- **스케일링**: 알고리즘 특성에 맞게 선택

### 추가 학습 권장
- 도메인별 특성공학 기법
- 앙상블 방법론
- 딥러닝 기초
- MLOps 파이프라인 